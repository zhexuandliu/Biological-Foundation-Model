{"cells":[{"cell_type":"markdown","metadata":{"id":"ZK9MIU6G04ga"},"source":["# Model Performance Comparison: Pre-trained vs Fine-tuned scGPT\n","\n","This notebook provides a comprehensive comparison of the pre-trained and fine-tuned scGPT models' performance on both training and test data to assess the effectiveness of fine-tuning.\n","\n","## Overview\n","- **Goal**: Compare performance between pre-trained and fine-tuned models on training and test data\n","- **Dataset**: Adamson perturbation data with simulation split\n","- **Analysis**: Multiple evaluation metrics including perturbation prediction accuracy, gene expression reconstruction, and downstream task performance\n","- **Context**: Previous analysis showed OOD issues - this notebook quantifies how well fine-tuning addresses them\n"]},{"cell_type":"code","source":["from google.colab import drive\n","import os\n","\n","drive.mount('/content/drive')\n","os.chdir('/content/drive/MyDrive/GitHub/Biological-Foundation-Model/Notebooks/scGPT_finetune')\n","\n","!pip install -r ./requirements.txt\n","!pip install scgpt \"flash-attn<1.0.5\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mnx8KEr_0-Lf","executionInfo":{"status":"ok","timestamp":1759726114908,"user_tz":300,"elapsed":862129,"user":{"displayName":"Zhexuan Liu","userId":"18073944608501350772"}},"outputId":"790590eb-442e-4ddf-c3fe-9713531bedef"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from -r ./requirements.txt (line 2)) (2.0.2)\n","Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from -r ./requirements.txt (line 3)) (2.2.2)\n","Collecting torch==2.3.1 (from -r ./requirements.txt (line 6))\n","  Downloading torch-2.3.1-cp312-cp312-manylinux1_x86_64.whl.metadata (26 kB)\n","Collecting torchvision==0.18.1 (from -r ./requirements.txt (line 7))\n","  Downloading torchvision-0.18.1-cp312-cp312-manylinux1_x86_64.whl.metadata (6.6 kB)\n","Collecting torchaudio==2.3.1 (from -r ./requirements.txt (line 8))\n","  Downloading torchaudio-2.3.1-cp312-cp312-manylinux1_x86_64.whl.metadata (6.4 kB)\n","Collecting torchtext==0.18.0 (from -r ./requirements.txt (line 9))\n","  Downloading torchtext-0.18.0-cp312-cp312-manylinux1_x86_64.whl.metadata (7.9 kB)\n","Collecting scanpy<2.0,>=1.9.1 (from -r ./requirements.txt (line 12))\n","  Downloading scanpy-1.11.4-py3-none-any.whl.metadata (9.2 kB)\n","Collecting scvi-tools<1.0,>=0.16.0 (from -r ./requirements.txt (line 13))\n","  Downloading scvi_tools-0.20.3-py3-none-any.whl.metadata (9.8 kB)\n","Collecting torch_geometric (from -r ./requirements.txt (line 16))\n","  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting cell-gears (from -r ./requirements.txt (line 17))\n","  Downloading cell_gears-0.1.2-py3-none-any.whl.metadata (3.6 kB)\n","Collecting scgpt (from -r ./requirements.txt (line 18))\n","  Downloading scgpt-0.2.4-py3-none-any.whl.metadata (10.0 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1->-r ./requirements.txt (line 6)) (3.19.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1->-r ./requirements.txt (line 6)) (4.15.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1->-r ./requirements.txt (line 6)) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1->-r ./requirements.txt (line 6)) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1->-r ./requirements.txt (line 6)) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1->-r ./requirements.txt (line 6)) (2025.3.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.1->-r ./requirements.txt (line 6))\n","  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.1->-r ./requirements.txt (line 6))\n","  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.1->-r ./requirements.txt (line 6))\n","  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.1->-r ./requirements.txt (line 6))\n","  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.1->-r ./requirements.txt (line 6))\n","  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.1->-r ./requirements.txt (line 6))\n","  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.1->-r ./requirements.txt (line 6))\n","  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.1->-r ./requirements.txt (line 6))\n","  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.1->-r ./requirements.txt (line 6))\n","  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.1->-r ./requirements.txt (line 6))\n","  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.1->-r ./requirements.txt (line 6))\n","  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision==0.18.1->-r ./requirements.txt (line 7)) (11.3.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torchtext==0.18.0->-r ./requirements.txt (line 9)) (4.67.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torchtext==0.18.0->-r ./requirements.txt (line 9)) (2.32.4)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.1->-r ./requirements.txt (line 6)) (12.6.85)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.0->-r ./requirements.txt (line 3)) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.0->-r ./requirements.txt (line 3)) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.0->-r ./requirements.txt (line 3)) (2025.2)\n","Collecting anndata>=0.8 (from scanpy<2.0,>=1.9.1->-r ./requirements.txt (line 12))\n","  Downloading anndata-0.12.2-py3-none-any.whl.metadata (9.6 kB)\n","Requirement already satisfied: h5py>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from scanpy<2.0,>=1.9.1->-r ./requirements.txt (line 12)) (3.14.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from scanpy<2.0,>=1.9.1->-r ./requirements.txt (line 12)) (1.5.2)\n","Collecting legacy-api-wrap>=1.4.1 (from scanpy<2.0,>=1.9.1->-r ./requirements.txt (line 12))\n","  Downloading legacy_api_wrap-1.4.1-py3-none-any.whl.metadata (2.1 kB)\n","Requirement already satisfied: matplotlib>=3.7.5 in /usr/local/lib/python3.12/dist-packages (from scanpy<2.0,>=1.9.1->-r ./requirements.txt (line 12)) (3.10.0)\n","Requirement already satisfied: natsort in /usr/local/lib/python3.12/dist-packages (from scanpy<2.0,>=1.9.1->-r ./requirements.txt (line 12)) (8.4.0)\n","Requirement already satisfied: numba>=0.57.1 in /usr/local/lib/python3.12/dist-packages (from scanpy<2.0,>=1.9.1->-r ./requirements.txt (line 12)) (0.60.0)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from scanpy<2.0,>=1.9.1->-r ./requirements.txt (line 12)) (25.0)\n","Requirement already satisfied: patsy!=1.0.0 in /usr/local/lib/python3.12/dist-packages (from scanpy<2.0,>=1.9.1->-r ./requirements.txt (line 12)) (1.0.1)\n","Requirement already satisfied: pynndescent>=0.5.13 in /usr/local/lib/python3.12/dist-packages (from scanpy<2.0,>=1.9.1->-r ./requirements.txt (line 12)) (0.5.13)\n","Requirement already satisfied: scikit-learn>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from scanpy<2.0,>=1.9.1->-r ./requirements.txt (line 12)) (1.6.1)\n","Requirement already satisfied: scipy>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from scanpy<2.0,>=1.9.1->-r ./requirements.txt (line 12)) (1.16.2)\n","Requirement already satisfied: seaborn>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from scanpy<2.0,>=1.9.1->-r ./requirements.txt (line 12)) (0.13.2)\n","Collecting session-info2 (from scanpy<2.0,>=1.9.1->-r ./requirements.txt (line 12))\n","  Downloading session_info2-0.2.2-py3-none-any.whl.metadata (3.4 kB)\n","Requirement already satisfied: statsmodels>=0.14.5 in /usr/local/lib/python3.12/dist-packages (from scanpy<2.0,>=1.9.1->-r ./requirements.txt (line 12)) (0.14.5)\n","Requirement already satisfied: umap-learn>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from scanpy<2.0,>=1.9.1->-r ./requirements.txt (line 12)) (0.5.9.post2)\n","Requirement already satisfied: chex in /usr/local/lib/python3.12/dist-packages (from scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13)) (0.1.90)\n","Collecting docrep>=0.3.2 (from scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13))\n","  Downloading docrep-0.3.2.tar.gz (33 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: flax in /usr/local/lib/python3.12/dist-packages (from scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13)) (0.10.6)\n","Requirement already satisfied: jax>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13)) (0.5.3)\n","Requirement already satisfied: jaxlib>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13)) (0.5.3)\n","Collecting ml-collections>=0.1.1 (from scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13))\n","  Downloading ml_collections-1.1.0-py3-none-any.whl.metadata (22 kB)\n","Collecting mudata>=0.1.2 (from scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13))\n","  Downloading mudata-0.3.2-py3-none-any.whl.metadata (8.4 kB)\n","Collecting numpyro (from scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13))\n","  Downloading numpyro-0.19.0-py3-none-any.whl.metadata (37 kB)\n","Requirement already satisfied: openpyxl>=3.0 in /usr/local/lib/python3.12/dist-packages (from scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13)) (3.1.5)\n","Requirement already satisfied: optax in /usr/local/lib/python3.12/dist-packages (from scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13)) (0.2.6)\n","Collecting pyro-ppl>=1.6.0 (from scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13))\n","  Downloading pyro_ppl-1.9.1-py3-none-any.whl.metadata (7.8 kB)\n","Collecting pytorch-lightning<1.10.0,>=1.9.0 (from scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13))\n","  Downloading pytorch_lightning-1.9.5-py3-none-any.whl.metadata (23 kB)\n","Requirement already satisfied: rich>=12.0.0 in /usr/local/lib/python3.12/dist-packages (from scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13)) (13.9.4)\n","Collecting torchmetrics>=0.11.0 (from scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13))\n","  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch_geometric->-r ./requirements.txt (line 16)) (3.12.15)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch_geometric->-r ./requirements.txt (line 16)) (5.9.5)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch_geometric->-r ./requirements.txt (line 16)) (3.2.5)\n","Collecting dcor (from cell-gears->-r ./requirements.txt (line 17))\n","  Downloading dcor-0.6-py3-none-any.whl.metadata (6.2 kB)\n","Collecting cell-gears (from -r ./requirements.txt (line 17))\n","  Downloading cell-gears-0.0.2.tar.gz (25 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting datasets<3.0.0,>=2.3.0 (from scgpt->-r ./requirements.txt (line 18))\n","  Downloading datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\n","Collecting leidenalg>=0.8.10 (from scgpt->-r ./requirements.txt (line 18))\n","  Downloading leidenalg-0.10.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n","Collecting orbax<0.1.8 (from scgpt->-r ./requirements.txt (line 18))\n","  Downloading orbax-0.1.7-py3-none-any.whl.metadata (1.9 kB)\n","Collecting scib<2.0.0,>=1.0.3 (from scgpt->-r ./requirements.txt (line 18))\n","  Downloading scib-1.1.7-1-py3-none-any.whl.metadata (9.8 kB)\n","Collecting scikit-misc>=0.1.4 (from scgpt->-r ./requirements.txt (line 18))\n","  Downloading scikit_misc-0.5.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n","Collecting array-api-compat>=1.7.1 (from anndata>=0.8->scanpy<2.0,>=1.9.1->-r ./requirements.txt (line 12))\n","  Downloading array_api_compat-1.12.0-py3-none-any.whl.metadata (2.5 kB)\n","Collecting zarr!=3.0.*,>=2.18.7 (from anndata>=0.8->scanpy<2.0,>=1.9.1->-r ./requirements.txt (line 12))\n","  Downloading zarr-3.1.3-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets<3.0.0,>=2.3.0->scgpt->-r ./requirements.txt (line 18)) (18.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets<3.0.0,>=2.3.0->scgpt->-r ./requirements.txt (line 18)) (0.3.8)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets<3.0.0,>=2.3.0->scgpt->-r ./requirements.txt (line 18)) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from datasets<3.0.0,>=2.3.0->scgpt->-r ./requirements.txt (line 18)) (0.70.16)\n","Collecting fsspec (from torch==2.3.1->-r ./requirements.txt (line 6))\n","  Downloading fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.12/dist-packages (from datasets<3.0.0,>=2.3.0->scgpt->-r ./requirements.txt (line 18)) (0.35.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets<3.0.0,>=2.3.0->scgpt->-r ./requirements.txt (line 18)) (6.0.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from docrep>=0.3.2->scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13)) (1.17.0)\n","Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from jax>=0.4.4->scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13)) (0.5.3)\n","Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax>=0.4.4->scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13)) (3.4.0)\n","Collecting igraph<0.12,>=0.10.0 (from leidenalg>=0.8.10->scgpt->-r ./requirements.txt (line 18))\n","  Downloading igraph-0.11.9-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.5->scanpy<2.0,>=1.9.1->-r ./requirements.txt (line 12)) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.5->scanpy<2.0,>=1.9.1->-r ./requirements.txt (line 12)) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.5->scanpy<2.0,>=1.9.1->-r ./requirements.txt (line 12)) (4.60.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.5->scanpy<2.0,>=1.9.1->-r ./requirements.txt (line 12)) (1.4.9)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from ml-collections>=0.1.1->scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13)) (1.4.0)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.57.1->scanpy<2.0,>=1.9.1->-r ./requirements.txt (line 12)) (0.43.0)\n","Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl>=3.0->scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13)) (2.0.0)\n","Collecting cached_property (from orbax<0.1.8->scgpt->-r ./requirements.txt (line 18))\n","  Downloading cached_property-2.0.1-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: importlib_resources in /usr/local/lib/python3.12/dist-packages (from orbax<0.1.8->scgpt->-r ./requirements.txt (line 18)) (6.5.2)\n","Requirement already satisfied: msgpack in /usr/local/lib/python3.12/dist-packages (from orbax<0.1.8->scgpt->-r ./requirements.txt (line 18)) (1.1.1)\n","Requirement already satisfied: etils in /usr/local/lib/python3.12/dist-packages (from orbax<0.1.8->scgpt->-r ./requirements.txt (line 18)) (1.13.0)\n","Requirement already satisfied: tensorstore>=0.1.20 in /usr/local/lib/python3.12/dist-packages (from orbax<0.1.8->scgpt->-r ./requirements.txt (line 18)) (0.1.77)\n","Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.12/dist-packages (from orbax<0.1.8->scgpt->-r ./requirements.txt (line 18)) (1.6.0)\n","Collecting pyro-api>=0.1.1 (from pyro-ppl>=1.6.0->scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13))\n","  Downloading pyro_api-0.1.2-py3-none-any.whl.metadata (2.5 kB)\n","Collecting lightning-utilities>=0.6.0.post0 (from pytorch-lightning<1.10.0,>=1.9.0->scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13))\n","  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.18.0->-r ./requirements.txt (line 9)) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.18.0->-r ./requirements.txt (line 9)) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.18.0->-r ./requirements.txt (line 9)) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.18.0->-r ./requirements.txt (line 9)) (2025.8.3)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.0.0->scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13)) (4.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.0.0->scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13)) (2.19.2)\n","Requirement already satisfied: pydot in /usr/local/lib/python3.12/dist-packages (from scib<2.0.0,>=1.0.3->scgpt->-r ./requirements.txt (line 18)) (3.0.4)\n","Collecting deprecated (from scib<2.0.0,>=1.0.3->scgpt->-r ./requirements.txt (line 18))\n","  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.3->scanpy<2.0,>=1.9.1->-r ./requirements.txt (line 12)) (3.6.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric->-r ./requirements.txt (line 16)) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric->-r ./requirements.txt (line 16)) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric->-r ./requirements.txt (line 16)) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric->-r ./requirements.txt (line 16)) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric->-r ./requirements.txt (line 16)) (6.6.4)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric->-r ./requirements.txt (line 16)) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric->-r ./requirements.txt (line 16)) (1.20.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from chex->scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13)) (75.2.0)\n","Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chex->scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13)) (0.12.1)\n","Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.12/dist-packages (from flax->scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13)) (0.11.24)\n","Requirement already satisfied: treescope>=0.1.7 in /usr/local/lib/python3.12/dist-packages (from flax->scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13)) (0.1.10)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.3.1->-r ./requirements.txt (line 6)) (3.0.3)\n","Requirement already satisfied: multipledispatch in /usr/local/lib/python3.12/dist-packages (from numpyro->scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13)) (1.0.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.3.1->-r ./requirements.txt (line 6)) (1.3.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21.2->datasets<3.0.0,>=2.3.0->scgpt->-r ./requirements.txt (line 18)) (1.1.10)\n","Collecting texttable>=1.6.2 (from igraph<0.12,>=0.10.0->leidenalg>=0.8.10->scgpt->-r ./requirements.txt (line 18))\n","  Downloading texttable-1.7.0-py2.py3-none-any.whl.metadata (9.8 kB)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13)) (0.1.2)\n","Collecting donfig>=0.8 (from zarr!=3.0.*,>=2.18.7->anndata>=0.8->scanpy<2.0,>=1.9.1->-r ./requirements.txt (line 12))\n","  Downloading donfig-0.8.1.post1-py3-none-any.whl.metadata (5.0 kB)\n","Collecting numcodecs>=0.14 (from numcodecs[crc32c]>=0.14->zarr!=3.0.*,>=2.18.7->anndata>=0.8->scanpy<2.0,>=1.9.1->-r ./requirements.txt (line 12))\n","  Downloading numcodecs-0.16.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n","Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.12/dist-packages (from deprecated->scib<2.0.0,>=1.0.3->scgpt->-r ./requirements.txt (line 18)) (1.17.3)\n","Requirement already satisfied: aiofiles in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax->scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13)) (24.1.0)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax->scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13)) (5.29.5)\n","Requirement already satisfied: humanize in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax->scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13)) (4.13.0)\n","Requirement already satisfied: simplejson>=3.16.0 in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax->scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13)) (3.20.2)\n","Collecting crc32c>=2.7 (from numcodecs[crc32c]>=0.14->zarr!=3.0.*,>=2.18.7->anndata>=0.8->scanpy<2.0,>=1.9.1->-r ./requirements.txt (line 12))\n","  Downloading crc32c-2.7.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n","Requirement already satisfied: zipp in /usr/local/lib/python3.12/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax->scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13)) (3.23.0)\n","Downloading torch-2.3.1-cp312-cp312-manylinux1_x86_64.whl (779.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchvision-0.18.1-cp312-cp312-manylinux1_x86_64.whl (7.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchaudio-2.3.1-cp312-cp312-manylinux1_x86_64.whl (3.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m85.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchtext-0.18.0-cp312-cp312-manylinux1_x86_64.whl (2.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m94.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading scanpy-1.11.4-py3-none-any.whl (2.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m101.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading scvi_tools-0.20.3-py3-none-any.whl (330 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.3/330.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading scgpt-0.2.4-py3-none-any.whl (831 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m831.7/831.7 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading anndata-0.12.2-py3-none-any.whl (169 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.9/169.9 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading datasets-2.21.0-py3-none-any.whl (527 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.3/527.3 kB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading legacy_api_wrap-1.4.1-py3-none-any.whl (10.0 kB)\n","Downloading leidenalg-0.10.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ml_collections-1.1.0-py3-none-any.whl (76 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.7/76.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mudata-0.3.2-py3-none-any.whl (41 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading orbax-0.1.7-py3-none-any.whl (77 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.5/77.5 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyro_ppl-1.9.1-py3-none-any.whl (755 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pytorch_lightning-1.9.5-py3-none-any.whl (829 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m829.5/829.5 kB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading scib-1.1.7-1-py3-none-any.whl (84 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.6/84.6 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading scikit_misc-0.5.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (183 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.6/183.6 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dcor-0.6-py3-none-any.whl (55 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numpyro-0.19.0-py3-none-any.whl (370 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m370.9/370.9 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading session_info2-0.2.2-py3-none-any.whl (16 kB)\n","Downloading array_api_compat-1.12.0-py3-none-any.whl (58 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.2/58.2 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading igraph-0.11.9-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m120.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n","Downloading pyro_api-0.1.2-py3-none-any.whl (11 kB)\n","Downloading zarr-3.1.3-py3-none-any.whl (276 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.4/276.4 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading cached_property-2.0.1-py3-none-any.whl (7.4 kB)\n","Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n","Downloading donfig-0.8.1.post1-py3-none-any.whl (21 kB)\n","Downloading numcodecs-0.16.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n","Downloading crc32c-2.7.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.5/53.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: cell-gears, docrep\n","  Building wheel for cell-gears (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for cell-gears: filename=cell_gears-0.0.2-py3-none-any.whl size=27809 sha256=051383a96efb604e0ba233fb2d45b37bddc9eb962e03765876b093a92b0e3915\n","  Stored in directory: /root/.cache/pip/wheels/c3/7d/33/062df7a4c34312454fa656f964080fe34b4d518fdb851d164f\n","  Building wheel for docrep (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for docrep: filename=docrep-0.3.2-py3-none-any.whl size=19876 sha256=ee0d4e668f6ccdf6f575499df35cc0cfa68d4a41d92ad29594edfba9c1fd8ceb\n","  Stored in directory: /root/.cache/pip/wheels/d6/19/ee/0a6a1793d91c449563b49ccab57ce52da3e6fab7614836bd8c\n","Successfully built cell-gears docrep\n","Installing collected packages: texttable, pyro-api, session-info2, scikit-misc, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numcodecs, ml-collections, lightning-utilities, legacy-api-wrap, igraph, fsspec, donfig, docrep, deprecated, crc32c, cached_property, array-api-compat, nvidia-cusolver-cu12, nvidia-cudnn-cu12, leidenalg, dcor, zarr, torch_geometric, torch, torchvision, torchtext, torchmetrics, torchaudio, pyro-ppl, orbax, numpyro, datasets, anndata, scanpy, pytorch-lightning, mudata, scib, cell-gears, scvi-tools, scgpt\n","  Attempting uninstall: nvidia-nvtx-cu12\n","    Found existing installation: nvidia-nvtx-cu12 12.6.77\n","    Uninstalling nvidia-nvtx-cu12-12.6.77:\n","      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n","  Attempting uninstall: nvidia-nccl-cu12\n","    Found existing installation: nvidia-nccl-cu12 2.27.3\n","    Uninstalling nvidia-nccl-cu12-2.27.3:\n","      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n","    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.7.77\n","    Uninstalling nvidia-curand-cu12-10.3.7.77:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n","    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n","      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n","    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n","    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n","    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n","      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2025.3.0\n","    Uninstalling fsspec-2025.3.0:\n","      Successfully uninstalled fsspec-2025.3.0\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n","    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n","    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.8.0+cu126\n","    Uninstalling torch-2.8.0+cu126:\n","      Successfully uninstalled torch-2.8.0+cu126\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.23.0+cu126\n","    Uninstalling torchvision-0.23.0+cu126:\n","      Successfully uninstalled torchvision-0.23.0+cu126\n","  Attempting uninstall: torchaudio\n","    Found existing installation: torchaudio 2.8.0+cu126\n","    Uninstalling torchaudio-2.8.0+cu126:\n","      Successfully uninstalled torchaudio-2.8.0+cu126\n","  Attempting uninstall: datasets\n","    Found existing installation: datasets 4.0.0\n","    Uninstalling datasets-4.0.0:\n","      Successfully uninstalled datasets-4.0.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.6.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed anndata-0.12.2 array-api-compat-1.12.0 cached_property-2.0.1 cell-gears-0.0.2 crc32c-2.7.1 datasets-2.21.0 dcor-0.6 deprecated-1.2.18 docrep-0.3.2 donfig-0.8.1.post1 fsspec-2024.6.1 igraph-0.11.9 legacy-api-wrap-1.4.1 leidenalg-0.10.2 lightning-utilities-0.15.2 ml-collections-1.1.0 mudata-0.3.2 numcodecs-0.16.3 numpyro-0.19.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 orbax-0.1.7 pyro-api-0.1.2 pyro-ppl-1.9.1 pytorch-lightning-1.9.5 scanpy-1.11.4 scgpt-0.2.4 scib-1.1.7 scikit-misc-0.5.1 scvi-tools-0.20.3 session-info2-0.2.2 texttable-1.7.0 torch-2.3.1 torch_geometric-2.6.1 torchaudio-2.3.1 torchmetrics-1.8.2 torchtext-0.18.0 torchvision-0.18.1 zarr-3.1.3\n","Requirement already satisfied: scgpt in /usr/local/lib/python3.12/dist-packages (0.2.4)\n","Collecting flash-attn<1.0.5\n","  Downloading flash_attn-1.0.4.tar.gz (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: cell-gears<0.0.3 in /usr/local/lib/python3.12/dist-packages (from scgpt) (0.0.2)\n","Requirement already satisfied: datasets<3.0.0,>=2.3.0 in /usr/local/lib/python3.12/dist-packages (from scgpt) (2.21.0)\n","Requirement already satisfied: leidenalg>=0.8.10 in /usr/local/lib/python3.12/dist-packages (from scgpt) (0.10.2)\n","Requirement already satisfied: numba>=0.55.1 in /usr/local/lib/python3.12/dist-packages (from scgpt) (0.60.0)\n","Requirement already satisfied: orbax<0.1.8 in /usr/local/lib/python3.12/dist-packages (from scgpt) (0.1.7)\n","Requirement already satisfied: pandas>=1.3.5 in /usr/local/lib/python3.12/dist-packages (from scgpt) (2.2.2)\n","Requirement already satisfied: scanpy<2.0.0,>=1.9.1 in /usr/local/lib/python3.12/dist-packages (from scgpt) (1.11.4)\n","Requirement already satisfied: scib<2.0.0,>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from scgpt) (1.1.7)\n","Requirement already satisfied: scikit-misc>=0.1.4 in /usr/local/lib/python3.12/dist-packages (from scgpt) (0.5.1)\n","Requirement already satisfied: scvi-tools<1.0,>=0.16.0 in /usr/local/lib/python3.12/dist-packages (from scgpt) (0.20.3)\n","Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from scgpt) (2.3.1)\n","Requirement already satisfied: torchtext in /usr/local/lib/python3.12/dist-packages (from scgpt) (0.18.0)\n","Requirement already satisfied: typing-extensions<5.0.0,>=4.2.0 in /usr/local/lib/python3.12/dist-packages (from scgpt) (4.15.0)\n","Requirement already satisfied: umap-learn>=0.5.3 in /usr/local/lib/python3.12/dist-packages (from scgpt) (0.5.9.post2)\n","Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from flash-attn<1.0.5) (0.8.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from flash-attn<1.0.5) (25.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from cell-gears<0.0.3->scgpt) (2.0.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from cell-gears<0.0.3->scgpt) (4.67.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from cell-gears<0.0.3->scgpt) (1.6.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from cell-gears<0.0.3->scgpt) (3.5)\n","Requirement already satisfied: dcor in /usr/local/lib/python3.12/dist-packages (from cell-gears<0.0.3->scgpt) (0.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets<3.0.0,>=2.3.0->scgpt) (3.19.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets<3.0.0,>=2.3.0->scgpt) (18.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets<3.0.0,>=2.3.0->scgpt) (0.3.8)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets<3.0.0,>=2.3.0->scgpt) (2.32.4)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets<3.0.0,>=2.3.0->scgpt) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from datasets<3.0.0,>=2.3.0->scgpt) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets<3.0.0,>=2.3.0->scgpt) (2024.6.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from datasets<3.0.0,>=2.3.0->scgpt) (3.12.15)\n","Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.12/dist-packages (from datasets<3.0.0,>=2.3.0->scgpt) (0.35.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets<3.0.0,>=2.3.0->scgpt) (6.0.3)\n","Requirement already satisfied: igraph<0.12,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from leidenalg>=0.8.10->scgpt) (0.11.9)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.55.1->scgpt) (0.43.0)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from orbax<0.1.8->scgpt) (1.4.0)\n","Requirement already satisfied: cached_property in /usr/local/lib/python3.12/dist-packages (from orbax<0.1.8->scgpt) (2.0.1)\n","Requirement already satisfied: importlib_resources in /usr/local/lib/python3.12/dist-packages (from orbax<0.1.8->scgpt) (6.5.2)\n","Requirement already satisfied: msgpack in /usr/local/lib/python3.12/dist-packages (from orbax<0.1.8->scgpt) (1.1.1)\n","Requirement already satisfied: etils in /usr/local/lib/python3.12/dist-packages (from orbax<0.1.8->scgpt) (1.13.0)\n","Requirement already satisfied: jax>=0.4.6 in /usr/local/lib/python3.12/dist-packages (from orbax<0.1.8->scgpt) (0.5.3)\n","Requirement already satisfied: jaxlib in /usr/local/lib/python3.12/dist-packages (from orbax<0.1.8->scgpt) (0.5.3)\n","Requirement already satisfied: tensorstore>=0.1.20 in /usr/local/lib/python3.12/dist-packages (from orbax<0.1.8->scgpt) (0.1.77)\n","Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.12/dist-packages (from orbax<0.1.8->scgpt) (1.6.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.5->scgpt) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.5->scgpt) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.5->scgpt) (2025.2)\n","Requirement already satisfied: anndata>=0.8 in /usr/local/lib/python3.12/dist-packages (from scanpy<2.0.0,>=1.9.1->scgpt) (0.12.2)\n","Requirement already satisfied: h5py>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from scanpy<2.0.0,>=1.9.1->scgpt) (3.14.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from scanpy<2.0.0,>=1.9.1->scgpt) (1.5.2)\n","Requirement already satisfied: legacy-api-wrap>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from scanpy<2.0.0,>=1.9.1->scgpt) (1.4.1)\n","Requirement already satisfied: matplotlib>=3.7.5 in /usr/local/lib/python3.12/dist-packages (from scanpy<2.0.0,>=1.9.1->scgpt) (3.10.0)\n","Requirement already satisfied: natsort in /usr/local/lib/python3.12/dist-packages (from scanpy<2.0.0,>=1.9.1->scgpt) (8.4.0)\n","Requirement already satisfied: patsy!=1.0.0 in /usr/local/lib/python3.12/dist-packages (from scanpy<2.0.0,>=1.9.1->scgpt) (1.0.1)\n","Requirement already satisfied: pynndescent>=0.5.13 in /usr/local/lib/python3.12/dist-packages (from scanpy<2.0.0,>=1.9.1->scgpt) (0.5.13)\n","Requirement already satisfied: scipy>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from scanpy<2.0.0,>=1.9.1->scgpt) (1.16.2)\n","Requirement already satisfied: seaborn>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from scanpy<2.0.0,>=1.9.1->scgpt) (0.13.2)\n","Requirement already satisfied: session-info2 in /usr/local/lib/python3.12/dist-packages (from scanpy<2.0.0,>=1.9.1->scgpt) (0.2.2)\n","Requirement already satisfied: statsmodels>=0.14.5 in /usr/local/lib/python3.12/dist-packages (from scanpy<2.0.0,>=1.9.1->scgpt) (0.14.5)\n","Requirement already satisfied: pydot in /usr/local/lib/python3.12/dist-packages (from scib<2.0.0,>=1.0.3->scgpt) (3.0.4)\n","Requirement already satisfied: deprecated in /usr/local/lib/python3.12/dist-packages (from scib<2.0.0,>=1.0.3->scgpt) (1.2.18)\n","Requirement already satisfied: chex in /usr/local/lib/python3.12/dist-packages (from scvi-tools<1.0,>=0.16.0->scgpt) (0.1.90)\n","Requirement already satisfied: docrep>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from scvi-tools<1.0,>=0.16.0->scgpt) (0.3.2)\n","Requirement already satisfied: flax in /usr/local/lib/python3.12/dist-packages (from scvi-tools<1.0,>=0.16.0->scgpt) (0.10.6)\n","Requirement already satisfied: ml-collections>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from scvi-tools<1.0,>=0.16.0->scgpt) (1.1.0)\n","Requirement already satisfied: mudata>=0.1.2 in /usr/local/lib/python3.12/dist-packages (from scvi-tools<1.0,>=0.16.0->scgpt) (0.3.2)\n","Requirement already satisfied: numpyro in /usr/local/lib/python3.12/dist-packages (from scvi-tools<1.0,>=0.16.0->scgpt) (0.19.0)\n","Requirement already satisfied: openpyxl>=3.0 in /usr/local/lib/python3.12/dist-packages (from scvi-tools<1.0,>=0.16.0->scgpt) (3.1.5)\n","Requirement already satisfied: optax in /usr/local/lib/python3.12/dist-packages (from scvi-tools<1.0,>=0.16.0->scgpt) (0.2.6)\n","Requirement already satisfied: pyro-ppl>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scvi-tools<1.0,>=0.16.0->scgpt) (1.9.1)\n","Requirement already satisfied: pytorch-lightning<1.10.0,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from scvi-tools<1.0,>=0.16.0->scgpt) (1.9.5)\n","Requirement already satisfied: rich>=12.0.0 in /usr/local/lib/python3.12/dist-packages (from scvi-tools<1.0,>=0.16.0->scgpt) (13.9.4)\n","Requirement already satisfied: torchmetrics>=0.11.0 in /usr/local/lib/python3.12/dist-packages (from scvi-tools<1.0,>=0.16.0->scgpt) (1.8.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->scgpt) (1.13.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->scgpt) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->scgpt) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->scgpt) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->scgpt) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->scgpt) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->scgpt) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->scgpt) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->scgpt) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->scgpt) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->scgpt) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->scgpt) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->scgpt) (12.1.105)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->scgpt) (12.6.85)\n","Requirement already satisfied: array-api-compat>=1.7.1 in /usr/local/lib/python3.12/dist-packages (from anndata>=0.8->scanpy<2.0.0,>=1.9.1->scgpt) (1.12.0)\n","Requirement already satisfied: zarr!=3.0.*,>=2.18.7 in /usr/local/lib/python3.12/dist-packages (from anndata>=0.8->scanpy<2.0.0,>=1.9.1->scgpt) (3.1.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from docrep>=0.3.2->scvi-tools<1.0,>=0.16.0->scgpt) (1.17.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets<3.0.0,>=2.3.0->scgpt) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets<3.0.0,>=2.3.0->scgpt) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets<3.0.0,>=2.3.0->scgpt) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets<3.0.0,>=2.3.0->scgpt) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets<3.0.0,>=2.3.0->scgpt) (6.6.4)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets<3.0.0,>=2.3.0->scgpt) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets<3.0.0,>=2.3.0->scgpt) (1.20.1)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21.2->datasets<3.0.0,>=2.3.0->scgpt) (1.1.10)\n","Requirement already satisfied: texttable>=1.6.2 in /usr/local/lib/python3.12/dist-packages (from igraph<0.12,>=0.10.0->leidenalg>=0.8.10->scgpt) (1.7.0)\n","Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from jax>=0.4.6->orbax<0.1.8->scgpt) (0.5.3)\n","Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax>=0.4.6->orbax<0.1.8->scgpt) (3.4.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.5->scanpy<2.0.0,>=1.9.1->scgpt) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.5->scanpy<2.0.0,>=1.9.1->scgpt) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.5->scanpy<2.0.0,>=1.9.1->scgpt) (4.60.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.5->scanpy<2.0.0,>=1.9.1->scgpt) (1.4.9)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.5->scanpy<2.0.0,>=1.9.1->scgpt) (11.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.5->scanpy<2.0.0,>=1.9.1->scgpt) (3.2.5)\n","Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl>=3.0->scvi-tools<1.0,>=0.16.0->scgpt) (2.0.0)\n","Requirement already satisfied: pyro-api>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from pyro-ppl>=1.6.0->scvi-tools<1.0,>=0.16.0->scgpt) (0.1.2)\n","Requirement already satisfied: lightning-utilities>=0.6.0.post0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning<1.10.0,>=1.9.0->scvi-tools<1.0,>=0.16.0->scgpt) (0.15.2)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets<3.0.0,>=2.3.0->scgpt) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets<3.0.0,>=2.3.0->scgpt) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets<3.0.0,>=2.3.0->scgpt) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets<3.0.0,>=2.3.0->scgpt) (2025.8.3)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.0.0->scvi-tools<1.0,>=0.16.0->scgpt) (4.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.0.0->scvi-tools<1.0,>=0.16.0->scgpt) (2.19.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->cell-gears<0.0.3->scgpt) (3.6.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from chex->scvi-tools<1.0,>=0.16.0->scgpt) (75.2.0)\n","Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chex->scvi-tools<1.0,>=0.16.0->scgpt) (0.12.1)\n","Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.12/dist-packages (from deprecated->scib<2.0.0,>=1.0.3->scgpt) (1.17.3)\n","Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.12/dist-packages (from flax->scvi-tools<1.0,>=0.16.0->scgpt) (0.11.24)\n","Requirement already satisfied: treescope>=0.1.7 in /usr/local/lib/python3.12/dist-packages (from flax->scvi-tools<1.0,>=0.16.0->scgpt) (0.1.10)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.13.0->scgpt) (3.0.3)\n","Requirement already satisfied: multipledispatch in /usr/local/lib/python3.12/dist-packages (from numpyro->scvi-tools<1.0,>=0.16.0->scgpt) (1.0.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch>=1.13.0->scgpt) (1.3.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->scvi-tools<1.0,>=0.16.0->scgpt) (0.1.2)\n","Requirement already satisfied: donfig>=0.8 in /usr/local/lib/python3.12/dist-packages (from zarr!=3.0.*,>=2.18.7->anndata>=0.8->scanpy<2.0.0,>=1.9.1->scgpt) (0.8.1.post1)\n","Requirement already satisfied: numcodecs>=0.14 in /usr/local/lib/python3.12/dist-packages (from numcodecs[crc32c]>=0.14->zarr!=3.0.*,>=2.18.7->anndata>=0.8->scanpy<2.0.0,>=1.9.1->scgpt) (0.16.3)\n","Requirement already satisfied: aiofiles in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax->scvi-tools<1.0,>=0.16.0->scgpt) (24.1.0)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax->scvi-tools<1.0,>=0.16.0->scgpt) (5.29.5)\n","Requirement already satisfied: humanize in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax->scvi-tools<1.0,>=0.16.0->scgpt) (4.13.0)\n","Requirement already satisfied: simplejson>=3.16.0 in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax->scvi-tools<1.0,>=0.16.0->scgpt) (3.20.2)\n","Requirement already satisfied: crc32c>=2.7 in /usr/local/lib/python3.12/dist-packages (from numcodecs[crc32c]>=0.14->zarr!=3.0.*,>=2.18.7->anndata>=0.8->scanpy<2.0.0,>=1.9.1->scgpt) (2.7.1)\n","Requirement already satisfied: zipp in /usr/local/lib/python3.12/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax->scvi-tools<1.0,>=0.16.0->scgpt) (3.23.0)\n","Building wheels for collected packages: flash-attn\n","  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for flash-attn: filename=flash_attn-1.0.4-cp312-cp312-linux_x86_64.whl size=72831146 sha256=23ba5c1054bbf9b61643f64de928c74a337804b1bebc6263a9db20f4eb3bfd98\n","  Stored in directory: /root/.cache/pip/wheels/e6/d9/e4/0b3fc5da539a482a48b9b041e20a07fec0964ba6b4e7148e5e\n","Successfully built flash-attn\n","Installing collected packages: flash-attn\n","Successfully installed flash-attn-1.0.4\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8GPMSEqE04ge","executionInfo":{"status":"ok","timestamp":1759726170541,"user_tz":300,"elapsed":55624,"user":{"displayName":"Zhexuan Liu","userId":"18073944608501350772"}},"outputId":"60cc9efa-d415-41e7-e484-35f2a28ecf4c"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torchtext/vocab/__init__.py:4: UserWarning: \n","/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n","Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n","  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n","/usr/local/lib/python3.12/dist-packages/torchtext/utils.py:4: UserWarning: \n","/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n","Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n","  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"]},{"output_type":"stream","name":"stdout","text":["Libraries imported successfully!\n"]}],"source":["# Import libraries\n","import json\n","import os\n","import sys\n","import time\n","import copy\n","from pathlib import Path\n","from typing import Iterable, List, Tuple, Dict, Union, Optional\n","import warnings\n","\n","import torch\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import plotly.express as px\n","import plotly.graph_objects as go\n","from plotly.subplots import make_subplots\n","from scipy import stats\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","from sklearn.decomposition import PCA\n","from torch import nn\n","from torch.nn import functional as F\n","from torchtext.vocab import Vocab\n","from torchtext._torchtext import Vocab as VocabPybind\n","from torch_geometric.loader import DataLoader\n","from gears import PertData, GEARS\n","from gears.inference import compute_metrics, deeper_analysis, non_dropout_analysis\n","from gears.utils import create_cell_graph_dataset_for_prediction\n","\n","sys.path.insert(0, \"../\")\n","\n","import scgpt as scg\n","from scgpt.model import TransformerGenerator\n","from scgpt.loss import (\n","    masked_mse_loss,\n","    criterion_neg_log_bernoulli,\n","    masked_relative_error,\n",")\n","from scgpt.tokenizer import tokenize_batch, pad_batch, tokenize_and_pad_batch\n","from scgpt.tokenizer.gene_tokenizer import GeneVocab\n","from scgpt.utils import set_seed, map_raw_id_to_vocab_id, compute_perturbation_metrics\n","\n","# Set up plotting\n","plt.style.use('default')\n","sns.set_palette(\"husl\")\n","warnings.filterwarnings(\"ignore\")\n","\n","set_seed(42)\n","print(\"Libraries imported successfully!\")\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zoZIZ0WI04gg","executionInfo":{"status":"ok","timestamp":1759726231779,"user_tz":300,"elapsed":61179,"user":{"displayName":"Zhexuan Liu","userId":"18073944608501350772"}},"outputId":"601c277c-15db-4922-93e7-854a36b36be3"},"outputs":[{"output_type":"stream","name":"stderr","text":["Found local copy...\n"]},{"output_type":"stream","name":"stdout","text":["Loading perturbation data...\n"]},{"output_type":"stream","name":"stderr","text":["Local copy of pyg dataset is detected. Loading...\n","Done!\n","Local copy of split is detected. Loading...\n","Simulation split test composition:\n","combo_seen0:0\n","combo_seen1:0\n","combo_seen2:0\n","unseen_single:22\n","Done!\n","Creating dataloaders....\n","Done!\n"]}],"source":["# Load and prepare data\n","print(\"Loading perturbation data...\")\n","\n","# Settings for data processing\n","pad_token = \"<pad>\"\n","special_tokens = [pad_token, \"<cls>\", \"<eoc>\"]\n","pad_value = 0\n","pert_pad_id = 0\n","include_zero_gene = \"all\"\n","max_seq_len = 1536\n","\n","# Dataset settings\n","data_name = \"adamson\"\n","split = \"simulation\"\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Load perturbation data\n","pert_data = PertData(\"./data\")\n","pert_data.load(data_name=data_name)\n","pert_data.prepare_split(split=split, seed=1)\n","pert_data.get_dataloader(batch_size=64, test_batch_size=64)\n","\n","# print(f\"Data loaded successfully!\")\n","# print(f\"Dataset: {data_name}\")\n","# print(f\"Split: {split}\")\n","# print(f\"Device: {device}\")\n","\n","# # Get basic info about the dataset\n","# adata = pert_data.adata\n","# print(f\"\\nDataset info:\")\n","# print(f\"Total cells: {adata.n_obs}\")\n","# print(f\"Total genes: {adata.n_vars}\")\n","# print(f\"Conditions: {len(adata.obs['condition'].unique())} unique conditions\")\n","\n","# # Extract train/test splits\n","# def extract_split_data_by_conditions(adata, set2conditions, split_name):\n","#     \"\"\"Extract data for a specific split based on conditions\"\"\"\n","#     if split_name not in set2conditions:\n","#         raise ValueError(f\"Unknown split: {split_name}\")\n","\n","#     # Get conditions for this split\n","#     split_conditions = set2conditions[split_name]\n","\n","#     # Create boolean mask for cells in this split\n","#     split_mask = adata.obs['condition'].isin(split_conditions)\n","\n","#     return adata[split_mask].copy()\n","\n","# train_adata = extract_split_data_by_conditions(adata, pert_data.set2conditions, \"train\")\n","# test_adata = extract_split_data_by_conditions(adata, pert_data.set2conditions, \"test\")\n","# val_adata = extract_split_data_by_conditions(adata, pert_data.set2conditions, \"val\")\n","\n","# print(f\"\\nSplit sizes:\")\n","# print(f\"Train: {train_adata.n_obs} cells\")\n","# print(f\"Test: {test_adata.n_obs} cells\")\n","# print(f\"Val: {val_adata.n_obs} cells\")\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"leQFcp3w04gg","executionInfo":{"status":"ok","timestamp":1759726233007,"user_tz":300,"elapsed":1219,"user":{"displayName":"Zhexuan Liu","userId":"18073944608501350772"}},"outputId":"acfdc636-c5d7-4ec7-92b1-78ade86ac857"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading models...\n","Model configuration loaded:\n","  Vocabulary size: 60697\n","  Embedding size: 512\n","  Number of layers: 12\n","  Genes in vocab: 4399/5060\n"]}],"source":["# Load pretrained and finetuned models\n","print(\"Loading models...\")\n","\n","# Model settings\n","load_model = \"./save/scGPT_human\"\n","load_param_prefixs = [\n","    \"encoder\",\n","    \"value_encoder\",\n","    \"transformer_encoder\",\n","]\n","\n","# Load model configuration\n","model_dir = Path(\"./save/scGPT_human\")\n","model_config_file = model_dir / \"args.json\"\n","model_file = model_dir / \"best_model.pt\"\n","vocab_file = model_dir / \"vocab.json\"\n","\n","vocab = GeneVocab.from_file(vocab_file)\n","for s in special_tokens:\n","    if s not in vocab:\n","        vocab.append_token(s)\n","\n","pert_data.adata.var[\"id_in_vocab\"] = [\n","    1 if gene in vocab else -1 for gene in pert_data.adata.var[\"gene_name\"]\n","]\n","gene_ids_in_vocab = np.array(pert_data.adata.var[\"id_in_vocab\"])\n","genes = pert_data.adata.var[\"gene_name\"].tolist()\n","\n","# Load model configuration\n","with open(model_config_file, \"r\") as f:\n","    model_configs = json.load(f)\n","\n","embsize = model_configs[\"embsize\"]\n","nhead = model_configs[\"nheads\"]\n","d_hid = model_configs[\"d_hid\"]\n","nlayers = model_configs[\"nlayers\"]\n","n_layers_cls = model_configs[\"n_layers_cls\"]\n","\n","vocab.set_default_index(vocab[\"<pad>\"])\n","gene_ids = np.array(\n","    [vocab[gene] if gene in vocab else vocab[\"<pad>\"] for gene in genes], dtype=int\n",")\n","n_genes = len(genes)\n","ntokens = len(vocab)\n","\n","print(f\"Model configuration loaded:\")\n","print(f\"  Vocabulary size: {ntokens}\")\n","print(f\"  Embedding size: {embsize}\")\n","print(f\"  Number of layers: {nlayers}\")\n","print(f\"  Genes in vocab: {np.sum(gene_ids_in_vocab >= 0)}/{len(gene_ids_in_vocab)}\")\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V-ZJgaIY04gh","executionInfo":{"status":"ok","timestamp":1759726288333,"user_tz":300,"elapsed":55332,"user":{"displayName":"Zhexuan Liu","userId":"18073944608501350772"}},"outputId":"c875d12e-ea77-418c-d594-9d50677c2b2a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading pretrained model...\n","Loading pretrained param encoder.embedding.weight with shape torch.Size([60697, 512])\n","Loading pretrained param encoder.enc_norm.weight with shape torch.Size([512])\n","Loading pretrained param encoder.enc_norm.bias with shape torch.Size([512])\n","Loading pretrained param value_encoder.linear1.weight with shape torch.Size([512, 1])\n","Loading pretrained param value_encoder.linear1.bias with shape torch.Size([512])\n","Loading pretrained param value_encoder.linear2.weight with shape torch.Size([512, 512])\n","Loading pretrained param value_encoder.linear2.bias with shape torch.Size([512])\n","Loading pretrained param value_encoder.norm.weight with shape torch.Size([512])\n","Loading pretrained param value_encoder.norm.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n","Loading pretrained param transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])\n","Loading pretrained param transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])\n","Loading pretrained param transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])\n","Loading pretrained param transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])\n","Loading pretrained param transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n","Loading pretrained param transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])\n","Loading pretrained param transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])\n","Loading pretrained param transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])\n","Loading pretrained param transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])\n","Loading pretrained param transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n","Loading pretrained param transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])\n","Loading pretrained param transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])\n","Loading pretrained param transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])\n","Loading pretrained param transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])\n","Loading pretrained param transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n","Loading pretrained param transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])\n","Loading pretrained param transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])\n","Loading pretrained param transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])\n","Loading pretrained param transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])\n","Loading pretrained param transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n","Loading pretrained param transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])\n","Loading pretrained param transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])\n","Loading pretrained param transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])\n","Loading pretrained param transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])\n","Loading pretrained param transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n","Loading pretrained param transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])\n","Loading pretrained param transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])\n","Loading pretrained param transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])\n","Loading pretrained param transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])\n","Loading pretrained param transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n","Loading pretrained param transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])\n","Loading pretrained param transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])\n","Loading pretrained param transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])\n","Loading pretrained param transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])\n","Loading pretrained param transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n","Loading pretrained param transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])\n","Loading pretrained param transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])\n","Loading pretrained param transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])\n","Loading pretrained param transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])\n","Loading pretrained param transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n","Loading pretrained param transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])\n","Loading pretrained param transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])\n","Loading pretrained param transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])\n","Loading pretrained param transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])\n","Loading pretrained param transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n","Loading pretrained param transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])\n","Loading pretrained param transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])\n","Loading pretrained param transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])\n","Loading pretrained param transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])\n","Loading pretrained param transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n","Loading pretrained param transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])\n","Loading pretrained param transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])\n","Loading pretrained param transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])\n","Loading pretrained param transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])\n","Loading pretrained param transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n","Loading pretrained param transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])\n","Loading pretrained param transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])\n","Loading pretrained param transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])\n","Loading pretrained param transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])\n","Loading pretrained param transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])\n","Loading pretrained param transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])\n","Pretrained model loaded successfully!\n","Loading finetuned model...\n","Finetuned model loaded successfully!\n","Loading finetuned model...\n","Finetuned model loaded successfully!\n","Loading finetuned model...\n","Finetuned model loaded successfully!\n","Loading finetuned model...\n","Finetuned model loaded successfully!\n","Models ready for evaluation!\n"]}],"source":["# Create and load pretrained model\n","print(\"Loading pretrained model...\")\n","model_pretrain = TransformerGenerator(\n","    ntokens,\n","    embsize,\n","    nhead,\n","    d_hid,\n","    nlayers,\n","    nlayers_cls=n_layers_cls,\n","    n_cls=1,\n","    vocab=vocab,\n","    dropout=0,\n","    pad_token=pad_token,\n","    pad_value=pad_value,\n","    pert_pad_id=pert_pad_id,\n","    use_fast_transformer=True,\n",")\n","\n","# Load pretrained weights\n","model_dict = model_pretrain.state_dict()\n","pretrained_dict = torch.load(model_file)\n","pretrained_dict = {\n","    k: v for k, v in pretrained_dict.items()\n","    if any([k.startswith(prefix) for prefix in load_param_prefixs])\n","}\n","for k, v in pretrained_dict.items():\n","    print(f\"Loading pretrained param {k} with shape {v.shape}\")\n","model_dict.update(pretrained_dict)\n","model_pretrain.load_state_dict(model_dict)\n","model_pretrain.to(device)\n","model_pretrain.eval()\n","\n","print(\"Pretrained model loaded successfully!\")\n","\n","# Load finetuned model\n","print(\"Loading finetuned model...\")\n","model_finetune = TransformerGenerator(\n","    ntokens,\n","    embsize,\n","    nhead,\n","    d_hid,\n","    nlayers,\n","    nlayers_cls=n_layers_cls,\n","    n_cls=1,\n","    vocab=vocab,\n","    dropout=0,\n","    pad_token=pad_token,\n","    pad_value=pad_value,\n","    pert_pad_id=pert_pad_id,\n","    use_fast_transformer=True,\n",")\n","\n","# Try to load finetuned weights\n","finetuned_model_dir = Path(\"./save/scGPT_human_finetuned_adamson\")\n","finetuned_model_file = finetuned_model_dir / \"best_model.pt\"\n","\n","if finetuned_model_file.exists():\n","    try:\n","        model_finetune.load_state_dict(torch.load(finetuned_model_file))\n","        print(\"Finetuned model loaded successfully!\")\n","    except Exception as e:\n","        print(f\"Error loading finetuned model: {e}\")\n","        print(\"Using pretrained model for both comparisons...\")\n","        model_finetune = copy.deepcopy(model_pretrain)\n","else:\n","    print(\"Finetuned model not found. Using pretrained model for both comparisons...\")\n","    model_finetune = copy.deepcopy(model_pretrain)\n","\n","model_finetune.to(device)\n","model_finetune.eval()\n","\n","print(\"Loading finetuned model...\")\n","model_finetune_1 = TransformerGenerator(\n","    ntokens,\n","    embsize,\n","    nhead,\n","    d_hid,\n","    nlayers,\n","    nlayers_cls=n_layers_cls,\n","    n_cls=1,\n","    vocab=vocab,\n","    dropout=0,\n","    pad_token=pad_token,\n","    pad_value=pad_value,\n","    pert_pad_id=pert_pad_id,\n","    use_fast_transformer=True,\n",")\n","\n","# Try to load finetuned weights\n","finetuned_model_dir = Path(\"./save/scGPT_human_finetuned_adamson\")\n","finetuned_model_file = finetuned_model_dir / \"model_1.pt\"\n","\n","if finetuned_model_file.exists():\n","    model_finetune_1.load_state_dict(torch.load(finetuned_model_file))\n","    print(\"Finetuned model loaded successfully!\")\n","\n","model_finetune.to(device)\n","model_finetune.eval()\n","\n","print(\"Loading finetuned model...\")\n","model_finetune_2 = TransformerGenerator(\n","    ntokens,\n","    embsize,\n","    nhead,\n","    d_hid,\n","    nlayers,\n","    nlayers_cls=n_layers_cls,\n","    n_cls=1,\n","    vocab=vocab,\n","    dropout=0,\n","    pad_token=pad_token,\n","    pad_value=pad_value,\n","    pert_pad_id=pert_pad_id,\n","    use_fast_transformer=True,\n",")\n","\n","# Try to load finetuned weights\n","finetuned_model_dir = Path(\"./save/scGPT_human_finetuned_adamson\")\n","finetuned_model_file = finetuned_model_dir / \"model_2.pt\"\n","\n","if finetuned_model_file.exists():\n","    model_finetune_2.load_state_dict(torch.load(finetuned_model_file))\n","    print(\"Finetuned model loaded successfully!\")\n","\n","model_finetune_2.to(device)\n","model_finetune_2.eval()\n","\n","print(\"Loading finetuned model...\")\n","model_finetune_3 = TransformerGenerator(\n","    ntokens,\n","    embsize,\n","    nhead,\n","    d_hid,\n","    nlayers,\n","    nlayers_cls=n_layers_cls,\n","    n_cls=1,\n","    vocab=vocab,\n","    dropout=0,\n","    pad_token=pad_token,\n","    pad_value=pad_value,\n","    pert_pad_id=pert_pad_id,\n","    use_fast_transformer=True,\n",")\n","\n","# Try to load finetuned weights\n","finetuned_model_dir = Path(\"./save/scGPT_human_finetuned_adamson\")\n","finetuned_model_file = finetuned_model_dir / \"model_3.pt\"\n","\n","if finetuned_model_file.exists():\n","    model_finetune_3.load_state_dict(torch.load(finetuned_model_file))\n","    print(\"Finetuned model loaded successfully!\")\n","\n","model_finetune_3.to(device)\n","model_finetune_3.eval()\n","\n","print(\"Models ready for evaluation!\")\n"]},{"cell_type":"code","source":["def eval_perturb(\n","    loader: DataLoader, model: TransformerGenerator, device: torch.device\n",") -> Dict:\n","    \"\"\"\n","    Run model in inference mode using a given data loader\n","    \"\"\"\n","\n","    model.eval()\n","    model.to(device)\n","    pert_cat = []\n","    pred = []\n","    truth = []\n","    pred_de = []\n","    truth_de = []\n","    results = {}\n","    logvar = []\n","\n","    for itr, batch in enumerate(loader):\n","        batch.to(device)\n","        pert_cat.extend(batch.pert)\n","\n","        with torch.no_grad():\n","            p = model.pred_perturb(\n","                batch,\n","                include_zero_gene=include_zero_gene,\n","                gene_ids=gene_ids,\n","            )\n","            t = batch.y\n","            pred.extend(p.cpu())\n","            truth.extend(t.cpu())\n","\n","            # Differentially expressed genes\n","            for itr, de_idx in enumerate(batch.de_idx):\n","                pred_de.append(p[itr, de_idx])\n","                truth_de.append(t[itr, de_idx])\n","\n","    # all genes\n","    results[\"pert_cat\"] = np.array(pert_cat)\n","    pred = torch.stack(pred)\n","    truth = torch.stack(truth)\n","    results[\"pred\"] = pred.detach().cpu().numpy().astype(np.float64)\n","    results[\"truth\"] = truth.detach().cpu().numpy().astype(np.float64)\n","\n","    pred_de = torch.stack(pred_de)\n","    truth_de = torch.stack(truth_de)\n","    results[\"pred_de\"] = pred_de.detach().cpu().numpy().astype(np.float64)\n","    results[\"truth_de\"] = truth_de.detach().cpu().numpy().astype(np.float64)\n","\n","    return results\n","\n","train_loader = pert_data.dataloader[\"train_loader\"]\n","valid_loader = pert_data.dataloader[\"val_loader\"]\n","test_loader = pert_data.dataloader[\"test_loader\"]\n","\n","# train_res_pt = eval_perturb(train_loader, model_pretrain, device)\n","# train_metrics_pt = compute_perturbation_metrics(\n","#     train_res, pert_data.adata[pert_data.adata.obs[\"condition\"] == \"ctrl\"]\n","# )\n","# val_res_pt = eval_perturb(valid_loader, model_pretrain, device)\n","# val_metrics_pt = compute_perturbation_metrics(\n","#     val_res_pt, pert_data.adata[pert_data.adata.obs[\"condition\"] == \"ctrl\"]\n","# )\n","# test_res_pt = eval_perturb(test_loader, model_pretrain, device)\n","# test_metrics_pt = compute_perturbation_metrics(\n","#     test_res_pt, pert_data.adata[pert_data.adata.obs[\"condition\"] == \"ctrl\"]\n","# )\n","\n","# print(\"pretrain_done\")\n","\n","# # train_res_ft = eval_perturb(train_loader, model_finetune, device)\n","# # train_metrics_ft = compute_perturbation_metrics(\n","# #     train_res, pert_data.adata[pert_data.adata.obs[\"condition\"] == \"ctrl\"]\n","# # )\n","# val_res_ft = eval_perturb(valid_loader, model_finetune, device)\n","# val_metrics_ft = compute_perturbation_metrics(\n","#     val_res_ft, pert_data.adata[pert_data.adata.obs[\"condition\"] == \"ctrl\"]\n","# )\n","# test_res_ft = eval_perturb(test_loader, model_finetune, device)\n","# test_metrics_ft = compute_perturbation_metrics(\n","#     test_res_ft, pert_data.adata[pert_data.adata.obs[\"condition\"] == \"ctrl\"]\n","# )\n","\n","val_res_ft_1 = eval_perturb(valid_loader, model_finetune_1, device)\n","val_metrics_ft_1 = compute_perturbation_metrics(\n","    val_res_ft_1, pert_data.adata[pert_data.adata.obs[\"condition\"] == \"ctrl\"]\n",")\n","test_res_ft_1 = eval_perturb(test_loader, model_finetune_1, device)\n","test_metrics_ft_1 = compute_perturbation_metrics(\n","    test_res_ft_1, pert_data.adata[pert_data.adata.obs[\"condition\"] == \"ctrl\"]\n",")\n","val_res_ft_2 = eval_perturb(valid_loader, model_finetune_2, device)\n","val_metrics_ft_2 = compute_perturbation_metrics(\n","    val_res_ft_2, pert_data.adata[pert_data.adata.obs[\"condition\"] == \"ctrl\"]\n",")\n","test_res_ft_2 = eval_perturb(test_loader, model_finetune_2, device)\n","test_metrics_ft_2 = compute_perturbation_metrics(\n","    test_res_ft_2, pert_data.adata[pert_data.adata.obs[\"condition\"] == \"ctrl\"]\n",")\n","val_res_ft_3 = eval_perturb(valid_loader, model_finetune_3, device)\n","val_metrics_ft_3 = compute_perturbation_metrics(\n","    val_res_ft_3, pert_data.adata[pert_data.adata.obs[\"condition\"] == \"ctrl\"]\n",")\n","test_res_ft_3 = eval_perturb(test_loader, model_finetune_3, device)\n","test_metrics_ft_3 = compute_perturbation_metrics(\n","    test_res_ft_3, pert_data.adata[pert_data.adata.obs[\"condition\"] == \"ctrl\"]\n",")"],"metadata":{"id":"yb304_CgJvsQ","executionInfo":{"status":"ok","timestamp":1759728234214,"user_tz":300,"elapsed":1945358,"user":{"displayName":"Zhexuan Liu","userId":"18073944608501350772"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# print(\"Pretrained model evaluation:\")\n","# # print(train_metrics_pt)\n","# print(val_metrics_pt)\n","# print(test_metrics_pt)\n","print(\"Finetuned model evaluation:\")\n","# print(train_metrics_ft)\n","print(val_metrics_ft_1)\n","print(test_metrics_ft_1)\n","print(val_metrics_ft_2)\n","print(test_metrics_ft_2)\n","print(val_metrics_ft_3)\n","print(test_metrics_ft_3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2duyxhapOLg2","executionInfo":{"status":"ok","timestamp":1759728797229,"user_tz":300,"elapsed":12,"user":{"displayName":"Zhexuan Liu","userId":"18073944608501350772"}},"outputId":"9bcb8d5a-ffd6-42b4-8dea-8a8b68ea818f"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Finetuned model evaluation:\n","{'pearson': np.float64(0.9896269943999882), 'pearson_de': np.float64(0.9521256939986291), 'pearson_delta': np.float64(0.6753658892400664), 'pearson_de_delta': np.float64(0.8529479473134424)}\n","{'pearson': np.float64(0.9896935866254931), 'pearson_de': np.float64(0.9761265028642859), 'pearson_delta': np.float64(0.6144568934466045), 'pearson_de_delta': np.float64(0.7843722436192774)}\n","{'pearson': np.float64(0.9885673434077875), 'pearson_de': np.float64(0.951038533174156), 'pearson_delta': np.float64(0.6779508353636224), 'pearson_de_delta': np.float64(0.8316920311951698)}\n","{'pearson': np.float64(0.9879044377188347), 'pearson_de': np.float64(0.9777859879099342), 'pearson_delta': np.float64(0.6086645358469214), 'pearson_de_delta': np.float64(0.788025265996234)}\n","{'pearson': np.float64(0.9890670983461928), 'pearson_de': np.float64(0.9441912344049294), 'pearson_delta': np.float64(0.6562050765776121), 'pearson_de_delta': np.float64(0.8109449165672137)}\n","{'pearson': np.float64(0.9897986912428371), 'pearson_de': np.float64(0.9779035239598389), 'pearson_delta': np.float64(0.6136638074586108), 'pearson_de_delta': np.float64(0.7966908166875661)}\n"]}]},{"cell_type":"code","source":["val_metrics"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fhwZc--6NMkM","executionInfo":{"status":"ok","timestamp":1759715504430,"user_tz":300,"elapsed":48,"user":{"displayName":"Zhexuan Liu","userId":"18073944608501350772"}},"outputId":"e2eead53-5b0b-4445-f397-f33d08eb36cd"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'pearson': np.float64(0.9905728379185182),\n"," 'pearson_de': np.float64(0.9530412024051579),\n"," 'pearson_delta': np.float64(0.7030412970266849),\n"," 'pearson_de_delta': np.float64(0.8525051671989553)}"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["# Saliency Map\n"],"metadata":{"id":"7FfidODyqgNH"}},{"cell_type":"code","source":["pert_data.adata.obs[\"condition\"].unique()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6OBVQNZgBiOs","executionInfo":{"status":"ok","timestamp":1759729087349,"user_tz":300,"elapsed":51,"user":{"displayName":"Zhexuan Liu","userId":"18073944608501350772"}},"outputId":"12fecb99-b024-48e0-a7ee-b20aa1efb5bc"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['CREB1+ctrl', 'ctrl', 'ZNF326+ctrl', 'BHLHE40+ctrl', 'DDIT3+ctrl', ..., 'CARS+ctrl', 'TMED2+ctrl', 'P4HB+ctrl', 'SPCS3+ctrl', 'SPCS2+ctrl']\n","Length: 87\n","Categories (88, object): ['AARS+ctrl', 'AMIGO3+ctrl', 'ARHGAP22+ctrl', 'ASCC3+ctrl', ...,\n","                          'XRN1+ctrl', 'YIPF5+ctrl', 'ZNF326+ctrl', 'ctrl']"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["def compute_saliency_map_for_perturbation_prediction(model, pert_data, pert_condition, target_gene_idx=None, n_cells=5):\n","    \"\"\"\n","    Compute saliency map for perturbation expression prediction using model.pred_perturb().\n","    \"\"\"\n","    model.eval()\n","\n","    # Get cells from the specific perturbation condition\n","    pert_cells = pert_data.adata[pert_data.adata.obs[\"condition\"] == pert_condition]\n","\n","    if pert_cells.shape[0] == 0:\n","        print(f\"No cells found for perturbation: {pert_condition}\")\n","        return None\n","\n","    # Sample cells from this perturbation\n","    n_available = min(n_cells, pert_cells.shape[0])\n","    sample_indices = np.random.choice(pert_cells.shape[0], n_available, replace=False)\n","    sampled_cells = pert_cells[sample_indices, :]\n","\n","    print(f\"Analyzing {n_available} cells from perturbation: {pert_condition}\")\n","\n","    saliency_results = {\n","        'pert_condition': pert_condition,\n","        'n_cells': n_available,\n","        'cell_saliencies': [],\n","        'average_saliency': None,\n","        'gene_names': genes\n","    }\n","\n","    # Process each cell\n","    for cell_idx in range(n_available):\n","        print(f\"Processing cell {cell_idx + 1}/{n_available}\")\n","\n","        try:\n","            # Get expression values for this cell\n","            cell_expr = sampled_cells.X[cell_idx].toarray().flatten()  # [n_genes]\n","\n","            # Create input tensors - use float32 to avoid Flash Attention issues\n","            input_values = torch.tensor(cell_expr, dtype=torch.float32, device=device, requires_grad=True)\n","\n","            # Create a batch-like structure for pred_perturb\n","            # We need to create the proper batch format that pred_perturb expects\n","            batch_size = 1\n","            n_genes = len(input_values)\n","\n","            # Create the batch structure similar to what GEARS creates\n","            # pred_perturb expects a batch with specific attributes\n","            class PerturbBatch:\n","                def __init__(self, x, y, pert, de_idx):\n","                    self.x = x  # [batch_size * n_genes, 2] - expression values and perturbation flags\n","                    self.y = y  # [batch_size, n_genes] - target values\n","                    self.pert = pert  # perturbation names\n","                    self.de_idx = de_idx  # differentially expressed gene indices\n","                    self.to = self.to_device\n","\n","                def to_device(self, device):\n","                    self.x = self.x.to(device)\n","                    self.y = self.y.to(device)\n","                    return self\n","\n","            # Create perturbation flags (all zeros for now)\n","            pert_flags = torch.zeros_like(input_values)\n","\n","            # Stack expression values and perturbation flags\n","            x_data = torch.stack([input_values, pert_flags], dim=1)  # [n_genes, 2]\n","            x_data = x_data.unsqueeze(0)  # [1, n_genes, 2]\n","            x_data = x_data.view(-1, 2)  # [n_genes, 2] - this is what pred_perturb expects\n","\n","            # Create dummy target (we don't need it for saliency)\n","            y_data = torch.zeros(batch_size, n_genes, device=device)\n","\n","            # Create batch\n","            batch = PerturbBatch(x_data, y_data, [pert_condition], [[]])\n","            batch = batch.to(device)\n","\n","            # Forward pass using pred_perturb\n","            predicted_expression = model.pred_perturb(\n","                batch,\n","                include_zero_gene=\"all\",  # or whatever setting you want\n","                gene_ids=gene_ids,\n","            )  # [batch_size, n_genes]\n","\n","            if target_gene_idx is not None:\n","                # Compute saliency for specific target gene\n","                target_output = predicted_expression[0, target_gene_idx]\n","                target_output.backward(retain_graph=True)\n","\n","                gradients = input_values.grad  # [n_genes]\n","                saliency = torch.abs(gradients).detach().cpu().numpy()\n","\n","            else:\n","                # Compute saliency averaged across all predicted genes\n","                saliency_maps = []\n","                for gene_idx in range(n_genes):\n","                    # Zero gradients\n","                    if input_values.grad is not None:\n","                        input_values.grad.zero_()\n","\n","                    gene_output = predicted_expression[0, gene_idx]\n","                    gene_output.backward(retain_graph=True)\n","\n","                    gradients = input_values.grad\n","                    saliency = torch.abs(gradients).detach().cpu().numpy()\n","                    saliency_maps.append(saliency)\n","\n","                # Average across all genes\n","                saliency = np.mean(saliency_maps, axis=0)\n","\n","            saliency_results['cell_saliencies'].append({\n","                'cell_idx': cell_idx,\n","                'saliency': saliency,\n","                'expression': cell_expr,\n","                'predicted_expression': predicted_expression[0].detach().cpu().numpy()\n","            })\n","\n","        except Exception as e:\n","            print(f\"Error processing cell {cell_idx + 1}: {e}\")\n","            import traceback\n","            traceback.print_exc()\n","            continue\n","\n","    if not saliency_results['cell_saliencies']:\n","        print(\"No cells processed successfully\")\n","        return None\n","\n","    # Compute average saliency across cells\n","    all_saliencies = np.array([cell['saliency'] for cell in saliency_results['cell_saliencies']])\n","    average_saliency = np.mean(all_saliencies, axis=0)\n","    saliency_results['average_saliency'] = average_saliency\n","\n","    return saliency_results\n","\n","# Usage example:\n","pert_condition = 'CREB1+ctrl'\n","print(f\"Computing saliency maps for perturbation prediction: {pert_condition}\")\n","\n","saliency_results = compute_saliency_map_for_perturbation_prediction(\n","    model_finetune,  # Use your model (not model_finetune)\n","    pert_data,\n","    pert_condition,\n","    target_gene_idx=None,\n","    n_cells=1\n",")\n","\n","if saliency_results:\n","    # Analyze results\n","    average_saliency = saliency_results['average_saliency']\n","    gene_names = saliency_results['gene_names']\n","\n","    # Get top contributing genes\n","    top_indices = np.argsort(average_saliency)[-15:][::-1]\n","    top_genes = [gene_names[idx] for idx in top_indices]\n","    top_saliency = average_saliency[top_indices]\n","\n","    print(f\"\\nTop 15 genes by average saliency for {pert_condition}:\")\n","    for gene, sal_val in zip(top_genes, top_saliency):\n","        print(f\"  {gene}: {sal_val:.6f}\")\n","\n","    # Check if the perturbed gene itself has high saliency\n","    # Parse perturbation to get actual gene name\n","    if \"+\" in pert_condition:\n","        pert_genes = [g for g in pert_condition.split(\"+\") if g != \"ctrl\"]\n","    else:\n","        pert_genes = [pert_condition]\n","\n","    for pert_gene in pert_genes:\n","        if pert_gene in gene_names:\n","            pert_gene_idx = gene_names.index(pert_gene)\n","            pert_gene_saliency = average_saliency[pert_gene_idx]\n","            pert_rank = np.sum(average_saliency > pert_gene_saliency) + 1\n","            pert_percentile = (1 - (pert_rank - 1) / len(average_saliency)) * 100\n","\n","            print(f\"\\nPerturbed gene {pert_gene}:\")\n","            print(f\"  Saliency score: {pert_gene_saliency:.6f}\")\n","            print(f\"  Rank: {pert_rank}/{len(average_saliency)} ({pert_percentile:.1f}th percentile)\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M_7Z-h84qiCk","executionInfo":{"status":"ok","timestamp":1759730585289,"user_tz":300,"elapsed":263320,"user":{"displayName":"Zhexuan Liu","userId":"18073944608501350772"}},"outputId":"efe2b2cc-7072-4fd4-b461-11f95f77578a"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Computing saliency maps for perturbation prediction: CREB1+ctrl\n","Analyzing 1 cells from perturbation: CREB1+ctrl\n","Processing cell 1/1\n","\n","Top 15 genes by average saliency for CREB1+ctrl:\n","  SRP68: 0.001279\n","  H2AFZ: 0.001221\n","  CTSC: 0.000703\n","  SNHG8: 0.000626\n","  H3F3B: 0.000591\n","  GMPR: 0.000578\n","  RPS29: 0.000560\n","  TCEAL8: 0.000505\n","  THAP7-AS1: 0.000460\n","  ATP5B: 0.000447\n","  CCDC85B: 0.000440\n","  ARGLU1: 0.000430\n","  HIST1H4C: 0.000423\n","  APOE: 0.000392\n","  ATP6V0B: 0.000379\n","\n","Perturbed gene CREB1:\n","  Saliency score: 0.000107\n","  Rank: 5055/5060 (0.1th percentile)\n"]}]},{"cell_type":"code","source":["def compute_saliency_for_specific_target_gene(model, pert_data, pert_condition, target_gene_name, n_cells=5):\n","    \"\"\"\n","    Compute saliency map for predicting a specific target gene's expression.\n","    \"\"\"\n","    model.eval()\n","\n","    # Get cells from the specific perturbation condition\n","    pert_cells = pert_data.adata[pert_data.adata.obs[\"condition\"] == pert_condition]\n","\n","    if pert_cells.shape[0] == 0:\n","        print(f\"No cells found for perturbation: {pert_condition}\")\n","        return None\n","\n","    # Find target gene index\n","    if target_gene_name not in genes:\n","        print(f\"Target gene {target_gene_name} not found in gene list\")\n","        return None\n","\n","    target_gene_idx = genes.index(target_gene_name)\n","    print(f\"Target gene {target_gene_name} at index {target_gene_idx}\")\n","\n","    # Sample cells from this perturbation\n","    n_available = min(n_cells, pert_cells.shape[0])\n","    sample_indices = np.random.choice(pert_cells.shape[0], n_available, replace=False)\n","    sampled_cells = pert_cells[sample_indices, :]\n","\n","    print(f\"Analyzing {n_available} cells for predicting {target_gene_name} expression\")\n","\n","    saliency_results = {\n","        'pert_condition': pert_condition,\n","        'target_gene': target_gene_name,\n","        'target_gene_idx': target_gene_idx,\n","        'n_cells': n_available,\n","        'cell_saliencies': [],\n","        'average_saliency': None,\n","        'gene_names': genes\n","    }\n","\n","    # Process each cell\n","    for cell_idx in range(n_available):\n","        print(f\"Processing cell {cell_idx + 1}/{n_available}\")\n","\n","        try:\n","            # Get expression values for this cell\n","            cell_expr = sampled_cells.X[cell_idx].toarray().flatten()  # [n_genes]\n","\n","            # Create input tensors\n","            input_values = torch.tensor(cell_expr, dtype=torch.float32, device=device, requires_grad=True)\n","\n","            # Create batch structure for pred_perturb\n","            class PerturbBatch:\n","                def __init__(self, x, y, pert, de_idx):\n","                    self.x = x\n","                    self.y = y\n","                    self.pert = pert\n","                    self.de_idx = de_idx\n","                    self.to = self.to_device\n","\n","                def to_device(self, device):\n","                    self.x = self.x.to(device)\n","                    self.y = self.y.to(device)\n","                    return self\n","\n","            # Create perturbation flags\n","            pert_flags = torch.zeros_like(input_values)\n","\n","            # Stack expression values and perturbation flags\n","            x_data = torch.stack([input_values, pert_flags], dim=1)  # [n_genes, 2]\n","            x_data = x_data.unsqueeze(0)  # [1, n_genes, 2]\n","            x_data = x_data.view(-1, 2)  # [n_genes, 2]\n","\n","            # Create dummy target\n","            y_data = torch.zeros(1, len(input_values), device=device)\n","\n","            # Create batch\n","            batch = PerturbBatch(x_data, y_data, [pert_condition], [[]])\n","            batch = batch.to(device)\n","\n","            # Forward pass using pred_perturb\n","            predicted_expression = model.pred_perturb(\n","                batch,\n","                include_zero_gene=\"all\",\n","                gene_ids=gene_ids,\n","            )  # [1, n_genes]\n","\n","            # Compute saliency for the specific target gene\n","            target_output = predicted_expression[0, target_gene_idx]\n","            target_output.backward(retain_graph=True)\n","\n","            gradients = input_values.grad  # [n_genes]\n","            saliency = torch.abs(gradients).detach().cpu().numpy()\n","\n","            saliency_results['cell_saliencies'].append({\n","                'cell_idx': cell_idx,\n","                'saliency': saliency,\n","                'expression': cell_expr,\n","                'target_prediction': target_output.detach().cpu().item()\n","            })\n","\n","        except Exception as e:\n","            print(f\"Error processing cell {cell_idx + 1}: {e}\")\n","            continue\n","\n","    if not saliency_results['cell_saliencies']:\n","        print(\"No cells processed successfully\")\n","        return None\n","\n","    # Compute average saliency across cells\n","    all_saliencies = np.array([cell['saliency'] for cell in saliency_results['cell_saliencies']])\n","    average_saliency = np.mean(all_saliencies, axis=0)\n","    saliency_results['average_saliency'] = average_saliency\n","\n","    return saliency_results\n","\n","def analyze_creb1_interactions(model, pert_data, pert_condition=\"CREB1+ctrl\"):\n","    \"\"\"\n","    Analyze CREB1's saliency when predicting genes that interact with CREB1.\n","    \"\"\"\n","    # Genes known to interact with CREB1 (you can expand this list)\n","    # These are examples - you should use a proper protein-protein interaction database\n","    creb1_interacting_genes = [\n","        \"FOS\",      # Immediate early gene, activated by CREB1\n","        \"JUN\",      # Part of AP-1 complex with FOS\n","        \"EGR1\",     # Early growth response protein\n","        \"BDNF\",     # Brain-derived neurotrophic factor\n","        \"NR4A1\",    # Nuclear receptor\n","        \"ATF3\",     # Activating transcription factor 3\n","        \"FOSB\",     # FosB proto-oncogene\n","        \"JUNB\",     # JunB proto-oncogene\n","        \"JUND\",     # JunD proto-oncogene\n","        \"ATF4\",     # Activating transcription factor 4\n","    ]\n","\n","    # Filter to genes that exist in our dataset\n","    available_interacting_genes = [gene for gene in creb1_interacting_genes if gene in genes]\n","    print(f\"Found {len(available_interacting_genes)} CREB1-interacting genes in dataset: {available_interacting_genes}\")\n","\n","    results = {}\n","\n","    for target_gene in available_interacting_genes:\n","        print(f\"\\n{'='*60}\")\n","        print(f\"Analyzing saliency for predicting {target_gene} expression\")\n","        print(f\"{'='*60}\")\n","\n","        saliency_results = compute_saliency_for_specific_target_gene(\n","            model, pert_data, pert_condition, target_gene, n_cells=5\n","        )\n","\n","        if saliency_results:\n","            average_saliency = saliency_results['average_saliency']\n","            gene_names = saliency_results['gene_names']\n","\n","            # Get CREB1's saliency score\n","            creb1_idx = genes.index(\"CREB1\")\n","            creb1_saliency = average_saliency[creb1_idx]\n","\n","            # Get top contributing genes\n","            top_indices = np.argsort(average_saliency)[-10:][::-1]\n","            top_genes = [gene_names[idx] for idx in top_indices]\n","            top_saliency = average_saliency[top_indices]\n","\n","            # Check CREB1's rank\n","            creb1_rank = np.sum(average_saliency > creb1_saliency) + 1\n","            creb1_percentile = (1 - (creb1_rank - 1) / len(average_saliency)) * 100\n","\n","            print(f\"\\nTop 10 genes by saliency for predicting {target_gene}:\")\n","            for i, (gene, sal_val) in enumerate(zip(top_genes, top_saliency)):\n","                marker = \"***\" if gene == \"CREB1\" else \"\"\n","                print(f\"  {i+1:2d}. {gene:<10} {sal_val:.6f} {marker}\")\n","\n","            print(f\"\\nCREB1 saliency for predicting {target_gene}:\")\n","            print(f\"  Score: {creb1_saliency:.6f}\")\n","            print(f\"  Rank: {creb1_rank}/{len(average_saliency)} ({creb1_percentile:.1f}th percentile)\")\n","\n","            if creb1_rank <= 10:\n","                print(f\"  *** CREB1 is in top 10 most influential genes! ***\")\n","\n","            results[target_gene] = {\n","                'creb1_saliency': creb1_saliency,\n","                'creb1_rank': creb1_rank,\n","                'creb1_percentile': creb1_percentile,\n","                'top_genes': top_genes,\n","                'top_saliency': top_saliency\n","            }\n","\n","    return results\n","\n","# Run the analysis\n","print(\"Analyzing CREB1 interactions with target genes...\")\n","interaction_results = analyze_creb1_interactions(model_finetune, pert_data, \"CREB1+ctrl\")\n","\n","# Summary\n","print(f\"\\n{'='*80}\")\n","print(\"SUMMARY: CREB1's influence on predicting interacting genes\")\n","print(f\"{'='*80}\")\n","\n","for target_gene, result in interaction_results.items():\n","    rank = result['creb1_rank']\n","    percentile = result['creb1_percentile']\n","    saliency = result['creb1_saliency']\n","\n","    status = \"HIGH INFLUENCE\" if rank <= 10 else \"LOW INFLUENCE\"\n","    print(f\"{target_gene:<10}: Rank {rank:4d} ({percentile:5.1f}th percentile) - {status}\")\n","    print(f\"            Saliency: {saliency:.6f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MGFVPUOeJw1S","executionInfo":{"status":"ok","timestamp":1759731209372,"user_tz":300,"elapsed":3612,"user":{"displayName":"Zhexuan Liu","userId":"18073944608501350772"}},"outputId":"627ad53c-3228-4846-ad68-49aa500599a2"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Analyzing CREB1 interactions with target genes...\n","Found 9 CREB1-interacting genes in dataset: ['FOS', 'JUN', 'EGR1', 'NR4A1', 'ATF3', 'FOSB', 'JUNB', 'JUND', 'ATF4']\n","\n","============================================================\n","Analyzing saliency for predicting FOS expression\n","============================================================\n","Target gene FOS at index 3623\n","Analyzing 5 cells for predicting FOS expression\n","Processing cell 1/5\n","Processing cell 2/5\n","Processing cell 3/5\n","Processing cell 4/5\n","Processing cell 5/5\n","\n","Top 10 genes by saliency for predicting FOS:\n","   1. FOS        0.555212 \n","   2. RP11-115C21.2 0.001509 \n","   3. STMN4      0.000702 \n","   4. S100A1     0.000612 \n","   5. H2AFZ      0.000433 \n","   6. DDIT3      0.000419 \n","   7. CDK1       0.000415 \n","   8. ATP5E      0.000353 \n","   9. RGS14      0.000322 \n","  10. HIST1H4C   0.000269 \n","\n","CREB1 saliency for predicting FOS:\n","  Score: 0.000000\n","  Rank: 4269/5060 (15.7th percentile)\n","\n","============================================================\n","Analyzing saliency for predicting JUN expression\n","============================================================\n","Target gene JUN at index 200\n","Analyzing 5 cells for predicting JUN expression\n","Processing cell 1/5\n","Processing cell 2/5\n","Processing cell 3/5\n","Processing cell 4/5\n","Processing cell 5/5\n","\n","Top 10 genes by saliency for predicting JUN:\n","   1. JUN        0.540596 \n","   2. SRP68      0.001380 \n","   3. RPS29      0.000911 \n","   4. RGS14      0.000589 \n","   5. SEC61B     0.000501 \n","   6. RP11-115C21.2 0.000501 \n","   7. RPS16      0.000366 \n","   8. THAP7-AS1  0.000351 \n","   9. KMT2E      0.000313 \n","  10. HIST1H2BK  0.000295 \n","\n","CREB1 saliency for predicting JUN:\n","  Score: 0.000002\n","  Rank: 3011/5060 (40.5th percentile)\n","\n","============================================================\n","Analyzing saliency for predicting EGR1 expression\n","============================================================\n","Target gene EGR1 at index 1597\n","Analyzing 5 cells for predicting EGR1 expression\n","Processing cell 1/5\n","Processing cell 2/5\n","Processing cell 3/5\n","Processing cell 4/5\n","Processing cell 5/5\n","\n","Top 10 genes by saliency for predicting EGR1:\n","   1. EGR1       0.541077 \n","   2. SRP68      0.001496 \n","   3. S100A1     0.000781 \n","   4. RGS14      0.000691 \n","   5. THAP7-AS1  0.000634 \n","   6. RP11-115C21.2 0.000565 \n","   7. ASXL2      0.000559 \n","   8. RPS29      0.000388 \n","   9. WDR36      0.000363 \n","  10. SEC61B     0.000312 \n","\n","CREB1 saliency for predicting EGR1:\n","  Score: 0.000001\n","  Rank: 4278/5060 (15.5th percentile)\n","\n","============================================================\n","Analyzing saliency for predicting NR4A1 expression\n","============================================================\n","Target gene NR4A1 at index 3252\n","Analyzing 5 cells for predicting NR4A1 expression\n","Processing cell 1/5\n","Processing cell 2/5\n","Processing cell 3/5\n","Processing cell 4/5\n","Processing cell 5/5\n","\n","Top 10 genes by saliency for predicting NR4A1:\n","   1. NR4A1      0.537112 \n","   2. HIST1H2BK  0.001445 \n","   3. SDF2L1     0.000763 \n","   4. ARPC5      0.000451 \n","   5. RP11-115C21.2 0.000433 \n","   6. S100A1     0.000382 \n","   7. STMN4      0.000341 \n","   8. ATP5B      0.000319 \n","   9. ATP5E      0.000318 \n","  10. HIST1H1C   0.000302 \n","\n","CREB1 saliency for predicting NR4A1:\n","  Score: 0.000001\n","  Rank: 3525/5060 (30.4th percentile)\n","\n","============================================================\n","Analyzing saliency for predicting ATF3 expression\n","============================================================\n","Target gene ATF3 at index 531\n","Analyzing 5 cells for predicting ATF3 expression\n","Processing cell 1/5\n","Processing cell 2/5\n","Processing cell 3/5\n","Processing cell 4/5\n","Processing cell 5/5\n","\n","Top 10 genes by saliency for predicting ATF3:\n","   1. ATF3       0.549253 \n","   2. HIST1H2BK  0.002509 \n","   3. HIST1H4C   0.001352 \n","   4. UFD1L      0.001274 \n","   5. RP11-115C21.2 0.001105 \n","   6. STT3A      0.000950 \n","   7. RPS29      0.000698 \n","   8. SEC61B     0.000691 \n","   9. ATP5B      0.000669 \n","  10. ATP6V0B    0.000647 \n","\n","CREB1 saliency for predicting ATF3:\n","  Score: 0.000002\n","  Rank: 3187/5060 (37.0th percentile)\n","\n","============================================================\n","Analyzing saliency for predicting FOSB expression\n","============================================================\n","Target gene FOSB at index 4775\n","Analyzing 5 cells for predicting FOSB expression\n","Processing cell 1/5\n","Processing cell 2/5\n","Processing cell 3/5\n","Processing cell 4/5\n","Processing cell 5/5\n","\n","Top 10 genes by saliency for predicting FOSB:\n","   1. FOSB       0.568597 \n","   2. KLK1       0.000443 \n","   3. SNHG8      0.000328 \n","   4. CAP1       0.000262 \n","   5. RP11-115C21.2 0.000240 \n","   6. RPS29      0.000195 \n","   7. XBP1       0.000193 \n","   8. HIST1H2BK  0.000184 \n","   9. CTSC       0.000181 \n","  10. ARPC5      0.000181 \n","\n","CREB1 saliency for predicting FOSB:\n","  Score: 0.000000\n","  Rank: 3435/5060 (32.1th percentile)\n","\n","============================================================\n","Analyzing saliency for predicting JUNB expression\n","============================================================\n","Target gene JUNB at index 4645\n","Analyzing 5 cells for predicting JUNB expression\n","Processing cell 1/5\n","Processing cell 2/5\n","Processing cell 3/5\n","Processing cell 4/5\n","Processing cell 5/5\n","\n","Top 10 genes by saliency for predicting JUNB:\n","   1. JUNB       0.560986 \n","   2. EEF1A1     0.002533 \n","   3. S100A1     0.001742 \n","   4. THAP7-AS1  0.001249 \n","   5. HBA1       0.001178 \n","   6. AGO1       0.001012 \n","   7. SRP68      0.000920 \n","   8. SEC61B     0.000895 \n","   9. PITX1      0.000670 \n","  10. TET1       0.000663 \n","\n","CREB1 saliency for predicting JUNB:\n","  Score: 0.000002\n","  Rank: 2985/5060 (41.0th percentile)\n","\n","============================================================\n","Analyzing saliency for predicting JUND expression\n","============================================================\n","Target gene JUND at index 4682\n","Analyzing 5 cells for predicting JUND expression\n","Processing cell 1/5\n","Processing cell 2/5\n","Processing cell 3/5\n","Processing cell 4/5\n","Processing cell 5/5\n","\n","Top 10 genes by saliency for predicting JUND:\n","   1. JUND       0.561559 \n","   2. RPS29      0.001294 \n","   3. S100A1     0.001246 \n","   4. SLC35B1    0.000662 \n","   5. THAP7-AS1  0.000636 \n","   6. SEC61B     0.000618 \n","   7. CCM2       0.000597 \n","   8. HBA1       0.000453 \n","   9. KLK1       0.000428 \n","  10. EEF1A1     0.000418 \n","\n","CREB1 saliency for predicting JUND:\n","  Score: 0.000002\n","  Rank: 3706/5060 (26.8th percentile)\n","\n","============================================================\n","Analyzing saliency for predicting ATF4 expression\n","============================================================\n","Target gene ATF4 at index 4961\n","Analyzing 5 cells for predicting ATF4 expression\n","Processing cell 1/5\n","Processing cell 2/5\n","Processing cell 3/5\n","Processing cell 4/5\n","Processing cell 5/5\n","\n","Top 10 genes by saliency for predicting ATF4:\n","   1. ATF4       0.606714 \n","   2. TET1       0.004640 \n","   3. SRP68      0.003269 \n","   4. RPL32      0.002391 \n","   5. RPS8       0.002114 \n","   6. SEC61B     0.002106 \n","   7. RPS16      0.002074 \n","   8. RPS27A     0.001781 \n","   9. RPL14      0.001780 \n","  10. RPL28      0.001677 \n","\n","CREB1 saliency for predicting ATF4:\n","  Score: 0.000003\n","  Rank: 4006/5060 (20.8th percentile)\n","\n","================================================================================\n","SUMMARY: CREB1's influence on predicting interacting genes\n","================================================================================\n","FOS       : Rank 4269 ( 15.7th percentile) - LOW INFLUENCE\n","            Saliency: 0.000000\n","JUN       : Rank 3011 ( 40.5th percentile) - LOW INFLUENCE\n","            Saliency: 0.000002\n","EGR1      : Rank 4278 ( 15.5th percentile) - LOW INFLUENCE\n","            Saliency: 0.000001\n","NR4A1     : Rank 3525 ( 30.4th percentile) - LOW INFLUENCE\n","            Saliency: 0.000001\n","ATF3      : Rank 3187 ( 37.0th percentile) - LOW INFLUENCE\n","            Saliency: 0.000002\n","FOSB      : Rank 3435 ( 32.1th percentile) - LOW INFLUENCE\n","            Saliency: 0.000000\n","JUNB      : Rank 2985 ( 41.0th percentile) - LOW INFLUENCE\n","            Saliency: 0.000002\n","JUND      : Rank 3706 ( 26.8th percentile) - LOW INFLUENCE\n","            Saliency: 0.000002\n","ATF4      : Rank 4006 ( 20.8th percentile) - LOW INFLUENCE\n","            Saliency: 0.000003\n"]}]}],"metadata":{"language_info":{"name":"python"},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}