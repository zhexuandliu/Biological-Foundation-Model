{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# scGPT Saliency vs Gene Interactions - Simple Analysis\n",
        "\n",
        "This notebook performs a straightforward analysis to answer:\n",
        "**Do genes with known interactions (from STRING database) have higher saliency scores in scGPT predictions?**\n",
        "\n",
        "## Approach\n",
        "1. Load scGPT model and compute saliency maps\n",
        "2. Load STRING gene interaction network\n",
        "3. Divide gene pairs into two groups:\n",
        "   - Group 1: Gene pairs WITH interaction (from STRING)\n",
        "   - Group 2: Gene pairs WITHOUT interaction\n",
        "4. Compare saliency distributions using boxplots\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup for Google Colab\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/MyDrive/GitHub/Biological-Foundation-Model/notebooks/scGPT_finetune')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "%pip install -q scgpt\n",
        "%pip install -q gears\n",
        "%pip install -q scanpy\n",
        "%pip install -q scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "from pathlib import Path\n",
        "import json\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# scGPT imports\n",
        "from scgpt.model import TransformerGenerator\n",
        "from scgpt.tokenizer.gene_tokenizer import GeneVocab\n",
        "from scgpt.utils import set_seed\n",
        "\n",
        "# Data loading\n",
        "from gears import PertData\n",
        "\n",
        "# Set device and seed\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "set_seed(42)\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load scGPT Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model configuration - UPDATE PATHS AS NEEDED\n",
        "model_dir = Path(\"./save/scGPT_human\")\n",
        "model_config_file = model_dir / \"args.json\"\n",
        "model_file = model_dir / \"best_model.pt\"\n",
        "vocab_file = model_dir / \"vocab.json\"\n",
        "\n",
        "# Load vocabulary\n",
        "vocab = GeneVocab.from_file(vocab_file)\n",
        "for s in [\"<pad>\", \"<cls>\", \"<eoc>\"]:\n",
        "    if s not in vocab:\n",
        "        vocab.append_token(s)\n",
        "\n",
        "print(f\"Vocabulary size: {len(vocab)}\")\n",
        "\n",
        "# Load model configuration\n",
        "with open(model_config_file, \"r\") as f:\n",
        "    model_configs = json.load(f)\n",
        "\n",
        "# Model parameters\n",
        "ntokens = len(vocab)\n",
        "embsize = model_configs[\"embsize\"]\n",
        "nhead = model_configs[\"nheads\"]\n",
        "d_hid = model_configs[\"d_hid\"]\n",
        "nlayers = model_configs[\"nlayers\"]\n",
        "n_layers_cls = model_configs[\"n_layers_cls\"]\n",
        "\n",
        "print(f\"Model: {embsize}D, {nlayers} layers, {nhead} heads\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load perturbation data\n",
        "pert_data = PertData(\"../../data\")\n",
        "pert_data.load(data_name=\"adamson\")\n",
        "pert_data.prepare_split(split=\"simulation\", seed=1)\n",
        "\n",
        "# Get gene list\n",
        "genes = pert_data.adata.var[\"gene_name\"].tolist()\n",
        "gene_ids = np.array([vocab[gene] if gene in vocab else vocab[\"<pad>\"] for gene in genes], dtype=int)\n",
        "\n",
        "print(f\"Total genes: {len(genes)}\")\n",
        "print(f\"Genes in vocab: {sum([1 for g in genes if g in vocab])}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize and load model\n",
        "model = TransformerGenerator(\n",
        "    ntokens, embsize, nhead, d_hid, nlayers,\n",
        "    nlayers_cls=n_layers_cls, n_cls=1, vocab=vocab,\n",
        "    dropout=0, pad_token=\"<pad>\", pad_value=0, pert_pad_id=0,\n",
        "    use_fast_transformer=True\n",
        ")\n",
        "\n",
        "# Load pretrained weights\n",
        "pretrained_dict = torch.load(model_file, map_location=device)\n",
        "load_prefixes = [\"encoder\", \"value_encoder\", \"transformer_encoder\"]\n",
        "pretrained_dict = {k: v for k, v in pretrained_dict.items() \n",
        "                   if any(k.startswith(p) for p in load_prefixes)}\n",
        "\n",
        "model_dict = model.state_dict()\n",
        "for k, v in pretrained_dict.items():\n",
        "    if k in model_dict and v.shape == model_dict[k].shape:\n",
        "        model_dict[k] = v\n",
        "\n",
        "model.load_state_dict(model_dict)\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "print(\"✓ Model loaded successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Compute Saliency Map\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_saliency(model, input_ids, input_values, target_idx):\n",
        "    \"\"\"Compute gradient-based saliency for a target gene.\"\"\"\n",
        "    model.eval()\n",
        "    input_ids = input_ids.unsqueeze(0).to(device)\n",
        "    input_values = input_values.unsqueeze(0).to(device)\n",
        "    input_values.requires_grad_(True)\n",
        "    \n",
        "    pert_flags = torch.zeros_like(input_ids).long()\n",
        "    src_key_padding_mask = torch.zeros_like(input_values, dtype=torch.bool)\n",
        "    \n",
        "    # Forward pass\n",
        "    output = model(input_ids, input_values, pert_flags,\n",
        "                   src_key_padding_mask=src_key_padding_mask,\n",
        "                   CLS=False, CCE=False, MVC=False, ECS=False)\n",
        "    \n",
        "    # Backprop to get gradients\n",
        "    target_output = output[\"mlm_output\"][0, target_idx]\n",
        "    gradients = torch.autograd.grad(target_output, input_values,\n",
        "                                     create_graph=False, retain_graph=False)[0]\n",
        "    \n",
        "    return torch.abs(gradients).squeeze(0).detach().cpu().numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare control cells data\n",
        "ctrl_cells = pert_data.adata[pert_data.adata.obs[\"condition\"] == \"ctrl\"]\n",
        "n_samples = min(50, ctrl_cells.shape[0])\n",
        "sample_idx = np.random.choice(ctrl_cells.shape[0], n_samples, replace=False)\n",
        "\n",
        "# Average expression across samples\n",
        "expr_data = ctrl_cells[sample_idx, :].X.toarray()\n",
        "mean_expr = np.mean(expr_data, axis=0)\n",
        "\n",
        "input_ids = torch.tensor(gene_ids, dtype=torch.long)\n",
        "input_values = torch.tensor(mean_expr, dtype=torch.float32)\n",
        "\n",
        "print(f\"Input shape: {input_values.shape}\")\n",
        "print(f\"Using {n_samples} control cells for mean expression\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute saliency matrix\n",
        "# For efficiency, compute for a subset of genes\n",
        "n_genes = len(genes)\n",
        "n_compute = min(300, n_genes)  # Adjust based on computational resources\n",
        "\n",
        "print(f\"Computing saliency for {n_compute} target genes...\")\n",
        "print(\"This may take a few minutes...\")\n",
        "\n",
        "saliency_matrix = np.zeros((n_genes, n_genes))  # [source, target]\n",
        "target_indices = np.random.choice(n_genes, n_compute, replace=False)\n",
        "\n",
        "for i, target_idx in enumerate(target_indices):\n",
        "    if (i + 1) % 50 == 0:\n",
        "        print(f\"  Progress: {i+1}/{n_compute}\")\n",
        "    \n",
        "    saliency = compute_saliency(model, input_ids, input_values, target_idx)\n",
        "    saliency_matrix[:, target_idx] = saliency\n",
        "\n",
        "print(f\"\\n✓ Saliency matrix computed: {saliency_matrix.shape}\")\n",
        "print(f\"  Range: [{saliency_matrix.min():.6f}, {saliency_matrix.max():.6f}]\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Load STRING Gene Interactions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# UPDATE THESE PATHS TO YOUR STRING DATABASE FILES\n",
        "STRING_LINKS = \"/content/drive/MyDrive/data/STRING/9606.protein.links.v12.0.txt\"\n",
        "STRING_ALIAS = \"/content/drive/MyDrive/data/STRING/9606.protein.aliases.v12.0.txt\"\n",
        "\n",
        "# Load STRING data\n",
        "print(\"Loading STRING database...\")\n",
        "string_links = pd.read_csv(STRING_LINKS, sep=\" \")\n",
        "string_links[\"protein1\"] = string_links[\"protein1\"].str.replace(\"9606.\", \"\", regex=False)\n",
        "string_links[\"protein2\"] = string_links[\"protein2\"].str.replace(\"9606.\", \"\", regex=False)\n",
        "\n",
        "# Load protein-to-gene mapping\n",
        "string_alias = pd.read_csv(STRING_ALIAS, sep=\"\\t\", header=None)\n",
        "string_alias = string_alias[string_alias[1].str.startswith(\"ENSG\", na=False)][[0,1]].drop_duplicates()\n",
        "string_alias[0] = string_alias[0].str.replace(\"9606.\", \"\", regex=False)\n",
        "protein_to_gene = dict(zip(string_alias[0], string_alias[1]))\n",
        "\n",
        "# Map to gene IDs\n",
        "string_links[\"gene1\"] = string_links[\"protein1\"].map(protein_to_gene)\n",
        "string_links[\"gene2\"] = string_links[\"protein2\"].map(protein_to_gene)\n",
        "string_links = string_links.dropna(subset=[\"gene1\", \"gene2\"])\n",
        "\n",
        "# Filter for high-confidence interactions\n",
        "high_conf = string_links[string_links[\"combined_score\"] > 700]\n",
        "\n",
        "print(f\"✓ Loaded {len(high_conf)} high-confidence interactions\")\n",
        "print(f\"  Unique genes: {len(set(high_conf['gene1']) | set(high_conf['gene2']))}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build interaction matrix\n",
        "def build_interaction_matrix(string_data, gene_list):\n",
        "    \"\"\"Build binary interaction matrix from STRING data.\"\"\"\n",
        "    n = len(gene_list)\n",
        "    matrix = np.zeros((n, n))\n",
        "    gene_to_idx = {gene: i for i, gene in enumerate(gene_list)}\n",
        "    \n",
        "    n_matched = 0\n",
        "    for _, row in string_data.iterrows():\n",
        "        g1, g2 = row[\"gene1\"], row[\"gene2\"]\n",
        "        if g1 in gene_to_idx and g2 in gene_to_idx:\n",
        "            i1, i2 = gene_to_idx[g1], gene_to_idx[g2]\n",
        "            matrix[i1, i2] = matrix[i2, i1] = 1\n",
        "            n_matched += 1\n",
        "    \n",
        "    print(f\"  Matched {n_matched} interactions to gene list\")\n",
        "    print(f\"  Density: {matrix.sum() / (n * n):.4f}\")\n",
        "    return matrix\n",
        "\n",
        "interaction_matrix = build_interaction_matrix(high_conf, genes)\n",
        "print(f\"✓ Interaction matrix: {interaction_matrix.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Divide Saliency into Two Groups\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remove diagonal and filter valid entries\n",
        "n = saliency_matrix.shape[0]\n",
        "mask = ~np.eye(n, dtype=bool)  # Exclude self-interactions\n",
        "\n",
        "saliency_flat = saliency_matrix[mask]\n",
        "interaction_flat = interaction_matrix[mask]\n",
        "\n",
        "# Only keep pairs where we computed saliency\n",
        "valid = saliency_flat != 0\n",
        "saliency_flat = saliency_flat[valid]\n",
        "interaction_flat = interaction_flat[valid]\n",
        "\n",
        "# Divide into two groups\n",
        "group_with_interaction = saliency_flat[interaction_flat == 1]\n",
        "group_without_interaction = saliency_flat[interaction_flat == 0]\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SALIENCY GROUPS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Total gene pairs evaluated: {len(saliency_flat):,}\")\n",
        "print(f\"\\nGroup 1 - WITH interaction (STRING):\")\n",
        "print(f\"  Count: {len(group_with_interaction):,}\")\n",
        "print(f\"  Mean saliency: {group_with_interaction.mean():.6f}\")\n",
        "print(f\"  Median saliency: {np.median(group_with_interaction):.6f}\")\n",
        "print(f\"  Std dev: {group_with_interaction.std():.6f}\")\n",
        "print(f\"\\nGroup 2 - WITHOUT interaction:\")\n",
        "print(f\"  Count: {len(group_without_interaction):,}\")\n",
        "print(f\"  Mean saliency: {group_without_interaction.mean():.6f}\")\n",
        "print(f\"  Median saliency: {np.median(group_without_interaction):.6f}\")\n",
        "print(f\"  Std dev: {group_without_interaction.std():.6f}\")\n",
        "print(f\"\\nRatio (With / Without):\")\n",
        "print(f\"  Mean ratio: {group_with_interaction.mean() / group_without_interaction.mean():.3f}x\")\n",
        "print(f\"  Median ratio: {np.median(group_with_interaction) / np.median(group_without_interaction):.3f}x\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Visualization: Boxplots\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create boxplot comparison\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "# Plot 1: Boxplot\n",
        "ax = axes[0]\n",
        "data_to_plot = [group_without_interaction, group_with_interaction]\n",
        "bp = ax.boxplot(data_to_plot, labels=['Without\\nInteraction', 'With\\nInteraction'],\n",
        "                patch_artist=True, showfliers=False)\n",
        "bp['boxes'][0].set_facecolor('lightblue')\n",
        "bp['boxes'][1].set_facecolor('lightcoral')\n",
        "ax.set_ylabel('Saliency Score', fontsize=12)\n",
        "ax.set_title('Saliency Comparison: Interacting vs Non-Interacting Gene Pairs', fontsize=13, fontweight='bold')\n",
        "ax.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Add sample sizes\n",
        "ax.text(1, ax.get_ylim()[1]*0.95, f'n={len(group_without_interaction):,}', \n",
        "        ha='center', fontsize=10, bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "ax.text(2, ax.get_ylim()[1]*0.95, f'n={len(group_with_interaction):,}', \n",
        "        ha='center', fontsize=10, bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "\n",
        "# Plot 2: Violin plot\n",
        "ax = axes[1]\n",
        "parts = ax.violinplot([group_without_interaction, group_with_interaction], \n",
        "                       positions=[1, 2], showmeans=True, showmedians=True)\n",
        "ax.set_xticks([1, 2])\n",
        "ax.set_xticklabels(['Without\\nInteraction', 'With\\nInteraction'])\n",
        "ax.set_ylabel('Saliency Score', fontsize=12)\n",
        "ax.set_title('Saliency Distribution (Violin Plot)', fontsize=13, fontweight='bold')\n",
        "ax.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Plot 3: Histogram overlay\n",
        "ax = axes[2]\n",
        "ax.hist(group_without_interaction, bins=50, alpha=0.6, label='Without Interaction', \n",
        "        density=True, color='blue', edgecolor='black')\n",
        "ax.hist(group_with_interaction, bins=50, alpha=0.6, label='With Interaction', \n",
        "        density=True, color='red', edgecolor='black')\n",
        "ax.set_xlabel('Saliency Score', fontsize=12)\n",
        "ax.set_ylabel('Density', fontsize=12)\n",
        "ax.set_title('Saliency Distribution (Histogram)', fontsize=13, fontweight='bold')\n",
        "ax.legend(loc='upper right', fontsize=10)\n",
        "ax.grid(True, alpha=0.3, axis='y')\n",
        "ax.set_yscale('log')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('saliency_vs_interaction_boxplots.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"✓ Plots saved as 'saliency_vs_interaction_boxplots.png'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
