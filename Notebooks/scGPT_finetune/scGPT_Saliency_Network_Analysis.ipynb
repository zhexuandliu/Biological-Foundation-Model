{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# scGPT Saliency Map vs Gene Network Analysis\n",
        "\n",
        "This notebook analyzes whether scGPT's saliency maps represent actual gene-gene interactions from the STRING database.\n",
        "\n",
        "## Research Question\n",
        "Given a perturbation of gene A, if gene B has strong interaction with gene A in the STRING database, does the saliency map show that gene A has large weight in predicting the expression of gene B?\n",
        "\n",
        "## Approach\n",
        "1. Load pre-trained scGPT model\n",
        "2. Load STRING gene interaction network\n",
        "3. Compute saliency maps for gene-gene interactions\n",
        "4. Compare saliency patterns with known gene interactions from STRING\n",
        "5. Evaluate correlation and predictive power\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup for Google Colab\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/MyDrive/GitHub/Biological-Foundation-Model/notebooks/scGPT_finetune')\n",
        "\n",
        "# Install required packages\n",
        "%pip install -q scgpt\n",
        "%pip install -q gears\n",
        "%pip install -q scanpy\n",
        "%pip install -q torch-geometric\n",
        "%pip install -q scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# scGPT imports\n",
        "import scgpt as scg\n",
        "from scgpt.model import TransformerGenerator\n",
        "from scgpt.tokenizer.gene_tokenizer import GeneVocab\n",
        "from scgpt.utils import set_seed, map_raw_id_to_vocab_id\n",
        "\n",
        "# Data loading\n",
        "from gears import PertData\n",
        "\n",
        "# ML imports\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, average_precision_score\n",
        "from scipy.stats import spearmanr, pearsonr\n",
        "\n",
        "# Set device and seed\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "set_seed(42)\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load scGPT Model and Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model configuration - UPDATE THESE PATHS FOR YOUR SETUP\n",
        "model_dir = Path(\"./save/scGPT_human\")\n",
        "model_config_file = model_dir / \"args.json\"\n",
        "model_file = model_dir / \"best_model.pt\"\n",
        "vocab_file = model_dir / \"vocab.json\"\n",
        "\n",
        "# Load vocabulary\n",
        "vocab = GeneVocab.from_file(vocab_file)\n",
        "special_tokens = [\"<pad>\", \"<cls>\", \"<eoc>\"]\n",
        "for s in special_tokens:\n",
        "    if s not in vocab:\n",
        "        vocab.append_token(s)\n",
        "\n",
        "print(f\"Vocabulary size: {len(vocab)}\")\n",
        "\n",
        "# Load model configuration\n",
        "with open(model_config_file, \"r\") as f:\n",
        "    model_configs = json.load(f)\n",
        "\n",
        "# Model parameters\n",
        "ntokens = len(vocab)\n",
        "embsize = model_configs[\"embsize\"]\n",
        "nhead = model_configs[\"nheads\"]\n",
        "d_hid = model_configs[\"d_hid\"]\n",
        "nlayers = model_configs[\"nlayers\"]\n",
        "n_layers_cls = model_configs[\"n_layers_cls\"]\n",
        "dropout = 0\n",
        "pad_token = \"<pad>\"\n",
        "pad_value = 0\n",
        "pert_pad_id = 0\n",
        "use_fast_transformer = True\n",
        "\n",
        "print(f\"Model config: {embsize} dim, {nlayers} layers, {nhead} heads\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load perturbation data\n",
        "pert_data = PertData(\"../../data\")  # Adjust path as needed\n",
        "pert_data.load(data_name=\"adamson\")\n",
        "pert_data.prepare_split(split=\"simulation\", seed=1)\n",
        "\n",
        "# Get gene information\n",
        "genes = pert_data.adata.var[\"gene_name\"].tolist()\n",
        "pert_data.adata.var[\"id_in_vocab\"] = [\n",
        "    1 if gene in vocab else -1 for gene in pert_data.adata.var[\"gene_name\"]\n",
        "]\n",
        "gene_ids_in_vocab = np.array(pert_data.adata.var[\"id_in_vocab\"])\n",
        "print(f\"Matched {np.sum(gene_ids_in_vocab >= 0)}/{len(gene_ids_in_vocab)} genes in vocabulary\")\n",
        "\n",
        "# Create gene ID mapping\n",
        "gene_ids = np.array(\n",
        "    [vocab[gene] if gene in vocab else vocab[\"<pad>\"] for gene in genes], dtype=int\n",
        ")\n",
        "n_genes = len(genes)\n",
        "print(f\"Total genes: {n_genes}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize model\n",
        "model = TransformerGenerator(\n",
        "    ntokens,\n",
        "    embsize,\n",
        "    nhead,\n",
        "    d_hid,\n",
        "    nlayers,\n",
        "    nlayers_cls=n_layers_cls,\n",
        "    n_cls=1,\n",
        "    vocab=vocab,\n",
        "    dropout=dropout,\n",
        "    pad_token=pad_token,\n",
        "    pad_value=pad_value,\n",
        "    pert_pad_id=pert_pad_id,\n",
        "    use_fast_transformer=use_fast_transformer,\n",
        ")\n",
        "\n",
        "# Load pre-trained weights\n",
        "model_dict = model.state_dict()\n",
        "pretrained_dict = torch.load(model_file, map_location=device)\n",
        "load_param_prefixs = [\"encoder\", \"value_encoder\", \"transformer_encoder\"]\n",
        "\n",
        "pretrained_dict = {\n",
        "    k: v for k, v in pretrained_dict.items()\n",
        "    if any([k.startswith(prefix) for prefix in load_param_prefixs])\n",
        "}\n",
        "\n",
        "for k, v in pretrained_dict.items():\n",
        "    if k in model_dict and v.shape == model_dict[k].shape:\n",
        "        model_dict[k] = v\n",
        "\n",
        "model.load_state_dict(model_dict)\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "print(\"Model loaded successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load STRING Gene Interaction Network\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download STRING database if needed\n",
        "# You may need to download these files from https://string-db.org/\n",
        "# For human: 9606.protein.links.v12.0.txt and 9606.protein.aliases.v12.0.txt\n",
        "\n",
        "# UPDATE THESE PATHS FOR YOUR SETUP\n",
        "STRING_LINKS_FILE = \"/content/drive/MyDrive/data/STRING/9606.protein.links.v12.0.txt\"\n",
        "STRING_ALIAS_FILE = \"/content/drive/MyDrive/data/STRING/9606.protein.aliases.v12.0.txt\"\n",
        "\n",
        "print(\"Loading STRING database...\")\n",
        "\n",
        "# Load protein-protein interactions\n",
        "STRING_homosapien = pd.read_csv(STRING_LINKS_FILE, sep=\" \")\n",
        "STRING_homosapien[\"protein1\"] = STRING_homosapien[\"protein1\"].str.replace(\"9606.\", \"\", regex=False)\n",
        "STRING_homosapien[\"protein2\"] = STRING_homosapien[\"protein2\"].str.replace(\"9606.\", \"\", regex=False)\n",
        "\n",
        "print(f\"Loaded {len(STRING_homosapien)} protein-protein interactions\")\n",
        "\n",
        "# Load protein-gene mappings\n",
        "STRING_homosapien_alias = pd.read_csv(STRING_ALIAS_FILE, sep=\"\\t\", header=None)\n",
        "STRING_homosapien_alias = STRING_homosapien_alias[STRING_homosapien_alias[1].str.startswith(\"ENSG\", na=False)][[0,1]].drop_duplicates()\n",
        "STRING_homosapien_alias[0] = STRING_homosapien_alias[0].str.replace(\"9606.\", \"\", regex=False)\n",
        "ENSP_to_ENSG = dict(zip(STRING_homosapien_alias[0], STRING_homosapien_alias[1]))\n",
        "\n",
        "print(f\"Loaded {len(ENSP_to_ENSG)} protein-gene mappings\")\n",
        "\n",
        "# Map protein IDs to gene IDs\n",
        "STRING_homosapien[\"gene1\"] = STRING_homosapien[\"protein1\"].map(ENSP_to_ENSG)\n",
        "STRING_homosapien[\"gene2\"] = STRING_homosapien[\"protein2\"].map(ENSP_to_ENSG)\n",
        "STRING_gene_interaction = STRING_homosapien.dropna(subset=[\"gene1\", \"gene2\", \"combined_score\"])\n",
        "\n",
        "print(f\"Total gene-gene interactions: {len(STRING_gene_interaction)}\")\n",
        "\n",
        "# Filter for high-confidence interactions (score > 700)\n",
        "STRING_gene_interaction_high_conf = STRING_gene_interaction[STRING_gene_interaction[\"combined_score\"] > 700]\n",
        "\n",
        "print(f\"High-confidence interactions (score > 700): {len(STRING_gene_interaction_high_conf)}\")\n",
        "print(f\"Unique genes in network: {len(set(STRING_gene_interaction_high_conf['gene1']) | set(STRING_gene_interaction_high_conf['gene2']))}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Map gene names to Ensembl IDs if needed\n",
        "# This depends on your data format - you may need to adjust this\n",
        "\n",
        "# For now, we'll create a mapping based on gene symbols\n",
        "# You might need to load a proper gene ID mapping file\n",
        "\n",
        "print(f\"Sample genes from perturbation data: {genes[:10]}\")\n",
        "print(f\"Sample genes from STRING: {list(STRING_gene_interaction_high_conf['gene1'].unique()[:10])}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Saliency Map Computation Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_gradient_saliency(model, input_ids, input_values, target_gene_idx):\n",
        "    \"\"\"\n",
        "    Compute gradient-based saliency map for a specific target gene.\n",
        "    \n",
        "    Args:\n",
        "        model: scGPT model\n",
        "        input_ids: gene token IDs [seq_len]\n",
        "        input_values: gene expression values [seq_len]\n",
        "        target_gene_idx: index of target gene in the sequence\n",
        "    \n",
        "    Returns:\n",
        "        saliency_map: gradient magnitudes for each input gene\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    input_ids = input_ids.unsqueeze(0).to(device)  # [1, seq_len]\n",
        "    input_values = input_values.unsqueeze(0).to(device)  # [1, seq_len]\n",
        "    \n",
        "    # Create perturbation flags (all zeros for now)\n",
        "    pert_flags = torch.zeros_like(input_ids).long()\n",
        "    src_key_padding_mask = torch.zeros_like(input_values, dtype=torch.bool)\n",
        "    \n",
        "    # Enable gradients for input values\n",
        "    input_values.requires_grad_(True)\n",
        "    \n",
        "    # Forward pass\n",
        "    output_dict = model(\n",
        "        input_ids,\n",
        "        input_values,\n",
        "        pert_flags,\n",
        "        src_key_padding_mask=src_key_padding_mask,\n",
        "        CLS=False, CCE=False, MVC=False, ECS=False,\n",
        "    )\n",
        "    \n",
        "    # Get output for target gene\n",
        "    target_output = output_dict[\"mlm_output\"][0, target_gene_idx]\n",
        "    \n",
        "    # Compute gradients\n",
        "    gradients = torch.autograd.grad(\n",
        "        outputs=target_output,\n",
        "        inputs=input_values,\n",
        "        create_graph=False,\n",
        "        retain_graph=False\n",
        "    )[0]\n",
        "    \n",
        "    # Return saliency (gradient magnitude)\n",
        "    saliency = torch.abs(gradients).squeeze(0).detach().cpu().numpy()\n",
        "    \n",
        "    return saliency\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prepare_sample_data(pert_data, condition, n_samples=20):\n",
        "    \"\"\"\n",
        "    Prepare sample data for saliency analysis.\n",
        "    \n",
        "    Args:\n",
        "        pert_data: PertData object\n",
        "        condition: perturbation condition (\"ctrl\" for control)\n",
        "        n_samples: number of samples to average\n",
        "    \n",
        "    Returns:\n",
        "        dictionary with input_ids, input_values, and gene_names\n",
        "    \"\"\"\n",
        "    # Get data for the condition\n",
        "    condition_data = pert_data.adata[pert_data.adata.obs[\"condition\"] == condition]\n",
        "    \n",
        "    # Sample cells\n",
        "    n_cells = min(n_samples, condition_data.shape[0])\n",
        "    sample_indices = np.random.choice(condition_data.shape[0], n_cells, replace=False)\n",
        "    sample_data = condition_data[sample_indices, :]\n",
        "    \n",
        "    # Get expression values\n",
        "    expr_values = sample_data.X.toarray()  # [n_cells, n_genes]\n",
        "    \n",
        "    # Get gene IDs\n",
        "    input_ids = torch.tensor(gene_ids, dtype=torch.long)  # [n_genes]\n",
        "    \n",
        "    # Take mean across samples\n",
        "    mean_expr = np.mean(expr_values, axis=0)  # [n_genes]\n",
        "    input_values = torch.tensor(mean_expr, dtype=torch.float32)\n",
        "    \n",
        "    return {\n",
        "        'input_ids': input_ids,\n",
        "        'input_values': input_values,\n",
        "        'gene_names': genes,\n",
        "        'condition': condition\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Compute Saliency Matrix for Gene Pairs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare control data\n",
        "print(\"Preparing control sample data...\")\n",
        "ctrl_sample = prepare_sample_data(pert_data, \"ctrl\", n_samples=50)\n",
        "\n",
        "print(f\"Control sample shape: {ctrl_sample['input_values'].shape}\")\n",
        "print(f\"Number of genes: {len(ctrl_sample['gene_names'])}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute saliency matrix for all genes\n",
        "# This computes: for each target gene j, what is the saliency of each source gene i?\n",
        "# Saliency[i, j] = how much does gene i influence the prediction of gene j\n",
        "\n",
        "print(\"Computing saliency matrix...\")\n",
        "print(\"This may take a while...\")\n",
        "\n",
        "n_genes = len(genes)\n",
        "saliency_matrix = np.zeros((n_genes, n_genes))  # [source_gene, target_gene]\n",
        "\n",
        "# For computational efficiency, we can sample a subset of genes\n",
        "# Set to n_genes to compute for all genes (may be slow)\n",
        "n_genes_to_compute = min(500, n_genes)  # Adjust based on your computational resources\n",
        "gene_indices_to_compute = np.random.choice(n_genes, n_genes_to_compute, replace=False)\n",
        "\n",
        "for i, target_idx in enumerate(gene_indices_to_compute):\n",
        "    if i % 50 == 0:\n",
        "        print(f\"Progress: {i}/{n_genes_to_compute} genes computed\")\n",
        "    \n",
        "    try:\n",
        "        saliency = compute_gradient_saliency(\n",
        "            model,\n",
        "            ctrl_sample['input_ids'],\n",
        "            ctrl_sample['input_values'],\n",
        "            target_idx\n",
        "        )\n",
        "        saliency_matrix[:, target_idx] = saliency\n",
        "    except Exception as e:\n",
        "        print(f\"Error computing saliency for gene {target_idx}: {e}\")\n",
        "        continue\n",
        "\n",
        "print(f\"Saliency matrix shape: {saliency_matrix.shape}\")\n",
        "print(f\"Saliency range: [{saliency_matrix.min():.6f}, {saliency_matrix.max():.6f}]\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Build Gene Interaction Network from STRING\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_interaction_matrix(string_data, gene_list, gene_id_col1='gene1', gene_id_col2='gene2'):\n",
        "    \"\"\"\n",
        "    Build a binary interaction matrix from STRING data.\n",
        "    \n",
        "    Args:\n",
        "        string_data: DataFrame with gene interactions\n",
        "        gene_list: List of gene names/IDs in the same order as saliency matrix\n",
        "        gene_id_col1: Column name for first gene\n",
        "        gene_id_col2: Column name for second gene\n",
        "    \n",
        "    Returns:\n",
        "        interaction_matrix: Binary matrix [n_genes, n_genes]\n",
        "    \"\"\"\n",
        "    n = len(gene_list)\n",
        "    interaction_matrix = np.zeros((n, n))\n",
        "    \n",
        "    # Create gene to index mapping\n",
        "    gene_to_idx = {gene: i for i, gene in enumerate(gene_list)}\n",
        "    \n",
        "    # Fill in interactions\n",
        "    n_matched = 0\n",
        "    for _, row in string_data.iterrows():\n",
        "        gene1 = row[gene_id_col1]\n",
        "        gene2 = row[gene_id_col2]\n",
        "        \n",
        "        # Check if both genes are in our gene list\n",
        "        if gene1 in gene_to_idx and gene2 in gene_to_idx:\n",
        "            idx1 = gene_to_idx[gene1]\n",
        "            idx2 = gene_to_idx[gene2]\n",
        "            interaction_matrix[idx1, idx2] = 1\n",
        "            interaction_matrix[idx2, idx1] = 1  # Symmetric\n",
        "            n_matched += 1\n",
        "    \n",
        "    print(f\"Matched {n_matched} interactions to gene list\")\n",
        "    print(f\"Interaction density: {interaction_matrix.sum() / (n * n):.4f}\")\n",
        "    \n",
        "    return interaction_matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Note: You may need to map between gene name formats\n",
        "# The perturbation data uses gene symbols, STRING uses Ensembl IDs\n",
        "# You might need to load a mapping file or use a package like mygene\n",
        "\n",
        "# For demonstration, we'll try to build the matrix\n",
        "# You may need to adjust this based on your gene ID formats\n",
        "\n",
        "print(\"Building interaction matrix from STRING data...\")\n",
        "\n",
        "# Try to build interaction matrix\n",
        "# This assumes gene names match - you may need to add ID conversion\n",
        "interaction_matrix = build_interaction_matrix(\n",
        "    STRING_gene_interaction_high_conf,\n",
        "    genes,\n",
        "    gene_id_col1='gene1',\n",
        "    gene_id_col2='gene2'\n",
        ")\n",
        "\n",
        "print(f\"Interaction matrix shape: {interaction_matrix.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Analyze Correlation Between Saliency and Gene Interactions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_saliency_vs_network(saliency_matrix, interaction_matrix):\n",
        "    \"\"\"\n",
        "    Evaluate how well saliency maps predict gene interactions.\n",
        "    \n",
        "    Args:\n",
        "        saliency_matrix: Matrix of saliency scores [n_genes, n_genes]\n",
        "        interaction_matrix: Binary matrix of gene interactions [n_genes, n_genes]\n",
        "    \n",
        "    Returns:\n",
        "        Dictionary of evaluation metrics\n",
        "    \"\"\"\n",
        "    # Remove diagonal (self-interactions)\n",
        "    n = saliency_matrix.shape[0]\n",
        "    mask = ~np.eye(n, dtype=bool)\n",
        "    \n",
        "    saliency_flat = saliency_matrix[mask]\n",
        "    interaction_flat = interaction_matrix[mask]\n",
        "    \n",
        "    # Filter out pairs where we computed saliency\n",
        "    valid_mask = saliency_flat != 0  # Only consider where we computed saliency\n",
        "    saliency_flat = saliency_flat[valid_mask]\n",
        "    interaction_flat = interaction_flat[valid_mask]\n",
        "    \n",
        "    print(f\"Evaluating {len(saliency_flat)} gene pairs\")\n",
        "    print(f\"Positive pairs (interacting): {interaction_flat.sum()}\")\n",
        "    print(f\"Negative pairs (non-interacting): {(interaction_flat == 0).sum()}\")\n",
        "    \n",
        "    # Compute correlation\n",
        "    spearman_corr, spearman_pval = spearmanr(saliency_flat, interaction_flat)\n",
        "    pearson_corr, pearson_pval = pearsonr(saliency_flat, interaction_flat)\n",
        "    \n",
        "    # Compute classification metrics\n",
        "    # Use saliency as predictor for interaction\n",
        "    if len(np.unique(interaction_flat)) > 1:  # Need both classes\n",
        "        auc_roc = roc_auc_score(interaction_flat, saliency_flat)\n",
        "        auc_pr = average_precision_score(interaction_flat, saliency_flat)\n",
        "        \n",
        "        # Binary prediction using median threshold\n",
        "        threshold = np.median(saliency_flat)\n",
        "        predictions = (saliency_flat > threshold).astype(int)\n",
        "        \n",
        "        accuracy = accuracy_score(interaction_flat, predictions)\n",
        "        precision = precision_score(interaction_flat, predictions, zero_division=0)\n",
        "        recall = recall_score(interaction_flat, predictions, zero_division=0)\n",
        "        f1 = f1_score(interaction_flat, predictions, zero_division=0)\n",
        "    else:\n",
        "        auc_roc = auc_pr = accuracy = precision = recall = f1 = np.nan\n",
        "    \n",
        "    results = {\n",
        "        'spearman_corr': spearman_corr,\n",
        "        'spearman_pval': spearman_pval,\n",
        "        'pearson_corr': pearson_corr,\n",
        "        'pearson_pval': pearson_pval,\n",
        "        'auc_roc': auc_roc,\n",
        "        'auc_pr': auc_pr,\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1_score': f1,\n",
        "        'n_pairs': len(saliency_flat),\n",
        "        'n_positive': int(interaction_flat.sum()),\n",
        "        'n_negative': int((interaction_flat == 0).sum())\n",
        "    }\n",
        "    \n",
        "    return results, saliency_flat, interaction_flat\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate saliency vs network\n",
        "print(\"Evaluating saliency maps against gene interaction network...\")\n",
        "\n",
        "results, saliency_flat, interaction_flat = evaluate_saliency_vs_network(\n",
        "    saliency_matrix,\n",
        "    interaction_matrix\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"RESULTS: Saliency Map vs Gene Interaction Network\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nCorrelation Metrics:\")\n",
        "print(f\"  Spearman correlation: {results['spearman_corr']:.4f} (p={results['spearman_pval']:.2e})\")\n",
        "print(f\"  Pearson correlation:  {results['pearson_corr']:.4f} (p={results['pearson_pval']:.2e})\")\n",
        "print(f\"\\nClassification Metrics:\")\n",
        "print(f\"  AUC-ROC:  {results['auc_roc']:.4f}\")\n",
        "print(f\"  AUC-PR:   {results['auc_pr']:.4f}\")\n",
        "print(f\"  Accuracy: {results['accuracy']:.4f}\")\n",
        "print(f\"  Precision: {results['precision']:.4f}\")\n",
        "print(f\"  Recall:    {results['recall']:.4f}\")\n",
        "print(f\"  F1 Score:  {results['f1_score']:.4f}\")\n",
        "print(f\"\\nDataset Statistics:\")\n",
        "print(f\"  Total gene pairs evaluated: {results['n_pairs']}\")\n",
        "print(f\"  Interacting pairs: {results['n_positive']}\")\n",
        "print(f\"  Non-interacting pairs: {results['n_negative']}\")\n",
        "print(f\"  Class balance: {results['n_positive']/results['n_pairs']:.4f}\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot saliency distribution for interacting vs non-interacting gene pairs\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Histogram\n",
        "ax = axes[0]\n",
        "interacting_saliency = saliency_flat[interaction_flat == 1]\n",
        "non_interacting_saliency = saliency_flat[interaction_flat == 0]\n",
        "\n",
        "ax.hist(non_interacting_saliency, bins=50, alpha=0.6, label='Non-interacting', density=True, color='blue')\n",
        "ax.hist(interacting_saliency, bins=50, alpha=0.6, label='Interacting (STRING)', density=True, color='red')\n",
        "ax.set_xlabel('Saliency Score')\n",
        "ax.set_ylabel('Density')\n",
        "ax.set_title('Saliency Distribution: Interacting vs Non-Interacting Pairs')\n",
        "ax.legend()\n",
        "ax.set_yscale('log')\n",
        "\n",
        "# Box plot\n",
        "ax = axes[1]\n",
        "data_to_plot = [non_interacting_saliency, interacting_saliency]\n",
        "ax.boxplot(data_to_plot, labels=['Non-interacting', 'Interacting'])\n",
        "ax.set_ylabel('Saliency Score')\n",
        "ax.set_title('Saliency Score Comparison')\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nMean saliency for interacting pairs: {interacting_saliency.mean():.6f}\")\n",
        "print(f\"Mean saliency for non-interacting pairs: {non_interacting_saliency.mean():.6f}\")\n",
        "print(f\"Ratio: {interacting_saliency.mean() / non_interacting_saliency.mean():.2f}x\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot ROC and PR curves\n",
        "from sklearn.metrics import roc_curve, precision_recall_curve\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# ROC curve\n",
        "fpr, tpr, _ = roc_curve(interaction_flat, saliency_flat)\n",
        "ax = axes[0]\n",
        "ax.plot(fpr, tpr, linewidth=2, label=f'AUC = {results[\"auc_roc\"]:.3f}')\n",
        "ax.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random')\n",
        "ax.set_xlabel('False Positive Rate')\n",
        "ax.set_ylabel('True Positive Rate')\n",
        "ax.set_title('ROC Curve: Saliency Predicting Gene Interactions')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Precision-Recall curve\n",
        "precision_curve, recall_curve, _ = precision_recall_curve(interaction_flat, saliency_flat)\n",
        "ax = axes[1]\n",
        "ax.plot(recall_curve, precision_curve, linewidth=2, label=f'AP = {results[\"auc_pr\"]:.3f}')\n",
        "baseline = results['n_positive'] / results['n_pairs']\n",
        "ax.axhline(y=baseline, color='k', linestyle='--', linewidth=1, label=f'Baseline = {baseline:.3f}')\n",
        "ax.set_xlabel('Recall')\n",
        "ax.set_ylabel('Precision')\n",
        "ax.set_title('Precision-Recall Curve')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize a subset of the saliency and interaction matrices\n",
        "n_genes_viz = min(100, n_genes)\n",
        "subset_indices = np.random.choice(n_genes, n_genes_viz, replace=False)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
        "\n",
        "# Saliency matrix\n",
        "ax = axes[0]\n",
        "im1 = ax.imshow(saliency_matrix[np.ix_(subset_indices, subset_indices)], \n",
        "                cmap='YlOrRd', aspect='auto', interpolation='nearest')\n",
        "ax.set_title(f'Saliency Matrix ({n_genes_viz} genes)')\n",
        "ax.set_xlabel('Target Gene')\n",
        "ax.set_ylabel('Source Gene')\n",
        "plt.colorbar(im1, ax=ax, label='Saliency Score')\n",
        "\n",
        "# Interaction matrix\n",
        "ax = axes[1]\n",
        "im2 = ax.imshow(interaction_matrix[np.ix_(subset_indices, subset_indices)], \n",
        "                cmap='binary', aspect='auto', interpolation='nearest')\n",
        "ax.set_title(f'STRING Interaction Matrix ({n_genes_viz} genes)')\n",
        "ax.set_xlabel('Gene 2')\n",
        "ax.set_ylabel('Gene 1')\n",
        "plt.colorbar(im2, ax=ax, label='Interaction (0/1)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Case Study: Specific Gene Interactions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_specific_gene(gene_name, saliency_matrix, interaction_matrix, gene_list, top_n=20):\n",
        "    \"\"\"\n",
        "    Analyze saliency vs interactions for a specific gene.\n",
        "    \"\"\"\n",
        "    if gene_name not in gene_list:\n",
        "        print(f\"Gene {gene_name} not found in gene list\")\n",
        "        return\n",
        "    \n",
        "    gene_idx = gene_list.index(gene_name)\n",
        "    \n",
        "    # Get saliency for this gene as target\n",
        "    gene_saliency = saliency_matrix[:, gene_idx]\n",
        "    gene_interactions = interaction_matrix[:, gene_idx]\n",
        "    \n",
        "    # Get top genes by saliency\n",
        "    top_saliency_indices = np.argsort(gene_saliency)[-top_n:][::-1]\n",
        "    top_saliency_genes = [gene_list[i] for i in top_saliency_indices]\n",
        "    top_saliency_scores = gene_saliency[top_saliency_indices]\n",
        "    top_saliency_interactions = gene_interactions[top_saliency_indices]\n",
        "    \n",
        "    # Get true interacting genes\n",
        "    true_interacting_indices = np.where(gene_interactions == 1)[0]\n",
        "    true_interacting_genes = [gene_list[i] for i in true_interacting_indices]\n",
        "    \n",
        "    print(f\"\\nAnalysis for gene: {gene_name}\")\n",
        "    print(f\"Number of known interactions (STRING): {len(true_interacting_genes)}\")\n",
        "    print(f\"\\nTop {top_n} genes by saliency:\")\n",
        "    \n",
        "    overlap = 0\n",
        "    for i, (gene, score, is_interacting) in enumerate(zip(top_saliency_genes, top_saliency_scores, top_saliency_interactions)):\n",
        "        marker = \"✓\" if is_interacting else \" \"\n",
        "        print(f\"{i+1:2d}. {gene:15s} | Saliency: {score:.6f} | Interacts: {marker}\")\n",
        "        if is_interacting:\n",
        "            overlap += 1\n",
        "    \n",
        "    print(f\"\\nOverlap: {overlap}/{top_n} ({100*overlap/top_n:.1f}%) of top saliency genes are known interactors\")\n",
        "    \n",
        "    # Plot\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "    colors = ['red' if i else 'blue' for i in top_saliency_interactions]\n",
        "    ax.barh(range(top_n), top_saliency_scores, color=colors, alpha=0.7)\n",
        "    ax.set_yticks(range(top_n))\n",
        "    ax.set_yticklabels(top_saliency_genes)\n",
        "    ax.set_xlabel('Saliency Score')\n",
        "    ax.set_title(f'Top {top_n} Genes by Saliency for {gene_name}\\n(Red = Known Interactor from STRING)')\n",
        "    ax.invert_yaxis()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    return {\n",
        "        'top_genes': top_saliency_genes,\n",
        "        'top_scores': top_saliency_scores,\n",
        "        'overlap': overlap,\n",
        "        'n_true_interactions': len(true_interacting_genes)\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze specific genes\n",
        "# Choose some well-known genes or genes from your perturbation data\n",
        "\n",
        "example_genes = genes[:5]  # Adjust to genes of interest\n",
        "print(f\"Analyzing example genes: {example_genes}\")\n",
        "\n",
        "for gene in example_genes:\n",
        "    try:\n",
        "        analyze_specific_gene(gene, saliency_matrix, interaction_matrix, genes, top_n=15)\n",
        "    except Exception as e:\n",
        "        print(f\"Error analyzing {gene}: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
