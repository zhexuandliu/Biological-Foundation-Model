{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# scGPT Saliency Map Analysis\n",
        "\n",
        "This notebook analyzes the attention patterns and saliency maps of scGPT to understand how the model uses gene interactions for perturbation prediction.\n",
        "\n",
        "## Research Question\n",
        "Given a perturbation of gene A, if gene B has strong interaction with gene A, does the saliency map show that gene A has large weight in predicting the expression of gene B?\n",
        "\n",
        "## Approach\n",
        "1. Load pre-trained scGPT model\n",
        "2. Compute saliency maps using gradient-based methods\n",
        "3. Analyze attention weights for gene-gene interactions\n",
        "4. Compare saliency patterns with known gene interaction networks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup and imports\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# scGPT imports\n",
        "import scgpt as scg\n",
        "from scgpt.model import TransformerGenerator\n",
        "from scgpt.tokenizer.gene_tokenizer import GeneVocab\n",
        "from scgpt.utils import set_seed, map_raw_id_to_vocab_id\n",
        "\n",
        "# Data loading\n",
        "from gears import PertData\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "# Set device and seed\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "set_seed(42)\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Model and Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model configuration\n",
        "model_dir = Path(\"./save/scGPT_human\")\n",
        "model_config_file = model_dir / \"args.json\"\n",
        "model_file = model_dir / \"best_model.pt\"\n",
        "vocab_file = model_dir / \"vocab.json\"\n",
        "\n",
        "# Load vocabulary\n",
        "vocab = GeneVocab.from_file(vocab_file)\n",
        "special_tokens = [\"<pad>\", \"<cls>\", \"<eoc>\"]\n",
        "for s in special_tokens:\n",
        "    if s not in vocab:\n",
        "        vocab.append_token(s)\n",
        "\n",
        "print(f\"Vocabulary size: {len(vocab)}\")\n",
        "\n",
        "# Load model configuration\n",
        "with open(model_config_file, \"r\") as f:\n",
        "    model_configs = json.load(f)\n",
        "\n",
        "# Model parameters\n",
        "ntokens = len(vocab)\n",
        "embsize = model_configs[\"embsize\"]\n",
        "nhead = model_configs[\"nheads\"]\n",
        "d_hid = model_configs[\"d_hid\"]\n",
        "nlayers = model_configs[\"nlayers\"]\n",
        "n_layers_cls = model_configs[\"n_layers_cls\"]\n",
        "dropout = 0\n",
        "pad_token = \"<pad>\"\n",
        "pad_value = 0\n",
        "pert_pad_id = 0\n",
        "use_fast_transformer = True\n",
        "\n",
        "print(f\"Model config: {embsize} dim, {nlayers} layers, {nhead} heads\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load perturbation data\n",
        "pert_data = PertData(\"./data\")\n",
        "pert_data.load(data_name=\"adamson\")\n",
        "pert_data.prepare_split(split=\"simulation\", seed=1)\n",
        "\n",
        "# Get gene information\n",
        "genes = pert_data.adata.var[\"gene_name\"].tolist()\n",
        "pert_data.adata.var[\"id_in_vocab\"] = [\n",
        "    1 if gene in vocab else -1 for gene in pert_data.adata.var[\"gene_name\"]\n",
        "]\n",
        "gene_ids_in_vocab = np.array(pert_data.adata.var[\"id_in_vocab\"])\n",
        "print(f\"Matched {np.sum(gene_ids_in_vocab >= 0)}/{len(gene_ids_in_vocab)} genes in vocabulary\")\n",
        "\n",
        "# Create gene ID mapping\n",
        "gene_ids = np.array(\n",
        "    [vocab[gene] if gene in vocab else vocab[\"<pad>\"] for gene in genes], dtype=int\n",
        ")\n",
        "n_genes = len(genes)\n",
        "\n",
        "# Get control data for baseline\n",
        "ctrl_data = pert_data.adata[pert_data.adata.obs[\"condition\"] == \"ctrl\"]\n",
        "print(f\"Control cells: {ctrl_data.shape[0]}\")\n",
        "\n",
        "# Get perturbation conditions\n",
        "pert_conditions = pert_data.adata.obs[\"condition\"].unique()\n",
        "pert_conditions = [c for c in pert_conditions if c != \"ctrl\"]\n",
        "print(f\"Available perturbations: {len(pert_conditions)}\")\n",
        "print(f\"Sample perturbations: {pert_conditions[:5]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize model\n",
        "model = TransformerGenerator(\n",
        "    ntokens,\n",
        "    embsize,\n",
        "    nhead,\n",
        "    d_hid,\n",
        "    nlayers,\n",
        "    nlayers_cls=n_layers_cls,\n",
        "    n_cls=1,\n",
        "    vocab=vocab,\n",
        "    dropout=dropout,\n",
        "    pad_token=pad_token,\n",
        "    pad_value=pad_value,\n",
        "    pert_pad_id=pert_pad_id,\n",
        "    use_fast_transformer=use_fast_transformer,\n",
        ")\n",
        "\n",
        "# Load pre-trained weights\n",
        "model_dict = model.state_dict()\n",
        "pretrained_dict = torch.load(model_file, map_location=device)\n",
        "load_param_prefixs = [\"encoder\", \"value_encoder\", \"transformer_encoder\"]\n",
        "\n",
        "pretrained_dict = {\n",
        "    k: v for k, v in pretrained_dict.items()\n",
        "    if any([k.startswith(prefix) for prefix in load_param_prefixs])\n",
        "}\n",
        "\n",
        "for k, v in pretrained_dict.items():\n",
        "    if k in model_dict and v.shape == model_dict[k].shape:\n",
        "        model_dict[k] = v\n",
        "\n",
        "model.load_state_dict(model_dict)\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "print(\"Model loaded successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Saliency Map Computation Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_gradient_saliency(model, input_ids, input_values, target_gene_idx, \n",
        "                             include_zero_gene=\"all\", max_seq_len=1536):\n",
        "    \"\"\"\n",
        "    Compute gradient-based saliency map for a specific target gene.\n",
        "    \n",
        "    Args:\n",
        "        model: scGPT model\n",
        "        input_ids: gene token IDs [seq_len]\n",
        "        input_values: gene expression values [seq_len]\n",
        "        target_gene_idx: index of target gene in the sequence\n",
        "        include_zero_gene: whether to include zero-expressed genes\n",
        "        max_seq_len: maximum sequence length\n",
        "    \n",
        "    Returns:\n",
        "        saliency_map: gradient magnitudes for each input gene\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    input_ids = input_ids.unsqueeze(0).to(device)  # [1, seq_len]\n",
        "    input_values = input_values.unsqueeze(0).to(device)  # [1, seq_len]\n",
        "    \n",
        "    # Create perturbation flags (all zeros for now)\n",
        "    pert_flags = torch.zeros_like(input_ids).long()\n",
        "    src_key_padding_mask = torch.zeros_like(input_values, dtype=torch.bool)\n",
        "    \n",
        "    # Enable gradients for input values\n",
        "    input_values.requires_grad_(True)\n",
        "    \n",
        "    # Forward pass\n",
        "    output_dict = model(\n",
        "        input_ids,\n",
        "        input_values,\n",
        "        pert_flags,\n",
        "        src_key_padding_mask=src_key_padding_mask,\n",
        "        CLS=False, CCE=False, MVC=False, ECS=False,\n",
        "    )\n",
        "    \n",
        "    # Get output for target gene\n",
        "    target_output = output_dict[\"mlm_output\"][0, target_gene_idx]\n",
        "    \n",
        "    # Compute gradients\n",
        "    gradients = torch.autograd.grad(\n",
        "        outputs=target_output,\n",
        "        inputs=input_values,\n",
        "        create_graph=False,\n",
        "        retain_graph=False\n",
        "    )[0]\n",
        "    \n",
        "    # Return saliency (gradient magnitude)\n",
        "    saliency = torch.abs(gradients).squeeze(0).detach().cpu().numpy()\n",
        "    \n",
        "    return saliency\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_attention_weights(model, input_ids, input_values, layer_idx=None):\n",
        "    \"\"\"\n",
        "    Extract attention weights from the transformer model.\n",
        "    \n",
        "    Args:\n",
        "        model: scGPT model\n",
        "        input_ids: gene token IDs [1, seq_len]\n",
        "        input_values: gene expression values [1, seq_len]\n",
        "        layer_idx: which layer to extract attention from (None for all layers)\n",
        "    \n",
        "    Returns:\n",
        "        attention_weights: attention weights [n_heads, seq_len, seq_len] or list of such\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        # Create perturbation flags and padding mask\n",
        "        pert_flags = torch.zeros_like(input_ids).long()\n",
        "        src_key_padding_mask = torch.zeros_like(input_values, dtype=torch.bool)\n",
        "        \n",
        "        # Forward pass with attention extraction\n",
        "        # We need to modify the model to return attention weights\n",
        "        # For now, we'll use a hook-based approach\n",
        "        \n",
        "        attention_weights = []\n",
        "        \n",
        "        def attention_hook(module, input, output):\n",
        "            # Extract attention weights from multi-head attention\n",
        "            if hasattr(module, 'attention_weights'):\n",
        "                attention_weights.append(module.attention_weights.detach().cpu())\n",
        "        \n",
        "        # Register hooks on attention layers\n",
        "        hooks = []\n",
        "        for name, module in model.named_modules():\n",
        "            if 'self_attn' in name and 'attention' in name:\n",
        "                hook = module.register_forward_hook(attention_hook)\n",
        "                hooks.append(hook)\n",
        "        \n",
        "        # Forward pass\n",
        "        output_dict = model(\n",
        "            input_ids,\n",
        "            input_values,\n",
        "            pert_flags,\n",
        "            src_key_padding_mask=src_key_padding_mask,\n",
        "            CLS=False, CCE=False, MVC=False, ECS=False,\n",
        "        )\n",
        "        \n",
        "        # Remove hooks\n",
        "        for hook in hooks:\n",
        "            hook.remove()\n",
        "        \n",
        "        return attention_weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prepare_sample_data(pert_data, condition, n_samples=10):\n",
        "    \"\"\"\n",
        "    Prepare sample data for saliency analysis.\n",
        "    \n",
        "    Args:\n",
        "        pert_data: PertData object\n",
        "        condition: perturbation condition\n",
        "        n_samples: number of samples to take\n",
        "    \n",
        "    Returns:\n",
        "        sample_data: dictionary with input_ids, input_values, and gene_names\n",
        "    \"\"\"\n",
        "    # Get data for the condition\n",
        "    if condition == \"ctrl\":\n",
        "        condition_data = pert_data.adata[pert_data.adata.obs[\"condition\"] == \"ctrl\"]\n",
        "    else:\n",
        "        condition_data = pert_data.adata[pert_data.adata.obs[\"condition\"] == condition]\n",
        "    \n",
        "    # Sample cells\n",
        "    n_cells = min(n_samples, condition_data.shape[0])\n",
        "    sample_indices = np.random.choice(condition_data.shape[0], n_cells, replace=False)\n",
        "    sample_data = condition_data[sample_indices, :]\n",
        "    \n",
        "    # Get expression values\n",
        "    expr_values = sample_data.X.toarray()  # [n_cells, n_genes]\n",
        "    \n",
        "    # Get gene IDs\n",
        "    input_ids = torch.tensor(gene_ids, dtype=torch.long)  # [n_genes]\n",
        "    \n",
        "    # Take mean across samples\n",
        "    mean_expr = np.mean(expr_values, axis=0)  # [n_genes]\n",
        "    input_values = torch.tensor(mean_expr, dtype=torch.float32)\n",
        "    \n",
        "    return {\n",
        "        'input_ids': input_ids,\n",
        "        'input_values': input_values,\n",
        "        'gene_names': genes,\n",
        "        'condition': condition\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Saliency Analysis for Gene Interactions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select a perturbation condition to analyze\n",
        "pert_condition = pert_conditions[0]  # Use first available perturbation\n",
        "print(f\"Analyzing perturbation: {pert_condition}\")\n",
        "\n",
        "# Parse the perturbation to identify the perturbed gene(s)\n",
        "if \"+\" in pert_condition:\n",
        "    pert_genes = pert_condition.split(\"+\")\n",
        "    pert_genes = [g for g in pert_genes if g != \"ctrl\"]\n",
        "else:\n",
        "    pert_genes = [pert_condition]\n",
        "\n",
        "print(f\"Perturbed genes: {pert_genes}\")\n",
        "\n",
        "# Find indices of perturbed genes\n",
        "pert_gene_indices = []\n",
        "for gene in pert_genes:\n",
        "    if gene in genes:\n",
        "        idx = genes.index(gene)\n",
        "        pert_gene_indices.append(idx)\n",
        "        print(f\"Gene {gene} at index {idx}\")\n",
        "    else:\n",
        "        print(f\"Warning: Gene {gene} not found in gene list\")\n",
        "\n",
        "if not pert_gene_indices:\n",
        "    print(\"No valid perturbed genes found. Using first gene as example.\")\n",
        "    pert_gene_indices = [0]\n",
        "    pert_genes = [genes[0]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for control and perturbed conditions\n",
        "ctrl_sample = prepare_sample_data(pert_data, \"ctrl\", n_samples=20)\n",
        "pert_sample = prepare_sample_data(pert_data, pert_condition, n_samples=20)\n",
        "\n",
        "print(f\"Control sample shape: {ctrl_sample['input_values'].shape}\")\n",
        "print(f\"Perturbed sample shape: {pert_sample['input_values'].shape}\")\n",
        "\n",
        "# Compute saliency maps for perturbed genes\n",
        "saliency_results = {}\n",
        "\n",
        "for i, pert_gene_idx in enumerate(pert_gene_indices):\n",
        "    pert_gene_name = pert_genes[i]\n",
        "    print(f\"\\nComputing saliency for gene {pert_gene_name} (index {pert_gene_idx})\")\n",
        "    \n",
        "    # Compute saliency on control data\n",
        "    ctrl_saliency = compute_gradient_saliency(\n",
        "        model, \n",
        "        ctrl_sample['input_ids'], \n",
        "        ctrl_sample['input_values'],\n",
        "        pert_gene_idx\n",
        "    )\n",
        "    \n",
        "    # Compute saliency on perturbed data\n",
        "    pert_saliency = compute_gradient_saliency(\n",
        "        model, \n",
        "        pert_sample['input_ids'], \n",
        "        pert_sample['input_values'],\n",
        "        pert_gene_idx\n",
        "    )\n",
        "    \n",
        "    saliency_results[pert_gene_name] = {\n",
        "        'ctrl_saliency': ctrl_saliency,\n",
        "        'pert_saliency': pert_saliency,\n",
        "        'gene_idx': pert_gene_idx\n",
        "    }\n",
        "    \n",
        "    print(f\"Control saliency range: [{ctrl_saliency.min():.6f}, {ctrl_saliency.max():.6f}]\")\n",
        "    print(f\"Perturbed saliency range: [{pert_saliency.min():.6f}, {pert_saliency.max():.6f}]\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Visualization and Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_saliency_comparison(saliency_results, gene_names, top_n=20):\n",
        "    \"\"\"\n",
        "    Plot comparison of saliency maps between control and perturbed conditions.\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(len(saliency_results), 2, figsize=(15, 4*len(saliency_results)))\n",
        "    if len(saliency_results) == 1:\n",
        "        axes = axes.reshape(1, -1)\n",
        "    \n",
        "    for i, (pert_gene, results) in enumerate(saliency_results.items()):\n",
        "        ctrl_saliency = results['ctrl_saliency']\n",
        "        pert_saliency = results['pert_saliency']\n",
        "        \n",
        "        # Get top contributing genes\n",
        "        ctrl_top_indices = np.argsort(ctrl_saliency)[-top_n:][::-1]\n",
        "        pert_top_indices = np.argsort(pert_saliency)[-top_n:][::-1]\n",
        "        \n",
        "        # Plot control saliency\n",
        "        ax1 = axes[i, 0]\n",
        "        ctrl_top_genes = [gene_names[idx] for idx in ctrl_top_indices]\n",
        "        ctrl_top_values = ctrl_saliency[ctrl_top_indices]\n",
        "        \n",
        "        bars1 = ax1.barh(range(top_n), ctrl_top_values)\n",
        "        ax1.set_yticks(range(top_n))\n",
        "        ax1.set_yticklabels(ctrl_top_genes)\n",
        "        ax1.set_xlabel('Saliency Score')\n",
        "        ax1.set_title(f'Control: Top {top_n} genes for {pert_gene}')\n",
        "        ax1.invert_yaxis()\n",
        "        \n",
        "        # Highlight the perturbed gene if it's in the top genes\n",
        "        if pert_gene in ctrl_top_genes:\n",
        "            idx = ctrl_top_genes.index(pert_gene)\n",
        "            bars1[idx].set_color('red')\n",
        "        \n",
        "        # Plot perturbed saliency\n",
        "        ax2 = axes[i, 1]\n",
        "        pert_top_genes = [gene_names[idx] for idx in pert_top_indices]\n",
        "        pert_top_values = pert_saliency[pert_top_indices]\n",
        "        \n",
        "        bars2 = ax2.barh(range(top_n), pert_top_values)\n",
        "        ax2.set_yticks(range(top_n))\n",
        "        ax2.set_yticklabels(pert_top_genes)\n",
        "        ax2.set_xlabel('Saliency Score')\n",
        "        ax2.set_title(f'Perturbed: Top {top_n} genes for {pert_gene}')\n",
        "        ax2.invert_yaxis()\n",
        "        \n",
        "        # Highlight the perturbed gene if it's in the top genes\n",
        "        if pert_gene in pert_top_genes:\n",
        "            idx = pert_top_genes.index(pert_gene)\n",
        "            bars2[idx].set_color('red')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_gene_interactions(saliency_results, gene_names, pert_gene_indices):\n",
        "    \"\"\"\n",
        "    Analyze whether perturbed genes show high saliency for their own prediction.\n",
        "    \"\"\"\n",
        "    results_summary = []\n",
        "    \n",
        "    for pert_gene, results in saliency_results.items():\n",
        "        pert_idx = results['gene_idx']\n",
        "        ctrl_saliency = results['ctrl_saliency']\n",
        "        pert_saliency = results['pert_saliency']\n",
        "        \n",
        "        # Get saliency score for the perturbed gene itself\n",
        "        ctrl_self_saliency = ctrl_saliency[pert_idx]\n",
        "        pert_self_saliency = pert_saliency[pert_idx]\n",
        "        \n",
        "        # Rank of the perturbed gene in saliency scores\n",
        "        ctrl_rank = np.sum(ctrl_saliency > ctrl_self_saliency) + 1\n",
        "        pert_rank = np.sum(pert_saliency > pert_self_saliency) + 1\n",
        "        \n",
        "        # Top percentile\n",
        "        ctrl_percentile = (1 - (ctrl_rank - 1) / len(ctrl_saliency)) * 100\n",
        "        pert_percentile = (1 - (pert_rank - 1) / len(pert_saliency)) * 100\n",
        "        \n",
        "        results_summary.append({\n",
        "            'pert_gene': pert_gene,\n",
        "            'ctrl_self_saliency': ctrl_self_saliency,\n",
        "            'pert_self_saliency': pert_self_saliency,\n",
        "            'ctrl_rank': ctrl_rank,\n",
        "            'pert_rank': pert_rank,\n",
        "            'ctrl_percentile': ctrl_percentile,\n",
        "            'pert_percentile': pert_percentile,\n",
        "            'saliency_change': pert_self_saliency - ctrl_self_saliency\n",
        "        })\n",
        "        \n",
        "        print(f\"\\nGene: {pert_gene}\")\n",
        "        print(f\"  Control self-saliency: {ctrl_self_saliency:.6f} (rank {ctrl_rank}/{len(ctrl_saliency)}, {ctrl_percentile:.1f}th percentile)\")\n",
        "        print(f\"  Perturbed self-saliency: {pert_self_saliency:.6f} (rank {pert_rank}/{len(pert_saliency)}, {pert_percentile:.1f}th percentile)\")\n",
        "        print(f\"  Change in self-saliency: {pert_self_saliency - ctrl_self_saliency:.6f}\")\n",
        "    \n",
        "    return pd.DataFrame(results_summary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate visualizations\n",
        "print(\"Generating saliency comparison plots...\")\n",
        "plot_saliency_comparison(saliency_results, genes, top_n=15)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze gene interactions\n",
        "print(\"Analyzing gene interactions...\")\n",
        "summary_df = analyze_gene_interactions(saliency_results, genes, pert_gene_indices)\n",
        "\n",
        "print(\"\\nSummary DataFrame:\")\n",
        "print(summary_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create summary visualization\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "# Plot 1: Self-saliency comparison\n",
        "axes[0].bar(summary_df['pert_gene'], summary_df['ctrl_self_saliency'], \n",
        "           alpha=0.7, label='Control', color='blue')\n",
        "axes[0].bar(summary_df['pert_gene'], summary_df['pert_self_saliency'], \n",
        "           alpha=0.7, label='Perturbed', color='red')\n",
        "axes[0].set_xlabel('Perturbed Gene')\n",
        "axes[0].set_ylabel('Self-Saliency Score')\n",
        "axes[0].set_title('Self-Saliency: Control vs Perturbed')\n",
        "axes[0].legend()\n",
        "axes[0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Plot 2: Rank comparison\n",
        "axes[1].bar(summary_df['pert_gene'], summary_df['ctrl_rank'], \n",
        "           alpha=0.7, label='Control', color='blue')\n",
        "axes[1].bar(summary_df['pert_gene'], summary_df['pert_rank'], \n",
        "           alpha=0.7, label='Perturbed', color='red')\n",
        "axes[1].set_xlabel('Perturbed Gene')\n",
        "axes[1].set_ylabel('Rank (lower is better)')\n",
        "axes[1].set_title('Rank: Control vs Perturbed')\n",
        "axes[1].legend()\n",
        "axes[1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Plot 3: Saliency change\n",
        "axes[2].bar(summary_df['pert_gene'], summary_df['saliency_change'], \n",
        "           alpha=0.7, color='green')\n",
        "axes[2].set_xlabel('Perturbed Gene')\n",
        "axes[2].set_ylabel('Change in Self-Saliency')\n",
        "axes[2].set_title('Change in Self-Saliency (Perturbed - Control)')\n",
        "axes[2].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
        "axes[2].tick_params(axis='x', rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
