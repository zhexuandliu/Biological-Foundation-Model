{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","import os\n","\n","drive.mount('/content/drive')\n","os.chdir('/content/drive/MyDrive/GitHub/Biological-Foundation-Model/Notebooks/scGPT_finetune')\n","\n","!pip install -r ./requirements.txt\n","!pip install scgpt \"flash-attn<1.0.5\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"0_TWNMn3kXDf","executionInfo":{"status":"ok","timestamp":1759723129837,"user_tz":300,"elapsed":856096,"user":{"displayName":"Zhexuan Liu","userId":"18073944608501350772"}},"outputId":"30cc8ebf-5486-49c7-9a2a-04de20754a5c"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from -r ./requirements.txt (line 2)) (2.0.2)\n","Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from -r ./requirements.txt (line 3)) (2.2.2)\n","Collecting torch==2.3.1 (from -r ./requirements.txt (line 6))\n","  Downloading torch-2.3.1-cp312-cp312-manylinux1_x86_64.whl.metadata (26 kB)\n","Collecting torchvision==0.18.1 (from -r ./requirements.txt (line 7))\n","  Downloading torchvision-0.18.1-cp312-cp312-manylinux1_x86_64.whl.metadata (6.6 kB)\n","Collecting torchaudio==2.3.1 (from -r ./requirements.txt (line 8))\n","  Downloading torchaudio-2.3.1-cp312-cp312-manylinux1_x86_64.whl.metadata (6.4 kB)\n","Collecting torchtext==0.18.0 (from -r ./requirements.txt (line 9))\n","  Downloading torchtext-0.18.0-cp312-cp312-manylinux1_x86_64.whl.metadata (7.9 kB)\n","Collecting scanpy<2.0,>=1.9.1 (from -r ./requirements.txt (line 12))\n","  Downloading scanpy-1.11.4-py3-none-any.whl.metadata (9.2 kB)\n","Collecting scvi-tools<1.0,>=0.16.0 (from -r ./requirements.txt (line 13))\n","  Downloading scvi_tools-0.20.3-py3-none-any.whl.metadata (9.8 kB)\n","Collecting torch_geometric (from -r ./requirements.txt (line 16))\n","  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting cell-gears (from -r ./requirements.txt (line 17))\n","  Downloading cell_gears-0.1.2-py3-none-any.whl.metadata (3.6 kB)\n","Collecting scgpt (from -r ./requirements.txt (line 18))\n","  Downloading scgpt-0.2.4-py3-none-any.whl.metadata (10.0 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1->-r ./requirements.txt (line 6)) (3.19.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1->-r ./requirements.txt (line 6)) (4.15.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1->-r ./requirements.txt (line 6)) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1->-r ./requirements.txt (line 6)) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1->-r ./requirements.txt (line 6)) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1->-r ./requirements.txt (line 6)) (2025.3.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.1->-r ./requirements.txt (line 6))\n","  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.1->-r ./requirements.txt (line 6))\n","  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.1->-r ./requirements.txt (line 6))\n","  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.1->-r ./requirements.txt (line 6))\n","  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.1->-r ./requirements.txt (line 6))\n","  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.1->-r ./requirements.txt (line 6))\n","  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.1->-r ./requirements.txt (line 6))\n","  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.1->-r ./requirements.txt (line 6))\n","  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.1->-r ./requirements.txt (line 6))\n","  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.1->-r ./requirements.txt (line 6))\n","  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.1->-r ./requirements.txt (line 6))\n","  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision==0.18.1->-r ./requirements.txt (line 7)) (11.3.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torchtext==0.18.0->-r ./requirements.txt (line 9)) (4.67.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torchtext==0.18.0->-r ./requirements.txt (line 9)) (2.32.4)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.1->-r ./requirements.txt (line 6)) (12.6.85)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.0->-r ./requirements.txt (line 3)) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.0->-r ./requirements.txt (line 3)) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.0->-r ./requirements.txt (line 3)) (2025.2)\n","Collecting anndata>=0.8 (from scanpy<2.0,>=1.9.1->-r ./requirements.txt (line 12))\n","  Downloading anndata-0.12.2-py3-none-any.whl.metadata (9.6 kB)\n","Requirement already satisfied: h5py>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from scanpy<2.0,>=1.9.1->-r ./requirements.txt (line 12)) (3.14.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from scanpy<2.0,>=1.9.1->-r ./requirements.txt (line 12)) (1.5.2)\n","Collecting legacy-api-wrap>=1.4.1 (from scanpy<2.0,>=1.9.1->-r ./requirements.txt (line 12))\n","  Downloading legacy_api_wrap-1.4.1-py3-none-any.whl.metadata (2.1 kB)\n","Requirement already satisfied: matplotlib>=3.7.5 in /usr/local/lib/python3.12/dist-packages (from scanpy<2.0,>=1.9.1->-r ./requirements.txt (line 12)) (3.10.0)\n","Requirement already satisfied: natsort in /usr/local/lib/python3.12/dist-packages (from scanpy<2.0,>=1.9.1->-r ./requirements.txt (line 12)) (8.4.0)\n","Requirement already satisfied: numba>=0.57.1 in /usr/local/lib/python3.12/dist-packages (from scanpy<2.0,>=1.9.1->-r ./requirements.txt (line 12)) (0.60.0)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from scanpy<2.0,>=1.9.1->-r ./requirements.txt (line 12)) (25.0)\n","Requirement already satisfied: patsy!=1.0.0 in /usr/local/lib/python3.12/dist-packages (from scanpy<2.0,>=1.9.1->-r ./requirements.txt (line 12)) (1.0.1)\n","Requirement already satisfied: pynndescent>=0.5.13 in /usr/local/lib/python3.12/dist-packages (from scanpy<2.0,>=1.9.1->-r ./requirements.txt (line 12)) (0.5.13)\n","Requirement already satisfied: scikit-learn>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from scanpy<2.0,>=1.9.1->-r ./requirements.txt (line 12)) (1.6.1)\n","Requirement already satisfied: scipy>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from scanpy<2.0,>=1.9.1->-r ./requirements.txt (line 12)) (1.16.2)\n","Requirement already satisfied: seaborn>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from scanpy<2.0,>=1.9.1->-r ./requirements.txt (line 12)) (0.13.2)\n","Collecting session-info2 (from scanpy<2.0,>=1.9.1->-r ./requirements.txt (line 12))\n","  Downloading session_info2-0.2.2-py3-none-any.whl.metadata (3.4 kB)\n","Requirement already satisfied: statsmodels>=0.14.5 in /usr/local/lib/python3.12/dist-packages (from scanpy<2.0,>=1.9.1->-r ./requirements.txt (line 12)) (0.14.5)\n","Requirement already satisfied: umap-learn>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from scanpy<2.0,>=1.9.1->-r ./requirements.txt (line 12)) (0.5.9.post2)\n","Requirement already satisfied: chex in /usr/local/lib/python3.12/dist-packages (from scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13)) (0.1.90)\n","Collecting docrep>=0.3.2 (from scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13))\n","  Downloading docrep-0.3.2.tar.gz (33 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: flax in /usr/local/lib/python3.12/dist-packages (from scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13)) (0.10.6)\n","Requirement already satisfied: jax>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13)) (0.5.3)\n","Requirement already satisfied: jaxlib>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13)) (0.5.3)\n","Collecting ml-collections>=0.1.1 (from scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13))\n","  Downloading ml_collections-1.1.0-py3-none-any.whl.metadata (22 kB)\n","Collecting mudata>=0.1.2 (from scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13))\n","  Downloading mudata-0.3.2-py3-none-any.whl.metadata (8.4 kB)\n","Collecting numpyro (from scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13))\n","  Downloading numpyro-0.19.0-py3-none-any.whl.metadata (37 kB)\n","Requirement already satisfied: openpyxl>=3.0 in /usr/local/lib/python3.12/dist-packages (from scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13)) (3.1.5)\n","Requirement already satisfied: optax in /usr/local/lib/python3.12/dist-packages (from scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13)) (0.2.6)\n","Collecting pyro-ppl>=1.6.0 (from scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13))\n","  Downloading pyro_ppl-1.9.1-py3-none-any.whl.metadata (7.8 kB)\n","Collecting pytorch-lightning<1.10.0,>=1.9.0 (from scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13))\n","  Downloading pytorch_lightning-1.9.5-py3-none-any.whl.metadata (23 kB)\n","Requirement already satisfied: rich>=12.0.0 in /usr/local/lib/python3.12/dist-packages (from scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13)) (13.9.4)\n","Collecting torchmetrics>=0.11.0 (from scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13))\n","  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch_geometric->-r ./requirements.txt (line 16)) (3.12.15)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch_geometric->-r ./requirements.txt (line 16)) (5.9.5)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch_geometric->-r ./requirements.txt (line 16)) (3.2.5)\n","Collecting dcor (from cell-gears->-r ./requirements.txt (line 17))\n","  Downloading dcor-0.6-py3-none-any.whl.metadata (6.2 kB)\n","Collecting cell-gears (from -r ./requirements.txt (line 17))\n","  Downloading cell-gears-0.0.2.tar.gz (25 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting datasets<3.0.0,>=2.3.0 (from scgpt->-r ./requirements.txt (line 18))\n","  Downloading datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\n","Collecting leidenalg>=0.8.10 (from scgpt->-r ./requirements.txt (line 18))\n","  Downloading leidenalg-0.10.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n","Collecting orbax<0.1.8 (from scgpt->-r ./requirements.txt (line 18))\n","  Downloading orbax-0.1.7-py3-none-any.whl.metadata (1.9 kB)\n","Collecting scib<2.0.0,>=1.0.3 (from scgpt->-r ./requirements.txt (line 18))\n","  Downloading scib-1.1.7-1-py3-none-any.whl.metadata (9.8 kB)\n","Collecting scikit-misc>=0.1.4 (from scgpt->-r ./requirements.txt (line 18))\n","  Downloading scikit_misc-0.5.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n","Collecting array-api-compat>=1.7.1 (from anndata>=0.8->scanpy<2.0,>=1.9.1->-r ./requirements.txt (line 12))\n","  Downloading array_api_compat-1.12.0-py3-none-any.whl.metadata (2.5 kB)\n","Collecting zarr!=3.0.*,>=2.18.7 (from anndata>=0.8->scanpy<2.0,>=1.9.1->-r ./requirements.txt (line 12))\n","  Downloading zarr-3.1.3-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets<3.0.0,>=2.3.0->scgpt->-r ./requirements.txt (line 18)) (18.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets<3.0.0,>=2.3.0->scgpt->-r ./requirements.txt (line 18)) (0.3.8)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets<3.0.0,>=2.3.0->scgpt->-r ./requirements.txt (line 18)) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from datasets<3.0.0,>=2.3.0->scgpt->-r ./requirements.txt (line 18)) (0.70.16)\n","Collecting fsspec (from torch==2.3.1->-r ./requirements.txt (line 6))\n","  Downloading fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.12/dist-packages (from datasets<3.0.0,>=2.3.0->scgpt->-r ./requirements.txt (line 18)) (0.35.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets<3.0.0,>=2.3.0->scgpt->-r ./requirements.txt (line 18)) (6.0.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from docrep>=0.3.2->scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13)) (1.17.0)\n","Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from jax>=0.4.4->scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13)) (0.5.3)\n","Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax>=0.4.4->scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13)) (3.4.0)\n","Collecting igraph<0.12,>=0.10.0 (from leidenalg>=0.8.10->scgpt->-r ./requirements.txt (line 18))\n","  Downloading igraph-0.11.9-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.5->scanpy<2.0,>=1.9.1->-r ./requirements.txt (line 12)) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.5->scanpy<2.0,>=1.9.1->-r ./requirements.txt (line 12)) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.5->scanpy<2.0,>=1.9.1->-r ./requirements.txt (line 12)) (4.60.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.5->scanpy<2.0,>=1.9.1->-r ./requirements.txt (line 12)) (1.4.9)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from ml-collections>=0.1.1->scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13)) (1.4.0)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.57.1->scanpy<2.0,>=1.9.1->-r ./requirements.txt (line 12)) (0.43.0)\n","Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl>=3.0->scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13)) (2.0.0)\n","Collecting cached_property (from orbax<0.1.8->scgpt->-r ./requirements.txt (line 18))\n","  Downloading cached_property-2.0.1-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: importlib_resources in /usr/local/lib/python3.12/dist-packages (from orbax<0.1.8->scgpt->-r ./requirements.txt (line 18)) (6.5.2)\n","Requirement already satisfied: msgpack in /usr/local/lib/python3.12/dist-packages (from orbax<0.1.8->scgpt->-r ./requirements.txt (line 18)) (1.1.1)\n","Requirement already satisfied: etils in /usr/local/lib/python3.12/dist-packages (from orbax<0.1.8->scgpt->-r ./requirements.txt (line 18)) (1.13.0)\n","Requirement already satisfied: tensorstore>=0.1.20 in /usr/local/lib/python3.12/dist-packages (from orbax<0.1.8->scgpt->-r ./requirements.txt (line 18)) (0.1.77)\n","Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.12/dist-packages (from orbax<0.1.8->scgpt->-r ./requirements.txt (line 18)) (1.6.0)\n","Collecting pyro-api>=0.1.1 (from pyro-ppl>=1.6.0->scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13))\n","  Downloading pyro_api-0.1.2-py3-none-any.whl.metadata (2.5 kB)\n","Collecting lightning-utilities>=0.6.0.post0 (from pytorch-lightning<1.10.0,>=1.9.0->scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13))\n","  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.18.0->-r ./requirements.txt (line 9)) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.18.0->-r ./requirements.txt (line 9)) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.18.0->-r ./requirements.txt (line 9)) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.18.0->-r ./requirements.txt (line 9)) (2025.8.3)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.0.0->scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13)) (4.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.0.0->scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13)) (2.19.2)\n","Requirement already satisfied: pydot in /usr/local/lib/python3.12/dist-packages (from scib<2.0.0,>=1.0.3->scgpt->-r ./requirements.txt (line 18)) (3.0.4)\n","Collecting deprecated (from scib<2.0.0,>=1.0.3->scgpt->-r ./requirements.txt (line 18))\n","  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.3->scanpy<2.0,>=1.9.1->-r ./requirements.txt (line 12)) (3.6.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric->-r ./requirements.txt (line 16)) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric->-r ./requirements.txt (line 16)) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric->-r ./requirements.txt (line 16)) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric->-r ./requirements.txt (line 16)) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric->-r ./requirements.txt (line 16)) (6.6.4)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric->-r ./requirements.txt (line 16)) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric->-r ./requirements.txt (line 16)) (1.20.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from chex->scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13)) (75.2.0)\n","Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chex->scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13)) (0.12.1)\n","Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.12/dist-packages (from flax->scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13)) (0.11.24)\n","Requirement already satisfied: treescope>=0.1.7 in /usr/local/lib/python3.12/dist-packages (from flax->scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13)) (0.1.10)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.3.1->-r ./requirements.txt (line 6)) (3.0.3)\n","Requirement already satisfied: multipledispatch in /usr/local/lib/python3.12/dist-packages (from numpyro->scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13)) (1.0.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.3.1->-r ./requirements.txt (line 6)) (1.3.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21.2->datasets<3.0.0,>=2.3.0->scgpt->-r ./requirements.txt (line 18)) (1.1.10)\n","Collecting texttable>=1.6.2 (from igraph<0.12,>=0.10.0->leidenalg>=0.8.10->scgpt->-r ./requirements.txt (line 18))\n","  Downloading texttable-1.7.0-py2.py3-none-any.whl.metadata (9.8 kB)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13)) (0.1.2)\n","Collecting donfig>=0.8 (from zarr!=3.0.*,>=2.18.7->anndata>=0.8->scanpy<2.0,>=1.9.1->-r ./requirements.txt (line 12))\n","  Downloading donfig-0.8.1.post1-py3-none-any.whl.metadata (5.0 kB)\n","Collecting numcodecs>=0.14 (from numcodecs[crc32c]>=0.14->zarr!=3.0.*,>=2.18.7->anndata>=0.8->scanpy<2.0,>=1.9.1->-r ./requirements.txt (line 12))\n","  Downloading numcodecs-0.16.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n","Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.12/dist-packages (from deprecated->scib<2.0.0,>=1.0.3->scgpt->-r ./requirements.txt (line 18)) (1.17.3)\n","Requirement already satisfied: aiofiles in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax->scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13)) (24.1.0)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax->scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13)) (5.29.5)\n","Requirement already satisfied: humanize in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax->scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13)) (4.13.0)\n","Requirement already satisfied: simplejson>=3.16.0 in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax->scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13)) (3.20.2)\n","Collecting crc32c>=2.7 (from numcodecs[crc32c]>=0.14->zarr!=3.0.*,>=2.18.7->anndata>=0.8->scanpy<2.0,>=1.9.1->-r ./requirements.txt (line 12))\n","  Downloading crc32c-2.7.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n","Requirement already satisfied: zipp in /usr/local/lib/python3.12/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax->scvi-tools<1.0,>=0.16.0->-r ./requirements.txt (line 13)) (3.23.0)\n","Downloading torch-2.3.1-cp312-cp312-manylinux1_x86_64.whl (779.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchvision-0.18.1-cp312-cp312-manylinux1_x86_64.whl (7.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m126.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchaudio-2.3.1-cp312-cp312-manylinux1_x86_64.whl (3.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchtext-0.18.0-cp312-cp312-manylinux1_x86_64.whl (2.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m99.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m147.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m117.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading scanpy-1.11.4-py3-none-any.whl (2.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m103.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading scvi_tools-0.20.3-py3-none-any.whl (330 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.3/330.3 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading scgpt-0.2.4-py3-none-any.whl (831 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m831.7/831.7 kB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading anndata-0.12.2-py3-none-any.whl (169 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.9/169.9 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading datasets-2.21.0-py3-none-any.whl (527 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.3/527.3 kB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading legacy_api_wrap-1.4.1-py3-none-any.whl (10.0 kB)\n","Downloading leidenalg-0.10.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ml_collections-1.1.0-py3-none-any.whl (76 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.7/76.7 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mudata-0.3.2-py3-none-any.whl (41 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading orbax-0.1.7-py3-none-any.whl (77 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.5/77.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyro_ppl-1.9.1-py3-none-any.whl (755 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pytorch_lightning-1.9.5-py3-none-any.whl (829 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m829.5/829.5 kB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading scib-1.1.7-1-py3-none-any.whl (84 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.6/84.6 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading scikit_misc-0.5.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (183 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.6/183.6 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dcor-0.6-py3-none-any.whl (55 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numpyro-0.19.0-py3-none-any.whl (370 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m370.9/370.9 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading session_info2-0.2.2-py3-none-any.whl (16 kB)\n","Downloading array_api_compat-1.12.0-py3-none-any.whl (58 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.2/58.2 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading igraph-0.11.9-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m93.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n","Downloading pyro_api-0.1.2-py3-none-any.whl (11 kB)\n","Downloading zarr-3.1.3-py3-none-any.whl (276 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.4/276.4 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading cached_property-2.0.1-py3-none-any.whl (7.4 kB)\n","Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n","Downloading donfig-0.8.1.post1-py3-none-any.whl (21 kB)\n","Downloading numcodecs-0.16.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m133.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n","Downloading crc32c-2.7.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.5/53.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: cell-gears, docrep\n","  Building wheel for cell-gears (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for cell-gears: filename=cell_gears-0.0.2-py3-none-any.whl size=27809 sha256=9779a008a9379a77bc3daf0074d78a3fc237f3ec7b0bb6ef6b19a992d571c2f5\n","  Stored in directory: /root/.cache/pip/wheels/c3/7d/33/062df7a4c34312454fa656f964080fe34b4d518fdb851d164f\n","  Building wheel for docrep (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for docrep: filename=docrep-0.3.2-py3-none-any.whl size=19876 sha256=659b61987a0673b2b04f25d04e6ebb5d70920f085a10f49362ca366df60533fa\n","  Stored in directory: /root/.cache/pip/wheels/d6/19/ee/0a6a1793d91c449563b49ccab57ce52da3e6fab7614836bd8c\n","Successfully built cell-gears docrep\n","Installing collected packages: texttable, pyro-api, session-info2, scikit-misc, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numcodecs, ml-collections, lightning-utilities, legacy-api-wrap, igraph, fsspec, donfig, docrep, deprecated, crc32c, cached_property, array-api-compat, nvidia-cusolver-cu12, nvidia-cudnn-cu12, leidenalg, dcor, zarr, torch_geometric, torch, torchvision, torchtext, torchmetrics, torchaudio, pyro-ppl, orbax, numpyro, datasets, anndata, scanpy, pytorch-lightning, mudata, scib, cell-gears, scvi-tools, scgpt\n","  Attempting uninstall: nvidia-nvtx-cu12\n","    Found existing installation: nvidia-nvtx-cu12 12.6.77\n","    Uninstalling nvidia-nvtx-cu12-12.6.77:\n","      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n","  Attempting uninstall: nvidia-nccl-cu12\n","    Found existing installation: nvidia-nccl-cu12 2.27.3\n","    Uninstalling nvidia-nccl-cu12-2.27.3:\n","      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n","    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.7.77\n","    Uninstalling nvidia-curand-cu12-10.3.7.77:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n","    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n","      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n","    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n","    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n","    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n","      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2025.3.0\n","    Uninstalling fsspec-2025.3.0:\n","      Successfully uninstalled fsspec-2025.3.0\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n","    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n","    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.8.0+cu126\n","    Uninstalling torch-2.8.0+cu126:\n","      Successfully uninstalled torch-2.8.0+cu126\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.23.0+cu126\n","    Uninstalling torchvision-0.23.0+cu126:\n","      Successfully uninstalled torchvision-0.23.0+cu126\n","  Attempting uninstall: torchaudio\n","    Found existing installation: torchaudio 2.8.0+cu126\n","    Uninstalling torchaudio-2.8.0+cu126:\n","      Successfully uninstalled torchaudio-2.8.0+cu126\n","  Attempting uninstall: datasets\n","    Found existing installation: datasets 4.0.0\n","    Uninstalling datasets-4.0.0:\n","      Successfully uninstalled datasets-4.0.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.6.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed anndata-0.12.2 array-api-compat-1.12.0 cached_property-2.0.1 cell-gears-0.0.2 crc32c-2.7.1 datasets-2.21.0 dcor-0.6 deprecated-1.2.18 docrep-0.3.2 donfig-0.8.1.post1 fsspec-2024.6.1 igraph-0.11.9 legacy-api-wrap-1.4.1 leidenalg-0.10.2 lightning-utilities-0.15.2 ml-collections-1.1.0 mudata-0.3.2 numcodecs-0.16.3 numpyro-0.19.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 orbax-0.1.7 pyro-api-0.1.2 pyro-ppl-1.9.1 pytorch-lightning-1.9.5 scanpy-1.11.4 scgpt-0.2.4 scib-1.1.7 scikit-misc-0.5.1 scvi-tools-0.20.3 session-info2-0.2.2 texttable-1.7.0 torch-2.3.1 torch_geometric-2.6.1 torchaudio-2.3.1 torchmetrics-1.8.2 torchtext-0.18.0 torchvision-0.18.1 zarr-3.1.3\n","Requirement already satisfied: scgpt in /usr/local/lib/python3.12/dist-packages (0.2.4)\n","Collecting flash-attn<1.0.5\n","  Downloading flash_attn-1.0.4.tar.gz (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: cell-gears<0.0.3 in /usr/local/lib/python3.12/dist-packages (from scgpt) (0.0.2)\n","Requirement already satisfied: datasets<3.0.0,>=2.3.0 in /usr/local/lib/python3.12/dist-packages (from scgpt) (2.21.0)\n","Requirement already satisfied: leidenalg>=0.8.10 in /usr/local/lib/python3.12/dist-packages (from scgpt) (0.10.2)\n","Requirement already satisfied: numba>=0.55.1 in /usr/local/lib/python3.12/dist-packages (from scgpt) (0.60.0)\n","Requirement already satisfied: orbax<0.1.8 in /usr/local/lib/python3.12/dist-packages (from scgpt) (0.1.7)\n","Requirement already satisfied: pandas>=1.3.5 in /usr/local/lib/python3.12/dist-packages (from scgpt) (2.2.2)\n","Requirement already satisfied: scanpy<2.0.0,>=1.9.1 in /usr/local/lib/python3.12/dist-packages (from scgpt) (1.11.4)\n","Requirement already satisfied: scib<2.0.0,>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from scgpt) (1.1.7)\n","Requirement already satisfied: scikit-misc>=0.1.4 in /usr/local/lib/python3.12/dist-packages (from scgpt) (0.5.1)\n","Requirement already satisfied: scvi-tools<1.0,>=0.16.0 in /usr/local/lib/python3.12/dist-packages (from scgpt) (0.20.3)\n","Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from scgpt) (2.3.1)\n","Requirement already satisfied: torchtext in /usr/local/lib/python3.12/dist-packages (from scgpt) (0.18.0)\n","Requirement already satisfied: typing-extensions<5.0.0,>=4.2.0 in /usr/local/lib/python3.12/dist-packages (from scgpt) (4.15.0)\n","Requirement already satisfied: umap-learn>=0.5.3 in /usr/local/lib/python3.12/dist-packages (from scgpt) (0.5.9.post2)\n","Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from flash-attn<1.0.5) (0.8.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from flash-attn<1.0.5) (25.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from cell-gears<0.0.3->scgpt) (2.0.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from cell-gears<0.0.3->scgpt) (4.67.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from cell-gears<0.0.3->scgpt) (1.6.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from cell-gears<0.0.3->scgpt) (3.5)\n","Requirement already satisfied: dcor in /usr/local/lib/python3.12/dist-packages (from cell-gears<0.0.3->scgpt) (0.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets<3.0.0,>=2.3.0->scgpt) (3.19.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets<3.0.0,>=2.3.0->scgpt) (18.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets<3.0.0,>=2.3.0->scgpt) (0.3.8)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets<3.0.0,>=2.3.0->scgpt) (2.32.4)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets<3.0.0,>=2.3.0->scgpt) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from datasets<3.0.0,>=2.3.0->scgpt) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets<3.0.0,>=2.3.0->scgpt) (2024.6.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from datasets<3.0.0,>=2.3.0->scgpt) (3.12.15)\n","Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.12/dist-packages (from datasets<3.0.0,>=2.3.0->scgpt) (0.35.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets<3.0.0,>=2.3.0->scgpt) (6.0.3)\n","Requirement already satisfied: igraph<0.12,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from leidenalg>=0.8.10->scgpt) (0.11.9)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.55.1->scgpt) (0.43.0)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from orbax<0.1.8->scgpt) (1.4.0)\n","Requirement already satisfied: cached_property in /usr/local/lib/python3.12/dist-packages (from orbax<0.1.8->scgpt) (2.0.1)\n","Requirement already satisfied: importlib_resources in /usr/local/lib/python3.12/dist-packages (from orbax<0.1.8->scgpt) (6.5.2)\n","Requirement already satisfied: msgpack in /usr/local/lib/python3.12/dist-packages (from orbax<0.1.8->scgpt) (1.1.1)\n","Requirement already satisfied: etils in /usr/local/lib/python3.12/dist-packages (from orbax<0.1.8->scgpt) (1.13.0)\n","Requirement already satisfied: jax>=0.4.6 in /usr/local/lib/python3.12/dist-packages (from orbax<0.1.8->scgpt) (0.5.3)\n","Requirement already satisfied: jaxlib in /usr/local/lib/python3.12/dist-packages (from orbax<0.1.8->scgpt) (0.5.3)\n","Requirement already satisfied: tensorstore>=0.1.20 in /usr/local/lib/python3.12/dist-packages (from orbax<0.1.8->scgpt) (0.1.77)\n","Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.12/dist-packages (from orbax<0.1.8->scgpt) (1.6.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.5->scgpt) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.5->scgpt) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.5->scgpt) (2025.2)\n","Requirement already satisfied: anndata>=0.8 in /usr/local/lib/python3.12/dist-packages (from scanpy<2.0.0,>=1.9.1->scgpt) (0.12.2)\n","Requirement already satisfied: h5py>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from scanpy<2.0.0,>=1.9.1->scgpt) (3.14.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from scanpy<2.0.0,>=1.9.1->scgpt) (1.5.2)\n","Requirement already satisfied: legacy-api-wrap>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from scanpy<2.0.0,>=1.9.1->scgpt) (1.4.1)\n","Requirement already satisfied: matplotlib>=3.7.5 in /usr/local/lib/python3.12/dist-packages (from scanpy<2.0.0,>=1.9.1->scgpt) (3.10.0)\n","Requirement already satisfied: natsort in /usr/local/lib/python3.12/dist-packages (from scanpy<2.0.0,>=1.9.1->scgpt) (8.4.0)\n","Requirement already satisfied: patsy!=1.0.0 in /usr/local/lib/python3.12/dist-packages (from scanpy<2.0.0,>=1.9.1->scgpt) (1.0.1)\n","Requirement already satisfied: pynndescent>=0.5.13 in /usr/local/lib/python3.12/dist-packages (from scanpy<2.0.0,>=1.9.1->scgpt) (0.5.13)\n","Requirement already satisfied: scipy>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from scanpy<2.0.0,>=1.9.1->scgpt) (1.16.2)\n","Requirement already satisfied: seaborn>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from scanpy<2.0.0,>=1.9.1->scgpt) (0.13.2)\n","Requirement already satisfied: session-info2 in /usr/local/lib/python3.12/dist-packages (from scanpy<2.0.0,>=1.9.1->scgpt) (0.2.2)\n","Requirement already satisfied: statsmodels>=0.14.5 in /usr/local/lib/python3.12/dist-packages (from scanpy<2.0.0,>=1.9.1->scgpt) (0.14.5)\n","Requirement already satisfied: pydot in /usr/local/lib/python3.12/dist-packages (from scib<2.0.0,>=1.0.3->scgpt) (3.0.4)\n","Requirement already satisfied: deprecated in /usr/local/lib/python3.12/dist-packages (from scib<2.0.0,>=1.0.3->scgpt) (1.2.18)\n","Requirement already satisfied: chex in /usr/local/lib/python3.12/dist-packages (from scvi-tools<1.0,>=0.16.0->scgpt) (0.1.90)\n","Requirement already satisfied: docrep>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from scvi-tools<1.0,>=0.16.0->scgpt) (0.3.2)\n","Requirement already satisfied: flax in /usr/local/lib/python3.12/dist-packages (from scvi-tools<1.0,>=0.16.0->scgpt) (0.10.6)\n","Requirement already satisfied: ml-collections>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from scvi-tools<1.0,>=0.16.0->scgpt) (1.1.0)\n","Requirement already satisfied: mudata>=0.1.2 in /usr/local/lib/python3.12/dist-packages (from scvi-tools<1.0,>=0.16.0->scgpt) (0.3.2)\n","Requirement already satisfied: numpyro in /usr/local/lib/python3.12/dist-packages (from scvi-tools<1.0,>=0.16.0->scgpt) (0.19.0)\n","Requirement already satisfied: openpyxl>=3.0 in /usr/local/lib/python3.12/dist-packages (from scvi-tools<1.0,>=0.16.0->scgpt) (3.1.5)\n","Requirement already satisfied: optax in /usr/local/lib/python3.12/dist-packages (from scvi-tools<1.0,>=0.16.0->scgpt) (0.2.6)\n","Requirement already satisfied: pyro-ppl>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scvi-tools<1.0,>=0.16.0->scgpt) (1.9.1)\n","Requirement already satisfied: pytorch-lightning<1.10.0,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from scvi-tools<1.0,>=0.16.0->scgpt) (1.9.5)\n","Requirement already satisfied: rich>=12.0.0 in /usr/local/lib/python3.12/dist-packages (from scvi-tools<1.0,>=0.16.0->scgpt) (13.9.4)\n","Requirement already satisfied: torchmetrics>=0.11.0 in /usr/local/lib/python3.12/dist-packages (from scvi-tools<1.0,>=0.16.0->scgpt) (1.8.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->scgpt) (1.13.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->scgpt) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->scgpt) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->scgpt) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->scgpt) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->scgpt) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->scgpt) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->scgpt) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->scgpt) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->scgpt) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->scgpt) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->scgpt) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->scgpt) (12.1.105)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->scgpt) (12.6.85)\n","Requirement already satisfied: array-api-compat>=1.7.1 in /usr/local/lib/python3.12/dist-packages (from anndata>=0.8->scanpy<2.0.0,>=1.9.1->scgpt) (1.12.0)\n","Requirement already satisfied: zarr!=3.0.*,>=2.18.7 in /usr/local/lib/python3.12/dist-packages (from anndata>=0.8->scanpy<2.0.0,>=1.9.1->scgpt) (3.1.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from docrep>=0.3.2->scvi-tools<1.0,>=0.16.0->scgpt) (1.17.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets<3.0.0,>=2.3.0->scgpt) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets<3.0.0,>=2.3.0->scgpt) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets<3.0.0,>=2.3.0->scgpt) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets<3.0.0,>=2.3.0->scgpt) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets<3.0.0,>=2.3.0->scgpt) (6.6.4)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets<3.0.0,>=2.3.0->scgpt) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets<3.0.0,>=2.3.0->scgpt) (1.20.1)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21.2->datasets<3.0.0,>=2.3.0->scgpt) (1.1.10)\n","Requirement already satisfied: texttable>=1.6.2 in /usr/local/lib/python3.12/dist-packages (from igraph<0.12,>=0.10.0->leidenalg>=0.8.10->scgpt) (1.7.0)\n","Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from jax>=0.4.6->orbax<0.1.8->scgpt) (0.5.3)\n","Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax>=0.4.6->orbax<0.1.8->scgpt) (3.4.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.5->scanpy<2.0.0,>=1.9.1->scgpt) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.5->scanpy<2.0.0,>=1.9.1->scgpt) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.5->scanpy<2.0.0,>=1.9.1->scgpt) (4.60.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.5->scanpy<2.0.0,>=1.9.1->scgpt) (1.4.9)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.5->scanpy<2.0.0,>=1.9.1->scgpt) (11.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.5->scanpy<2.0.0,>=1.9.1->scgpt) (3.2.5)\n","Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl>=3.0->scvi-tools<1.0,>=0.16.0->scgpt) (2.0.0)\n","Requirement already satisfied: pyro-api>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from pyro-ppl>=1.6.0->scvi-tools<1.0,>=0.16.0->scgpt) (0.1.2)\n","Requirement already satisfied: lightning-utilities>=0.6.0.post0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning<1.10.0,>=1.9.0->scvi-tools<1.0,>=0.16.0->scgpt) (0.15.2)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets<3.0.0,>=2.3.0->scgpt) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets<3.0.0,>=2.3.0->scgpt) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets<3.0.0,>=2.3.0->scgpt) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets<3.0.0,>=2.3.0->scgpt) (2025.8.3)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.0.0->scvi-tools<1.0,>=0.16.0->scgpt) (4.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.0.0->scvi-tools<1.0,>=0.16.0->scgpt) (2.19.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->cell-gears<0.0.3->scgpt) (3.6.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from chex->scvi-tools<1.0,>=0.16.0->scgpt) (75.2.0)\n","Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chex->scvi-tools<1.0,>=0.16.0->scgpt) (0.12.1)\n","Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.12/dist-packages (from deprecated->scib<2.0.0,>=1.0.3->scgpt) (1.17.3)\n","Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.12/dist-packages (from flax->scvi-tools<1.0,>=0.16.0->scgpt) (0.11.24)\n","Requirement already satisfied: treescope>=0.1.7 in /usr/local/lib/python3.12/dist-packages (from flax->scvi-tools<1.0,>=0.16.0->scgpt) (0.1.10)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.13.0->scgpt) (3.0.3)\n","Requirement already satisfied: multipledispatch in /usr/local/lib/python3.12/dist-packages (from numpyro->scvi-tools<1.0,>=0.16.0->scgpt) (1.0.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch>=1.13.0->scgpt) (1.3.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->scvi-tools<1.0,>=0.16.0->scgpt) (0.1.2)\n","Requirement already satisfied: donfig>=0.8 in /usr/local/lib/python3.12/dist-packages (from zarr!=3.0.*,>=2.18.7->anndata>=0.8->scanpy<2.0.0,>=1.9.1->scgpt) (0.8.1.post1)\n","Requirement already satisfied: numcodecs>=0.14 in /usr/local/lib/python3.12/dist-packages (from numcodecs[crc32c]>=0.14->zarr!=3.0.*,>=2.18.7->anndata>=0.8->scanpy<2.0.0,>=1.9.1->scgpt) (0.16.3)\n","Requirement already satisfied: aiofiles in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax->scvi-tools<1.0,>=0.16.0->scgpt) (24.1.0)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax->scvi-tools<1.0,>=0.16.0->scgpt) (5.29.5)\n","Requirement already satisfied: humanize in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax->scvi-tools<1.0,>=0.16.0->scgpt) (4.13.0)\n","Requirement already satisfied: simplejson>=3.16.0 in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax->scvi-tools<1.0,>=0.16.0->scgpt) (3.20.2)\n","Requirement already satisfied: crc32c>=2.7 in /usr/local/lib/python3.12/dist-packages (from numcodecs[crc32c]>=0.14->zarr!=3.0.*,>=2.18.7->anndata>=0.8->scanpy<2.0.0,>=1.9.1->scgpt) (2.7.1)\n","Requirement already satisfied: zipp in /usr/local/lib/python3.12/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax->scvi-tools<1.0,>=0.16.0->scgpt) (3.23.0)\n","Building wheels for collected packages: flash-attn\n","  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for flash-attn: filename=flash_attn-1.0.4-cp312-cp312-linux_x86_64.whl size=72830986 sha256=26852fd4c9c6cd71c6025cdb755c89571dce76803b8eb3482236809eeac20751\n","  Stored in directory: /root/.cache/pip/wheels/e6/d9/e4/0b3fc5da539a482a48b9b041e20a07fec0964ba6b4e7148e5e\n","Successfully built flash-attn\n","Installing collected packages: flash-attn\n","Successfully installed flash-attn-1.0.4\n"]}]},{"cell_type":"markdown","metadata":{"id":"IfC_Rdtejr3t"},"source":["# Fine-tuning Pre-trained Model for Perturbation Prediction"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lXJ8rqsIjr3v","executionInfo":{"status":"ok","timestamp":1759723183950,"user_tz":300,"elapsed":54045,"user":{"displayName":"Zhexuan Liu","userId":"18073944608501350772"}},"outputId":"a1aba895-9ed2-4f5a-fc52-e0e43fb9d9d5"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torchtext/vocab/__init__.py:4: UserWarning: \n","/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n","Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n","  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n","/usr/local/lib/python3.12/dist-packages/torchtext/utils.py:4: UserWarning: \n","/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n","Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n","  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"]}],"source":["import json\n","import os\n","import sys\n","import time\n","import copy\n","from pathlib import Path\n","from typing import Iterable, List, Tuple, Dict, Union, Optional\n","import warnings\n","\n","import torch\n","import numpy as np\n","import matplotlib\n","from torch import nn\n","from torch.nn import functional as F\n","from torchtext.vocab import Vocab\n","from torchtext._torchtext import (\n","    Vocab as VocabPybind,\n",")\n","from torch_geometric.loader import DataLoader\n","from gears import PertData, GEARS\n","from gears.inference import compute_metrics, deeper_analysis, non_dropout_analysis\n","from gears.utils import create_cell_graph_dataset_for_prediction\n","\n","sys.path.insert(0, \"../\")\n","\n","import scgpt as scg\n","from scgpt.model import TransformerGenerator\n","from scgpt.loss import (\n","    masked_mse_loss,\n","    criterion_neg_log_bernoulli,\n","    masked_relative_error,\n",")\n","from scgpt.tokenizer import tokenize_batch, pad_batch, tokenize_and_pad_batch\n","from scgpt.tokenizer.gene_tokenizer import GeneVocab\n","from scgpt.utils import set_seed, map_raw_id_to_vocab_id, compute_perturbation_metrics\n","\n","matplotlib.rcParams[\"savefig.transparent\"] = False\n","warnings.filterwarnings(\"ignore\")\n","\n","set_seed(42)\n"]},{"cell_type":"markdown","metadata":{"id":"7VHkZ-0xjr3w"},"source":[" ## Training Settings"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"QsbX8I8Gjr3w","executionInfo":{"status":"ok","timestamp":1759723184000,"user_tz":300,"elapsed":38,"user":{"displayName":"Zhexuan Liu","userId":"18073944608501350772"}}},"outputs":[],"source":["# settings for data prcocessing\n","pad_token = \"<pad>\"\n","special_tokens = [pad_token, \"<cls>\", \"<eoc>\"]\n","pad_value = 0  # for padding values\n","pert_pad_id = 0\n","include_zero_gene = \"all\"\n","max_seq_len = 1536\n","\n","# settings for training\n","MLM = True  # whether to use masked language modeling, currently it is always on.\n","CLS = False  # celltype classification objective\n","CCE = False  # Contrastive cell embedding objective\n","MVC = False  # Masked value prediction for cell embedding\n","ECS = False  # Elastic cell similarity objective\n","amp = True\n","load_model = \"./save/scGPT_human\"\n","load_param_prefixs = [\n","    \"encoder\",\n","    \"value_encoder\",\n","    \"transformer_encoder\",\n","]\n","\n","# settings for optimizer\n","lr = 1e-4  # or 1e-4\n","batch_size = 64\n","eval_batch_size = 64\n","epochs = 15\n","schedule_interval = 1\n","early_stop = 10\n","\n","# settings for the model\n","embsize = 512  # embedding dimension\n","d_hid = 512  # dimension of the feedforward network model in nn.TransformerEncoder\n","nlayers = 12  # number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n","nhead = 8  # number of heads in nn.MultiheadAttention\n","n_layers_cls = 3\n","dropout = 0  # dropout probability\n","use_fast_transformer = True  # whether to use fast transformer\n","\n","# logging\n","log_interval = 100\n","\n","# dataset and evaluation choices\n","data_name = \"adamson\"\n","split = \"simulation\"\n","if data_name == \"norman\":\n","    perts_to_plot = [\"SAMD1+ZBTB1\"]\n","elif data_name == \"adamson\":\n","    perts_to_plot = [\"KCTD16+ctrl\"]\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"vtSFD5NZjr3x","executionInfo":{"status":"ok","timestamp":1759723184047,"user_tz":300,"elapsed":40,"user":{"displayName":"Zhexuan Liu","userId":"18073944608501350772"}},"outputId":"37967959-a04f-43c1-dac7-1e81ae3b7428"},"outputs":[{"output_type":"stream","name":"stdout","text":["saving to save/dev_perturb_adamson-Oct06-03-59\n","scGPT - INFO - Running on 2025-10-06 03:59:43\n"]}],"source":["save_dir = Path(f\"./save/dev_perturb_{data_name}-{time.strftime('%b%d-%H-%M')}/\")\n","save_dir.mkdir(parents=True, exist_ok=True)\n","print(f\"saving to {save_dir}\")\n","\n","logger = scg.logger\n","scg.utils.add_file_handler(logger, save_dir / \"run.log\")\n","# log running date and current git commit\n","logger.info(f\"Running on {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HGVlaydDjr3x","executionInfo":{"status":"ok","timestamp":1759723245737,"user_tz":300,"elapsed":61653,"user":{"displayName":"Zhexuan Liu","userId":"18073944608501350772"}},"outputId":"82402e00-3b20-4cbd-cbed-d328d7e71f94"},"outputs":[{"output_type":"stream","name":"stderr","text":["Found local copy...\n","Local copy of pyg dataset is detected. Loading...\n","Done!\n","Local copy of split is detected. Loading...\n","Simulation split test composition:\n","combo_seen0:0\n","combo_seen1:0\n","combo_seen2:0\n","unseen_single:22\n","Done!\n","Creating dataloaders....\n","Done!\n"]}],"source":["pert_data = PertData(\"./data\")\n","pert_data.load(data_name=data_name)\n","pert_data.prepare_split(split=split, seed=1)\n","pert_data.get_dataloader(batch_size=batch_size, test_batch_size=eval_batch_size)\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9EiJkwMhjr3y","executionInfo":{"status":"ok","timestamp":1759723247392,"user_tz":300,"elapsed":1644,"user":{"displayName":"Zhexuan Liu","userId":"18073944608501350772"}},"outputId":"fda7595d-6f21-4e99-893d-ce199fbc2a17"},"outputs":[{"output_type":"stream","name":"stdout","text":["scGPT - INFO - match 4399/5060 genes in vocabulary of size 60697.\n","scGPT - INFO - Resume model from save/scGPT_human/best_model.pt, the model args will override the config save/scGPT_human/args.json.\n"]}],"source":["if load_model is not None:\n","    model_dir = Path(\"./save/scGPT_human\")\n","    model_config_file = model_dir / \"args.json\"\n","    model_file = model_dir / \"best_model.pt\"\n","    vocab_file = model_dir / \"vocab.json\"\n","\n","    vocab = GeneVocab.from_file(vocab_file)\n","    for s in special_tokens:\n","        if s not in vocab:\n","            vocab.append_token(s)\n","\n","    pert_data.adata.var[\"id_in_vocab\"] = [\n","        1 if gene in vocab else -1 for gene in pert_data.adata.var[\"gene_name\"]\n","    ]\n","    gene_ids_in_vocab = np.array(pert_data.adata.var[\"id_in_vocab\"])\n","    logger.info(\n","        f\"match {np.sum(gene_ids_in_vocab >= 0)}/{len(gene_ids_in_vocab)} genes \"\n","        f\"in vocabulary of size {len(vocab)}.\"\n","    )\n","    genes = pert_data.adata.var[\"gene_name\"].tolist()\n","\n","    # model\n","    with open(model_config_file, \"r\") as f:\n","        model_configs = json.load(f)\n","    logger.info(\n","        f\"Resume model from {model_file}, the model args will override the \"\n","        f\"config {model_config_file}.\"\n","    )\n","    embsize = model_configs[\"embsize\"]\n","    nhead = model_configs[\"nheads\"]\n","    d_hid = model_configs[\"d_hid\"]\n","    nlayers = model_configs[\"nlayers\"]\n","    n_layers_cls = model_configs[\"n_layers_cls\"]\n","else:\n","    genes = pert_data.adata.var[\"gene_name\"].tolist()\n","    vocab = Vocab(\n","        VocabPybind(genes + special_tokens, None)\n","    )  # bidirectional lookup [gene <-> int]\n","vocab.set_default_index(vocab[\"<pad>\"])\n","gene_ids = np.array(\n","    [vocab[gene] if gene in vocab else vocab[\"<pad>\"] for gene in genes], dtype=int\n",")\n","n_genes = len(genes)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"7cY8BKFxjr3y"},"source":[" # Create and train scGpt"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kR3jYQrjjr3y","executionInfo":{"status":"ok","timestamp":1759723261064,"user_tz":300,"elapsed":13662,"user":{"displayName":"Zhexuan Liu","userId":"18073944608501350772"}},"outputId":"5ca16ecb-7934-4659-fc08-a723a1ad0c51"},"outputs":[{"output_type":"stream","name":"stdout","text":["scGPT - INFO - Loading params encoder.embedding.weight with shape torch.Size([60697, 512])\n","scGPT - INFO - Loading params encoder.enc_norm.weight with shape torch.Size([512])\n","scGPT - INFO - Loading params encoder.enc_norm.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])\n","scGPT - INFO - Loading params value_encoder.linear1.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])\n","scGPT - INFO - Loading params value_encoder.linear2.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params value_encoder.norm.weight with shape torch.Size([512])\n","scGPT - INFO - Loading params value_encoder.norm.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n","scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])\n","scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])\n","scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])\n","scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])\n","scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n","scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])\n","scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])\n","scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])\n","scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])\n","scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n","scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])\n","scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])\n","scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])\n","scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])\n","scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n","scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])\n","scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])\n","scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])\n","scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])\n","scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n","scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])\n","scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])\n","scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])\n","scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])\n","scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n","scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])\n","scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])\n","scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])\n","scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])\n","scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n","scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])\n","scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])\n","scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])\n","scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])\n","scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n","scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])\n","scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])\n","scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])\n","scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])\n","scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n","scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])\n","scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])\n","scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])\n","scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])\n","scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n","scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])\n","scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])\n","scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])\n","scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])\n","scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n","scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])\n","scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])\n","scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])\n","scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])\n","scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n","scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])\n","scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])\n","scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])\n","scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])\n","scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])\n","scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])\n"]},{"output_type":"execute_result","data":{"text/plain":["TransformerGenerator(\n","  (encoder): GeneEncoder(\n","    (embedding): Embedding(60697, 512, padding_idx=60694)\n","    (enc_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (value_encoder): ContinuousValueEncoder(\n","    (dropout): Dropout(p=0, inplace=False)\n","    (linear1): Linear(in_features=1, out_features=512, bias=True)\n","    (activation): ReLU()\n","    (linear2): Linear(in_features=512, out_features=512, bias=True)\n","    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (pert_encoder): Embedding(3, 512, padding_idx=0)\n","  (transformer_encoder): TransformerEncoder(\n","    (layers): ModuleList(\n","      (0-11): 12 x FlashTransformerEncoderLayer(\n","        (self_attn): FlashMHA(\n","          (Wqkv): Linear(in_features=512, out_features=1536, bias=True)\n","          (inner_attn): FlashAttention()\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (linear1): Linear(in_features=512, out_features=512, bias=True)\n","        (dropout): Dropout(p=0, inplace=False)\n","        (linear2): Linear(in_features=512, out_features=512, bias=True)\n","        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (dropout1): Dropout(p=0, inplace=False)\n","        (dropout2): Dropout(p=0, inplace=False)\n","      )\n","    )\n","  )\n","  (decoder): AffineExprDecoder(\n","    (coeff_decoder): ExprDecoder(\n","      (fc): Sequential(\n","        (0): Linear(in_features=512, out_features=512, bias=True)\n","        (1): LeakyReLU(negative_slope=0.01)\n","        (2): Linear(in_features=512, out_features=512, bias=True)\n","        (3): LeakyReLU(negative_slope=0.01)\n","        (4): Linear(in_features=512, out_features=1, bias=True)\n","      )\n","    )\n","    (bias_decoder): ExprDecoder(\n","      (fc): Sequential(\n","        (0): Linear(in_features=512, out_features=512, bias=True)\n","        (1): LeakyReLU(negative_slope=0.01)\n","        (2): Linear(in_features=512, out_features=512, bias=True)\n","        (3): LeakyReLU(negative_slope=0.01)\n","        (4): Linear(in_features=512, out_features=1, bias=True)\n","      )\n","    )\n","  )\n","  (cls_decoder): ClsDecoder(\n","    (_decoder): ModuleList(\n","      (0): Linear(in_features=512, out_features=512, bias=True)\n","      (1): ReLU()\n","      (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      (3): Linear(in_features=512, out_features=512, bias=True)\n","      (4): ReLU()\n","      (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (out_layer): Linear(in_features=512, out_features=1, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":7}],"source":["ntokens = len(vocab)  # size of vocabulary\n","model = TransformerGenerator(\n","    ntokens,\n","    embsize,\n","    nhead,\n","    d_hid,\n","    nlayers,\n","    nlayers_cls=n_layers_cls,\n","    n_cls=1,\n","    vocab=vocab,\n","    dropout=dropout,\n","    pad_token=pad_token,\n","    pad_value=pad_value,\n","    pert_pad_id=pert_pad_id,\n","    use_fast_transformer=use_fast_transformer,\n",")\n","if load_param_prefixs is not None and load_model is not None:\n","    # only load params that start with the prefix\n","    model_dict = model.state_dict()\n","    pretrained_dict = torch.load(model_file)\n","    pretrained_dict = {\n","        k: v\n","        for k, v in pretrained_dict.items()\n","        if any([k.startswith(prefix) for prefix in load_param_prefixs])\n","    }\n","    for k, v in pretrained_dict.items():\n","        logger.info(f\"Loading params {k} with shape {v.shape}\")\n","    model_dict.update(pretrained_dict)\n","    model.load_state_dict(model_dict)\n","elif load_model is not None:\n","    try:\n","        model.load_state_dict(torch.load(model_file))\n","        logger.info(f\"Loading all model params from {model_file}\")\n","    except:\n","        # only load params that are in the model and match the size\n","        model_dict = model.state_dict()\n","        pretrained_dict = torch.load(model_file)\n","        pretrained_dict = {\n","            k: v\n","            for k, v in pretrained_dict.items()\n","            if k in model_dict and v.shape == model_dict[k].shape\n","        }\n","        for k, v in pretrained_dict.items():\n","            logger.info(f\"Loading params {k} with shape {v.shape}\")\n","        model_dict.update(pretrained_dict)\n","        model.load_state_dict(model_dict)\n","model.to(device)\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"Fg9vFgPvjr3y","executionInfo":{"status":"ok","timestamp":1759723261079,"user_tz":300,"elapsed":3,"user":{"displayName":"Zhexuan Liu","userId":"18073944608501350772"}}},"outputs":[],"source":["\n","criterion = masked_mse_loss\n","criterion_cls = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, schedule_interval, gamma=0.9)\n","scaler = torch.cuda.amp.GradScaler(enabled=amp)\n","\n","\n","def train(model: nn.Module, train_loader: torch.utils.data.DataLoader) -> None:\n","    \"\"\"\n","    Train the model for one epoch.\n","    \"\"\"\n","    model.train()\n","    total_loss, total_mse = 0.0, 0.0\n","    start_time = time.time()\n","\n","    num_batches = len(train_loader)\n","    for batch, batch_data in enumerate(train_loader):\n","        batch_size = len(batch_data.y)\n","        batch_data.to(device)\n","        x: torch.Tensor = batch_data.x  # (batch_size * n_genes, 2)\n","        ori_gene_values = x[:, 0].view(batch_size, n_genes)\n","        pert_flags = x[:, 1].long().view(batch_size, n_genes)\n","        target_gene_values = batch_data.y  # (batch_size, n_genes)\n","\n","        if include_zero_gene in [\"all\", \"batch-wise\"]:\n","            if include_zero_gene == \"all\":\n","                input_gene_ids = torch.arange(n_genes, device=device, dtype=torch.long)\n","            else:\n","                input_gene_ids = (\n","                    ori_gene_values.nonzero()[:, 1].flatten().unique().sort()[0]\n","                )\n","            # sample input_gene_id\n","            if len(input_gene_ids) > max_seq_len:\n","                input_gene_ids = torch.randperm(len(input_gene_ids), device=device)[\n","                    :max_seq_len\n","                ]\n","            input_values = ori_gene_values[:, input_gene_ids]\n","            input_pert_flags = pert_flags[:, input_gene_ids]\n","            target_values = target_gene_values[:, input_gene_ids]\n","\n","            mapped_input_gene_ids = map_raw_id_to_vocab_id(input_gene_ids, gene_ids)\n","            mapped_input_gene_ids = mapped_input_gene_ids.repeat(batch_size, 1)\n","\n","            # src_key_padding_mask = mapped_input_gene_ids.eq(vocab[pad_token])\n","            src_key_padding_mask = torch.zeros_like(\n","                input_values, dtype=torch.bool, device=device\n","            )\n","\n","        with torch.cuda.amp.autocast(enabled=amp):\n","            output_dict = model(\n","                mapped_input_gene_ids,\n","                input_values,\n","                input_pert_flags,\n","                src_key_padding_mask=src_key_padding_mask,\n","                CLS=CLS,\n","                CCE=CCE,\n","                MVC=MVC,\n","                ECS=ECS,\n","            )\n","            output_values = output_dict[\"mlm_output\"]\n","\n","            masked_positions = torch.ones_like(\n","                input_values, dtype=torch.bool\n","            )  # Use all\n","            loss = loss_mse = criterion(output_values, target_values, masked_positions)\n","\n","        model.zero_grad()\n","        scaler.scale(loss).backward()\n","        scaler.unscale_(optimizer)\n","        with warnings.catch_warnings(record=True) as w:\n","            warnings.filterwarnings(\"always\")\n","            torch.nn.utils.clip_grad_norm_(\n","                model.parameters(),\n","                1.0,\n","                error_if_nonfinite=False if scaler.is_enabled() else True,\n","            )\n","            if len(w) > 0:\n","                logger.warning(\n","                    f\"Found infinite gradient. This may be caused by the gradient \"\n","                    f\"scaler. The current scale is {scaler.get_scale()}. This warning \"\n","                    \"can be ignored if no longer occurs after autoscaling of the scaler.\"\n","                )\n","        scaler.step(optimizer)\n","        scaler.update()\n","\n","        # torch.cuda.empty_cache()\n","\n","        total_loss += loss.item()\n","        total_mse += loss_mse.item()\n","        if batch % log_interval == 0 and batch > 0:\n","            lr = scheduler.get_last_lr()[0]\n","            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n","            cur_loss = total_loss / log_interval\n","            cur_mse = total_mse / log_interval\n","            # ppl = math.exp(cur_loss)\n","            logger.info(\n","                f\"| epoch {epoch:3d} | {batch:3d}/{num_batches:3d} batches | \"\n","                f\"lr {lr:05.4f} | ms/batch {ms_per_batch:5.2f} | \"\n","                f\"loss {cur_loss:5.2f} | mse {cur_mse:5.2f} |\"\n","            )\n","            total_loss = 0\n","            total_mse = 0\n","            start_time = time.time()\n","\n","\n","def eval_perturb(\n","    loader: DataLoader, model: TransformerGenerator, device: torch.device\n",") -> Dict:\n","    \"\"\"\n","    Run model in inference mode using a given data loader\n","    \"\"\"\n","\n","    model.eval()\n","    model.to(device)\n","    pert_cat = []\n","    pred = []\n","    truth = []\n","    pred_de = []\n","    truth_de = []\n","    results = {}\n","    logvar = []\n","\n","    for itr, batch in enumerate(loader):\n","        batch.to(device)\n","        pert_cat.extend(batch.pert)\n","\n","        with torch.no_grad():\n","            p = model.pred_perturb(\n","                batch,\n","                include_zero_gene=include_zero_gene,\n","                gene_ids=gene_ids,\n","            )\n","            t = batch.y\n","            pred.extend(p.cpu())\n","            truth.extend(t.cpu())\n","\n","            # Differentially expressed genes\n","            for itr, de_idx in enumerate(batch.de_idx):\n","                pred_de.append(p[itr, de_idx])\n","                truth_de.append(t[itr, de_idx])\n","\n","    # all genes\n","    results[\"pert_cat\"] = np.array(pert_cat)\n","    pred = torch.stack(pred)\n","    truth = torch.stack(truth)\n","    results[\"pred\"] = pred.detach().cpu().numpy().astype(np.float64)\n","    results[\"truth\"] = truth.detach().cpu().numpy().astype(np.float64)\n","\n","    pred_de = torch.stack(pred_de)\n","    truth_de = torch.stack(truth_de)\n","    results[\"pred_de\"] = pred_de.detach().cpu().numpy().astype(np.float64)\n","    results[\"truth_de\"] = truth_de.detach().cpu().numpy().astype(np.float64)\n","\n","    return results\n","\n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":982},"id":"GuU30M5vjr3z","executionInfo":{"status":"error","timestamp":1759724170353,"user_tz":300,"elapsed":909273,"user":{"displayName":"Zhexuan Liu","userId":"18073944608501350772"}},"outputId":"b4f7fb84-65f9-42d2-85d1-88cd761cb2d8"},"outputs":[{"output_type":"stream","name":"stdout","text":["scGPT - INFO - | epoch   1 | 100/849 batches | lr 0.0001 | ms/batch 304.32 | loss  0.10 | mse  0.10 |\n","scGPT - INFO - | epoch   1 | 200/849 batches | lr 0.0001 | ms/batch 297.82 | loss  0.09 | mse  0.09 |\n","scGPT - INFO - | epoch   1 | 300/849 batches | lr 0.0001 | ms/batch 297.92 | loss  0.08 | mse  0.08 |\n","scGPT - INFO - | epoch   1 | 400/849 batches | lr 0.0001 | ms/batch 298.11 | loss  0.08 | mse  0.08 |\n","scGPT - INFO - | epoch   1 | 500/849 batches | lr 0.0001 | ms/batch 298.18 | loss  0.08 | mse  0.08 |\n","scGPT - INFO - | epoch   1 | 600/849 batches | lr 0.0001 | ms/batch 298.23 | loss  0.08 | mse  0.08 |\n","scGPT - INFO - | epoch   1 | 700/849 batches | lr 0.0001 | ms/batch 298.24 | loss  0.08 | mse  0.08 |\n","scGPT - INFO - | epoch   1 | 800/849 batches | lr 0.0001 | ms/batch 298.16 | loss  0.08 | mse  0.08 |\n","scGPT - INFO - val_metrics at epoch 1: \n","scGPT - INFO - {'pearson': np.float64(0.989626994401517), 'pearson_de': np.float64(0.9521256939986291), 'pearson_delta': np.float64(0.6753658892336164), 'pearson_de_delta': np.float64(0.8529479473134424)}\n","scGPT - INFO - | end of epoch   1 | time: 280.45s | \n","scGPT - INFO - Best model with score 0.9896\n","scGPT - INFO - | epoch   2 | 100/849 batches | lr 0.0001 | ms/batch 301.29 | loss  0.08 | mse  0.08 |\n","scGPT - INFO - | epoch   2 | 200/849 batches | lr 0.0001 | ms/batch 298.19 | loss  0.08 | mse  0.08 |\n","scGPT - INFO - | epoch   2 | 300/849 batches | lr 0.0001 | ms/batch 298.24 | loss  0.08 | mse  0.08 |\n","scGPT - INFO - | epoch   2 | 400/849 batches | lr 0.0001 | ms/batch 298.19 | loss  0.08 | mse  0.08 |\n","scGPT - INFO - | epoch   2 | 500/849 batches | lr 0.0001 | ms/batch 298.20 | loss  0.08 | mse  0.08 |\n","scGPT - INFO - | epoch   2 | 600/849 batches | lr 0.0001 | ms/batch 298.10 | loss  0.08 | mse  0.08 |\n","scGPT - INFO - | epoch   2 | 700/849 batches | lr 0.0001 | ms/batch 298.21 | loss  0.08 | mse  0.08 |\n","scGPT - INFO - | epoch   2 | 800/849 batches | lr 0.0001 | ms/batch 298.10 | loss  0.08 | mse  0.08 |\n","scGPT - INFO - val_metrics at epoch 2: \n","scGPT - INFO - {'pearson': np.float64(0.9885673434023506), 'pearson_de': np.float64(0.951038533174156), 'pearson_delta': np.float64(0.6779508352954968), 'pearson_de_delta': np.float64(0.8316920311951698)}\n","scGPT - INFO - | end of epoch   2 | time: 280.14s | \n","scGPT - INFO - | epoch   3 | 100/849 batches | lr 0.0001 | ms/batch 301.20 | loss  0.08 | mse  0.08 |\n","scGPT - INFO - | epoch   3 | 200/849 batches | lr 0.0001 | ms/batch 297.95 | loss  0.08 | mse  0.08 |\n","scGPT - INFO - | epoch   3 | 300/849 batches | lr 0.0001 | ms/batch 298.15 | loss  0.08 | mse  0.08 |\n","scGPT - INFO - | epoch   3 | 400/849 batches | lr 0.0001 | ms/batch 298.19 | loss  0.08 | mse  0.08 |\n","scGPT - INFO - | epoch   3 | 500/849 batches | lr 0.0001 | ms/batch 298.29 | loss  0.08 | mse  0.08 |\n","scGPT - INFO - | epoch   3 | 600/849 batches | lr 0.0001 | ms/batch 298.16 | loss  0.08 | mse  0.08 |\n","scGPT - INFO - | epoch   3 | 700/849 batches | lr 0.0001 | ms/batch 298.19 | loss  0.08 | mse  0.08 |\n","scGPT - INFO - | epoch   3 | 800/849 batches | lr 0.0001 | ms/batch 298.15 | loss  0.08 | mse  0.08 |\n","scGPT - INFO - val_metrics at epoch 3: \n","scGPT - INFO - {'pearson': np.float64(0.9890670984308308), 'pearson_de': np.float64(0.9441912342338706), 'pearson_delta': np.float64(0.6562050781176023), 'pearson_de_delta': np.float64(0.8109449151843258)}\n","scGPT - INFO - | end of epoch   3 | time: 280.11s | \n","scGPT - INFO - | epoch   4 | 100/849 batches | lr 0.0001 | ms/batch 301.05 | loss  0.08 | mse  0.08 |\n","scGPT - INFO - | epoch   4 | 200/849 batches | lr 0.0001 | ms/batch 298.05 | loss  0.08 | mse  0.08 |\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2750198221.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mvalid_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpert_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_loader\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     train(\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-1902564392.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader)\u001b[0m\n\u001b[1;32m     47\u001b[0m             )\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             output_dict = model(\n\u001b[1;32m     51\u001b[0m                 \u001b[0mmapped_input_gene_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/cuda/amp/autocast_mode.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# TODO: discuss a unified TorchScript-friendly API for autocast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_val\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_tb\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# type: ignore[override]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_scripting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["best_val_loss = float(\"inf\")\n","best_val_corr = 0\n","best_model = None\n","patience = 0\n","\n","for epoch in range(1, epochs + 1):\n","    epoch_start_time = time.time()\n","    train_loader = pert_data.dataloader[\"train_loader\"]\n","    valid_loader = pert_data.dataloader[\"val_loader\"]\n","\n","    train(\n","        model,\n","        train_loader,\n","    )\n","\n","    val_res = eval_perturb(valid_loader, model, device)\n","    val_metrics = compute_perturbation_metrics(\n","        val_res, pert_data.adata[pert_data.adata.obs[\"condition\"] == \"ctrl\"]\n","    )\n","    logger.info(f\"val_metrics at epoch {epoch}: \")\n","    logger.info(val_metrics)\n","\n","    elapsed = time.time() - epoch_start_time\n","    logger.info(f\"| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | \")\n","\n","    val_score = val_metrics[\"pearson\"]\n","    if val_score > best_val_corr:\n","        best_val_corr = val_score\n","        best_model = copy.deepcopy(model)\n","        logger.info(f\"Best model with score {val_score:5.4f}\")\n","        patience = 0\n","    else:\n","        patience += 1\n","        if patience >= early_stop:\n","            logger.info(f\"Early stop at epoch {epoch}\")\n","            break\n","\n","    torch.save(\n","        model.state_dict(),\n","        save_dir / f\"model_{epoch}.pt\",\n","    )\n","\n","    scheduler.step()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TAPt-eMkjr3z","executionInfo":{"status":"aborted","timestamp":1759724170350,"user_tz":300,"elapsed":1896689,"user":{"displayName":"Zhexuan Liu","userId":"18073944608501350772"}}},"outputs":[],"source":["# torch.save(best_model.state_dict(), save_dir / \"best_model.pt\")\n","torch.save(best_model.state_dict(), save_dir / \"best_model_one_epoch.pt\")\n"]},{"cell_type":"code","source":["save_dir"],"metadata":{"id":"l_xchWCTaoxo","executionInfo":{"status":"aborted","timestamp":1759724170355,"user_tz":300,"elapsed":1896688,"user":{"displayName":"Zhexuan Liu","userId":"18073944608501350772"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DX2IG_AFjr3z"},"source":[" ## Evaluations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MVKfOswMjr30","executionInfo":{"status":"aborted","timestamp":1759724170364,"user_tz":300,"elapsed":0,"user":{"displayName":"Zhexuan Liu","userId":"18073944608501350772"}}},"outputs":[],"source":["def predict(\n","    model: TransformerGenerator, pert_list: List[str], pool_size: Optional[int] = None\n",") -> Dict:\n","    \"\"\"\n","    Predict the gene expression values for the given perturbations.\n","\n","    Args:\n","        model (:class:`torch.nn.Module`): The model to use for prediction.\n","        pert_list (:obj:`List[str]`): The list of perturbations to predict.\n","        pool_size (:obj:`int`, optional): For each perturbation, use this number\n","            of cells in the control and predict their perturbation results. Report\n","            the stats of these predictions. If `None`, use all control cells.\n","    \"\"\"\n","    adata = pert_data.adata\n","    ctrl_adata = adata[adata.obs[\"condition\"] == \"ctrl\"]\n","    if pool_size is None:\n","        pool_size = len(ctrl_adata.obs)\n","    gene_list = pert_data.gene_names.values.tolist()\n","    for pert in pert_list:\n","        for i in pert:\n","            if i not in gene_list:\n","                raise ValueError(\n","                    \"The gene is not in the perturbation graph. Please select from GEARS.gene_list!\"\n","                )\n","\n","    model.eval()\n","    device = next(model.parameters()).device\n","    with torch.no_grad():\n","        results_pred = {}\n","        for pert in pert_list:\n","            cell_graphs = create_cell_graph_dataset_for_prediction(\n","                pert, ctrl_adata, gene_list, device, num_samples=pool_size\n","            )\n","            loader = DataLoader(cell_graphs, batch_size=eval_batch_size, shuffle=False)\n","            preds = []\n","            for batch_data in loader:\n","                pred_gene_values = model.pred_perturb(\n","                    batch_data, include_zero_gene, gene_ids=gene_ids, amp=amp\n","                )\n","                preds.append(pred_gene_values)\n","            preds = torch.cat(preds, dim=0)\n","            results_pred[\"_\".join(pert)] = np.mean(preds.detach().cpu().numpy(), axis=0)\n","\n","    return results_pred\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3pOUtA2rjr30","executionInfo":{"status":"aborted","timestamp":1759724170365,"user_tz":300,"elapsed":1896687,"user":{"displayName":"Zhexuan Liu","userId":"18073944608501350772"}}},"outputs":[],"source":["def plot_perturbation(\n","    model: nn.Module, query: str, save_file: str = None, pool_size: int = None\n",") -> matplotlib.figure.Figure:\n","    import matplotlib.pyplot as plt\n","    import numpy as np\n","    import seaborn as sns\n","\n","    sns.set_theme(style=\"ticks\", rc={\"axes.facecolor\": (0, 0, 0, 0)}, font_scale=1.5)\n","\n","    adata = pert_data.adata\n","    gene2idx = pert_data.node_map\n","    cond2name = dict(adata.obs[[\"condition\", \"condition_name\"]].values)\n","    gene_raw2id = dict(zip(adata.var.index.values, adata.var.gene_name.values))\n","\n","    de_idx = [\n","        gene2idx[gene_raw2id[i]]\n","        for i in adata.uns[\"top_non_dropout_de_20\"][cond2name[query]]\n","    ]\n","    genes = [\n","        gene_raw2id[i] for i in adata.uns[\"top_non_dropout_de_20\"][cond2name[query]]\n","    ]\n","    truth = adata[adata.obs.condition == query].X.toarray()[:, de_idx]\n","    if query.split(\"+\")[1] == \"ctrl\":\n","        pred = predict(model, [[query.split(\"+\")[0]]], pool_size=pool_size)\n","        pred = pred[query.split(\"+\")[0]][de_idx]\n","    else:\n","        pred = predict(model, [query.split(\"+\")], pool_size=pool_size)\n","        pred = pred[\"_\".join(query.split(\"+\"))][de_idx]\n","    ctrl_means = adata[adata.obs[\"condition\"] == \"ctrl\"].to_df().mean()[de_idx].values\n","\n","    pred = pred - ctrl_means\n","    truth = truth - ctrl_means\n","\n","    fig, ax = plt.subplots(figsize=[16.5, 4.5])\n","    plt.title(query)\n","    plt.boxplot(truth, showfliers=False, medianprops=dict(linewidth=0))\n","\n","    for i in range(pred.shape[0]):\n","        _ = plt.scatter(i + 1, pred[i], color=\"red\")\n","\n","    plt.axhline(0, linestyle=\"dashed\", color=\"green\")\n","\n","    ax.xaxis.set_ticklabels(genes, rotation=90)\n","\n","    plt.ylabel(\"Change in Gene Expression over Control\", labelpad=10)\n","    plt.tick_params(axis=\"x\", which=\"major\", pad=5)\n","    plt.tick_params(axis=\"y\", which=\"major\", pad=5)\n","    sns.despine()\n","\n","    if save_file:\n","        fig.savefig(save_file, bbox_inches=\"tight\", transparent=False)\n","\n","    return fig"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sCYD76BYjr30","executionInfo":{"status":"aborted","timestamp":1759724170366,"user_tz":300,"elapsed":1896682,"user":{"displayName":"Zhexuan Liu","userId":"18073944608501350772"}}},"outputs":[],"source":["# predict(best_model, [[\"FEV\"], [\"FEV\", \"SAMD11\"]])\n","for p in perts_to_plot:\n","    plot_perturbation(best_model, p, pool_size=300, save_file=f\"{save_dir}/{p}.png\")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fGv4LMX9jr30","executionInfo":{"status":"aborted","timestamp":1759724170366,"user_tz":300,"elapsed":1896676,"user":{"displayName":"Zhexuan Liu","userId":"18073944608501350772"}}},"outputs":[],"source":["test_loader = pert_data.dataloader[\"test_loader\"]\n","test_res = eval_perturb(test_loader, best_model, device)\n","# test_metrics, test_pert_res = compute_metrics(test_res)\n","test_metrics = compute_perturbation_metrics(\n","    test_res, pert_data.adata[pert_data.adata.obs[\"condition\"] == \"ctrl\"]\n",")\n","print(test_metrics)\n","\n","# save the dicts in json\n","with open(f\"{save_dir}/test_metrics.json\", \"w\") as f:\n","    json.dump(test_metrics, f)\n","# with open(f\"{save_dir}/test_pert_res.json\", \"w\") as f:\n","#     json.dump(test_pert_res, f)\n","\n","deeper_res = deeper_analysis(pert_data.adata, test_res)\n","non_dropout_res = non_dropout_analysis(pert_data.adata, test_res)\n","\n","metrics = [\"pearson_delta\", \"pearson_delta_de\"]\n","metrics_non_dropout = [\n","    \"pearson_delta_top20_de_non_dropout\",\n","    \"pearson_top20_de_non_dropout\",\n","]\n","subgroup_analysis = {}\n","for name in pert_data.subgroup[\"test_subgroup\"].keys():\n","    subgroup_analysis[name] = {}\n","    for m in metrics:\n","        subgroup_analysis[name][m] = []\n","\n","    for m in metrics_non_dropout:\n","        subgroup_analysis[name][m] = []\n","\n","for name, pert_list in pert_data.subgroup[\"test_subgroup\"].items():\n","    for pert in pert_list:\n","        for m in metrics:\n","            subgroup_analysis[name][m].append(deeper_res[pert][m])\n","\n","        for m in metrics_non_dropout:\n","            subgroup_analysis[name][m].append(non_dropout_res[pert][m])\n","\n","for name, result in subgroup_analysis.items():\n","    for m in result.keys():\n","        mean_value = np.mean(subgroup_analysis[name][m])\n","        logger.info(\"test_\" + name + \"_\" + m + \": \" + str(mean_value))\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.13"},"orig_nbformat":4,"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}